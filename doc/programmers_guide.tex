%% -*- mode:latex; tex-open-quote:"\\og{}"; tex-close-quote:"\\fg{}" -*-
%%
%%  Copyright (c) 1998-2002 by Pascal Vincent
%%
%%  $Id$

\documentclass[11pt]{book}
\usepackage{t1enc}              % new font encoding  (hyphenate words w/accents)
\usepackage{ae}                 % use virtual fonts for getting good PDF
\usepackage{isolatin1}          % support for French accents
\usepackage{url}                % support URLs properly

%%%%%%%%% Definitions %%%%%%%%%%%%
\newcommand{\PLearn}{{\bf \it PLearn}}
\newcommand{\Object}{{\bf Object}}
\newcommand{\Learner}{{\bf Learner}} 
\newcommand{\PPointable}{{\bf PPointable}} 
\newcommand{\Var}{{\tt Var}}
\newcommand{\RandomVar}{{\tt RandomVar}}

\parskip=2mm
\parindent=0mm

\title{\Huge PLearn Programmer's Guide\\ \Large A programmer's view of the Plearn C++ Machine-Learning Library and tools}

\begin{document}

%%%%%%%% Title Page %%%%%%%%%%
\pagenumbering{roman}
\thispagestyle{empty}

\maketitle

\pagebreak

\vspace*{10cm}



Copyright \copyright\ 1998-2002 Pascal Vincent, Yoshua Bengio \\
Copyright \copyright\ 2004 Martin Monperrus \\

Permission is granted to copy and distribute this document in any medium,
with or without modification, provided that the following conditions are
met:

\begin{enumerate}
\item Modified versions must give fair credit to all authors.
\item Modified versions may not be written with the aim to discredit, misrepresent, or otherwise taint the
      reputation of any of the above authors.
\item Modified versions must retain the above copyright notice, and append to
   it the names of the authors of the modifications, together with the years the
   modifications were written.
\item Modified versions must retain this list of conditions unaltered, 
    and may not impose any further restrictions.
\end{enumerate}


\pagebreak

%%%%%%%%% Table of contents %%%%%%%%%%%%
\addcontentsline{toc}{chapter}{\numberline{}Table of contents}
\tableofcontents

\cleardoublepage\pagebreak
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{ Overview of PLearn}
\section{ Introduction}
 Machine Learning algorithms are usually described in scientific papers in a standard mathematical formulation, often framed as an optimization of a given cost function. PLearn is a C++ library that uses the object-oriented and operator overloading capabilities of the C++ language to allow, among other things, to express cost functions and their optimization as a standard C++ program, in a declarative manner that is as close as possible to their mathematical formalization. 

 Most neural-network and general machine-learning simulation
environments define their own scripting language. While it is very
tempting for every computer-scientist to craft his own language,
creating a complete, clear, efficient and bug-free language is
a horrendous task, so this is how things usually go: one starts
bulding a simple scripting syntax (typically lisp-like because
it's easy to parse) to specify simple experiments. Quickly it
appears too limited, and it may grow to include loops, functions,
data structures, etc. Eventually it ends up including some sort of
support for object-oriented programming, and finally for efficiency
you want it to be compiled rather than interpreted! In the end,
you end up with a huge mess of a system that was not designed to
grow that much from the beginning, and which is often impossible to
comprehend and maintain for anybody but its author. The end-result
might sometimes be impressive, but at the cost of a lot of efforts
diverted from your actual research. While C++ is far from being the
perfect language, it is very powerful, can be both very expressive and
generate highly efficient code, and most of all it has the immense
advantage of being developed and well-supported by worldwide teams
of dedicated and competent people...


 When providing the correct type abstractions, C++ can be an expressive-enough language to directly serve as a highly customizable, extensible and efficient ``scripting language'' for designing and running even the most demanding experiments in machine-learning research and development. So this is what this library is all about: providing the right type abstractions. What originally got me started on this project was the desire to be able to optimize a complex cost function by just expressing it in a declarative way as close as possible to the mathematical formulation. This lead to the original implementation of the Var class. Since then PLearn has grown to include many other useful types and abstractions. 


 While PLearn has been successfully used by several people for over a year, it is still very much work in progress. As its primary use is for our own research, we did not want to carve it in stone: thus future versions may look quite different from this one, as we are still reworking the class hierarchy. But it is nevertheless already very usable, so feel free to play around and experiment with it! 


 Probably the biggest problem, like with many projects of this kind, is the cruel lack of documentation. This manual will attempt to give you a high-level understanding of the basic concepts, but to work out the details, you'll have to look at the actual code. Also, to fully use the potential of this library, you are expected to be somewhat comfortable with the C++ language. 


 Have fun! 


 Pascal 


\section{Developer CVS access}

If you are going to contribute to PLearn on SourceForge
(\url{http://www.sourceforge.net}):
\begin{itemize}
\item If you don't have one already, create a SourceForge account for yourself
\item Send me ({\tt plearner@users.sourceforge.net}) your account login,
so that I can add you to the developer list.
\item Make sure the {\tt CVS\_RSH} environment variable is set to
{\tt ssh} in your .cshrc or .bashrc
\item Check-out PLearn as follows:
\begin{verbatim}
cvs -d :ext:your_sourceforge_login@cvs.sourceforge.net:/cvsroot/plearn co PLearn
\end{verbatim}
\end{itemize}



\section{Additional tools for developers}

In addition, if you wish to develop new learning algorithms, or otherwise
 contribute to the librery, the following tools will be useful:
\begin{itemize}
\item {\bf ssh} for write access to the SourceForge CVS repository.
\item {\bf gdb} for basic debugging (or a {\em better} debugger if you have one!)
\item {\bf valgrind} a wonderful free tool for memory-bug hunting.
\item {\bf perl} for running perl scripts
\item {\bf LaTeX, pdflatex, dvips, latex2html, doxygen} to re-generate the documentation. 
\end{itemize}

\chapter{Basics}

\section{PLearn for Matrix-Vectors Operations}

PLearn can be used as a kind of Matlab. The notation are much 
difficult but the efficiency is uncomparable.

\subsection{Creating}

\begin{verbatim}
#include <plearn/math/TMat_maths.h>
using namespace PLearn;

int main(int argc, char** argv)
{
  // Example use of a `real' variable
  // a compilation option makes it either a double or a float
  // Please don't use double nor float

  real a=15;
  cout<<a<<endl;

  // Vector creation: method 1
  Vec b(3);
  b[0] = 2;
  b[1] = 42;
  b[2] = 21;
  cout<<b<<endl;

  // Vector creation: method 2
  Vec b2(3);
  b2<<"5 4.2 -2";
  cout<<b2<<endl;

  // Matrix creation : method 1
  Mat c(3,2);
  c(1,1)=1.1;
  c(1,0)=4;
  c(2,0)=5;
  c(0,1)=-73.2;
  c(0,0)=78;
  c(2,1)=5.32e-2;
  cout<<c<<endl;

  // Matrix creation : method 2
  Mat c2(3,2);
  c2<<"2 4 2.5e-1 6 1e3 3.1"; // read matrix row by matrix row 
  cout<<c2<<endl;

  return 0;
}
\end{verbatim}

\subsection{Manipulating}
All the corresponding methods are in TMat\_maths\_impl.h (or should be). As of 
date, they are not documented, so you have to have a bath in the file (methods 
should be commented). A short example:

\begin{verbatim}
#include <plearn/math/TMat_maths.h>
using namespace PLearn;

int main(int argc, char** argv)
{

  // vector creation
  Vec b(3);
  b[0] = 2;
  b[1] = 42;
  b[2] = 21;
  cout<<b<<endl;

  // matrix creation
  Mat c(3,2);
  c(1,1)=1.0;
  c(1,0)=4.0;
  c(2,0)=5.0;
  c(0,1)=73.0;
  c(0,0)=78.0;
  c(2,1)=5.0;


  Vec d(2);
  transposeProductAcc(d,c,b);
  cout<<d<<endl;
  return 0;
}
\end{verbatim}

\subsection{Loading and saving}
You can load and save a Mat with the following code (note that it needs an 
include of VMat.h):
\begin{verbatim}

#include <plearn/math/TMat_maths.h>
#include <plearn/var/Var_all.h>
#include <plearn/vmat/VMat.h>
#include <plearn/db/getDataSet.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Mat c(3,2);
  c(1,1)=1.0;
  c(1,0)=4.0;
  c(2,0)=5.0;
  c(0,1)=73.0;
  c(0,0)=78.0;
  c(2,1)=5.0;

  // save into a pmat file
  c.save("save.pmat");

  // save into an amat file
  VMat vm(c);
  vm->saveAMAT("save.amat");

  // load from a file
  VMat vm2 = getDataSet("save.pmat");
    // it could have been "save.amat"
  Mat m = vm2.toMat();
  cout<<m;

  return 0;
}

\end{verbatim}



\section{How to create a PLearner?}

PLearner is the super class for learner. Here we describe how to create a PLearner. PLearner is a subclass of Object so if you want to know more about what you are doing, go to section \ref{Object}.

\subsection{First steps}
\begin{enumerate}

\item Type \texttt{pyskeleton PLearner MyLearner}

\item Edit the file MyLearner.h to add the correct field (int, Mat,
      etc.). Normally you don't have to add any methods.

\item Edit the file MyLearner.cc
  \begin{enumerate}
    \item  Add short and complete description in
    \texttt{PLEARN\_IMPLEMENT\_OBJECT}

    \item  Add the \texttt{declareOption} corresponding
    to the field you create in the \texttt{void
    MyLearner::declareOptions(OptionList\& ol)} method (don't forget
    to fill the help option). This will be used for saving and loading
    the PLearner.

    \item  If some fields derive from basic ones, don't add a
    \texttt{declareOption}, you have to implemement their building
    in the \texttt{MyLearner::build\_()} method.

    \item  If some fields are filled after training, add a
    \texttt{declareOption} with a OptionBase::learntoption option.

    \item  Edit the remaining methods, \texttt{pyskeleton} has included
    comments to help you.
  \end{enumerate}

\item Pray while launching a \texttt{pymake MyLearner.cc}.
\end{enumerate} 


\subsection{How to get the dataset?}
TODO

\subsection{How to manage the dataset?}
TODO


\subsection{If you need gradients on a cost function...}

Go read the section \ref{Var} and the section \ref{Optimizer}.

%----------------------------------------------------------------------
\chapter{Intermediate}
%----------------------------------------------------------------------

\section{Low-level concepts}

\subsection{Important compilation flags}
TODO: explication

\begin{itemize}
\item BOUNDCHECK or nothing
\item USEFLOAT or USEDOUBLE
\item LITTLEENDIAN or BIGENDIAN
\end{itemize}
 Default with Pymake and Linux is BOUNDCHECK, USEDOUBLE, \linebreak
LITTLEENDIAN.

\subsection{Smart Pointers}
\label{PP}
 Memory management is one of the most error-prone aspects of traditional
C and C++ programming. PLearn makes it easier through the use of
\emph{reference-counted smart pointers}.

 Traditionally, there are two basic ways an object can typically be created: 

\begin{itemize}
\item  on the stack:
\begin{verbatim}
void f()
{ // Beginning of scope
  MyClass myinstance; 
    // memory is allocated on the stack,
    // and constructor is called

  myinstance.dosomething();
    // methods and members are called using a dot

} // when exiting the scope, destructor of object is
  // called automatically and stack memory is freed
\end{verbatim}

\item  by calling new:
\begin{verbatim}
void f()
{ // Beginning of scope

  MyClass* ptr = new MyClass(); 
    // memory is allocated on the heap by the "new"
    // opearator, which returns a pointer

  ptr->dosomething(); 
    // methods and members are called using "->"

  delete ptr;
    // we have to call "delete" explicitly,
    // because object is NOT automatically destroyed
}   // when leaving the scope
\end{verbatim}

\end{itemize}
 In more complex cases, where several ojects may contain pointers to other objects, keeping track of when to delete an object quickly becomes a complex and error-prone bookkeeping task. 


 PLearn uses reference-counted smart pointers to automate this, so
that you don't have to worry about calling delete. It is based on a
\emph{smart pointer} template (PP which stands for PLearnPointer)
that can be used on any class that derives from SmartPointable. A
SmartPointable object contains the count of the number of smart
pointers that point to it, and is automatically destroyed when this
\emph{reference count} becomes 0 (i.e. when nobody any longer points
to it)

\begin{verbatim}
class MyClass: public SmartPointable;

void f()
{ // Beginning of first scope
  PP<MyClass> ptr = new MyClass();
    // memory is allocated on the heap
    // (reference count for object is 1)

  { // Beginning of second scope
    PP<MyClass> ptr2 = ptr;
      // ptr2 and ptr point to the same object
      // (reference count becomes 2)

  } // Object is not destroyed upon exiting the second scope 
    // (reference count becomes 1)

  ptr->dosomething();
    // methods and members are called using "->"

} // Object is automatically destroyed here 
  // when reference count becomes 0
\end{verbatim}

 It is possible to mix traditional pointers to an object with smart pointers, and there are automatic conversions between the two. However, in general we discourage doing this, although it might prove useful in some situations (such as to keep a pointer to the actual specific type of the object rather than its base-class). If you do mix them, just remember that the object will get deleted as soon as the last smart pointer pointing to it is gone (when it gets out of scope for instance), regardless whether there are still traditional pointers pointing to it (the automatic reference count can only counts smart pointers!). 


 Many base classes in PLearn have an associated smart pointer type
with a similar (and usually shorter) name, as shown in the following
table. Sometimes this corresponding smart pointer type is a simple
typedef to the type PP<\emph{baseclass}>. 

But we also often specialised them (by deriving PP<\emph{baseclass}>)
to add operators and methods for user convenience. So that, for
instance, element at row i and column j of a VMat m can be accessed
as m(i,j) as an alternative to the more verbose m->get(i,j).

\begin{tabular}{|c|c|}
\hline 
base class &smart pointer \\
 \hline 
VMatrix &VMat \\
 \hline 
Variable &Var \\
 \hline 
RandomVariable &RandomVar \\
 \hline 
Kernel &Ker \\
 \hline 
CostFunction &CostFunc \\
 \hline 
StatsIterator &StatsIt \\
 \hline 

\end{tabular}




 Several concepts in PLearn can be seen as having two levels of implementation: 
 \begin{enumerate}
\item  A base class and its derived classes form the basic internal working mechanism for the concept which can be extended by deriving new classes. We call this the \emph{designer level}
.
\item  A correponding smart pointer type for the base class, and a number of utility functions give a more user-friendly syntax to use the concept. They are mostly wrapping and syntactic sugar around the \emph{designer level}
 classes. We call this the \emph{user level}
\end{enumerate}
 
 The person who only wishes to use the library typically doesn't need to understand all the details of the designer level hierarchy. Some concepts (such as Var) can be manipulated almost entirely through the smart pointer type and user-level functions, although knowing the most useful methods of the uinderlying base class, and the role of each subclass certainly doesn't harm. 

\section{How to subclass a PLearn \Object}
\label{Object}

\subsection{\Object}

 PLearn defines an \Object\ class. There is not much to it. Its role
is mainly to standardise the methods for printing, saving to file, and
duplicating objects. Not all classes in PLearn are derived from Object
(many low-level classes aren't). But all non-strictly-concrete classes
(i.e. those with virtual methods) in PLearn derive from Object. This
includes the Learner base class.

\Object\ allows an easy support for a number of useful generic facilities:
\begin{itemize}
\item automatic memory management (through reference counted smart pointers: \Object\ derives from \PPointable)
\item serialization/persistence ({\tt read, write, save, load})
\item runtime type information ({\tt classname})
\item displaying ({\tt info, print})
\item deep copying ({\tt deepCopy})
\item a generic way of setting options ({\tt setOption}) and a generic
  {\tt build()} method (the combination of the two allows for instance
  to change the object structure and rebuild it at runtime)
\end{itemize}


\subsection{Creating a basic class deriving from Object}

First, you can use \texttt{pyskeleton}, a python script which creates automatically the .h and .cc files.

\texttt{pyskeleton Object Person} creates a class called Person derived from Object.

The first thing to do is to fill the .h file.

Example:

\begin{verbatim}
...

private:
  
  typedef Object inherited;

protected:
  // *********************
  // * protected options *
  // *********************

  // ### declare protected option fields 
  // ###  (such as learnt parameters) here
  // ...
    
public:
  // here we had the good things
  string firstname;
  int age;

\end{verbatim}

Then you just have to fill the \texttt{declareOptions} method in the .cc .

\begin{verbatim}
void Person::declareOptions(OptionList& ol) 
{
  // ### Declare all of this object's options here
  // ### For the "flags" of each option, you should typically
  // ### specify one of OptionBase::buildoption, 
  // ### OptionBase::learntoption or OptionBase::tuningoption.
  // ### Another possible flag to be combined with is 
  // ### OptionBase::nosave

  // ### ex:
  declareOption(ol, "firstname", &Person::firstname, 
                 OptionBase::buildoption,
                 "Help text describing this option");

  declareOption(ol, "age", &Person::age, 
                 OptionBase::buildoption,
                 "Help text describing this option");
// ...

  // Now call the parent class' declareOptions
  inherited::declareOptions(ol);
}
\end{verbatim}

\subsection{Setting option fields and calling build()}

There are several techniques to implement the facilities of finishing
building afterwards and named parameters.  In PLearn, we typically
use public option fields (or sometimes protected fields with setter
methods) and a public {\tt build()} method that does the actual
building. Think of those public fields as really nothing but named
constructor parameters, and {\tt build()} as the one and only true
constructor.

The building of {\em me} in the previous example could then look
as follows:

\begin{verbatim}
#include "Person.h"

using namespace PLearn;

int main(int argc, char** argv)
{
  Person me; // default constructor can set default values 
             // for the option-fields
             // for ex: suppose default profession is "student"
  me.firstname = "Pascal";
  me.age = 29;
  me.build(); // finalize the building process

  cout<<me.firstname; 
}
\end{verbatim}

Note that there has to be a default (empty) constructor, whose role is also
to set the default values of the parameters.


\subsection{A generic way of setting options from ``outside''}

Sometimes, you want to set options and build an object from some
form of interpreted language environment or from a text description,
etc. That is to say from ``outside'' a C++ program. For this, \PLearn\ 
provides the setOption method. Suppose {\tt Person} is a subclass of
\Object, then we could do the following:

\begin{verbatim}
#include <plearn/base/Object.h>
#include "Person.h"

using namespace PLearn;

int main(int argc, char** argv)
{
  Object *o = new Person(); // o is a smart pointer to an 
                            // object whose true type is Person
  o->setOption("firstname","Pascal");
  o->setOption("age","29");

  Person *p = dynamic_cast<Person*>(o);

  cout<<p->firstname;
}
\end{verbatim}

Note that {\tt setOption} takes 2 strings: the name of the option, and
its value serialised in string form. Strings are universal because
anything can be represented (serialized) as a string. Actually,
setOption calls a lower-level method called {\tt readOptionVal}
which reads the option value from a stream (a string stream in
this case\ldots) rather than a string. Similarly there is a {\tt
getOption} method which returns a string representation of a named
option, and whose implementation simply calls {\tt writeOptionVal}
on a string stream.


\subsection{Building an object from its specification in a file}

Building an object from a specification in a file is a natural
extension of the setOption/build mechanism.
Suppose we now have a file {\tt me.psave} containing the following text:

\begin{verbatim}
Person( firstname="Pascal"; 
        age = 29;
      );
\end{verbatim}

In the following code, we a way to build {\tt me} from its description
in the file.

\begin{verbatim}
#include <plearn/base/Object.h>
#include "Person.h"

using namespace PLearn;

int main(int argc, char** argv)
{

  Object* o = loadObject("me.psave"); 
  Person *p = dynamic_cast<Person*>(o);

  cout<<p->firstname;

  return 0;
}
\end{verbatim}


There are others ways to do that:

\begin{verbatim}
string filename = "me.psave";

// 1) The loadObject function
{
  Object *me;
  me = loadObject(filename);
}

// 2) What loadObject actually does
{
  ifstream in(filename.c_str());
  Object *me = readObject(in);
}

// 3) An alternative (loadObject actually calls Object::read)
{
  Person me; 
  ifstream in(filename.c_str());
  me.read(in);
}

// 4) An alternative using the global generic 
//    plearn::read function
{
  Object *me;
  ifstream in(filename.c_str());
  ::read(in, me);
}

// 5) What if we have the string representation at hand?
{
  // get the content of the file as a string
  // (function in fileutils.h)
  string description = loadFileAsString(filename);
  Object *me = newObject(description);
}
\end{verbatim}

Naturally, all that these functions do is parse the description in
the file, and call {\tt readOptionVal} (the lower-level equivalent
of {\tt setOption}) for each specified option, before finally calling
{\tt build()}.

Note that options may have arbitrarily complex types. They are not limited to strings and numbers; in particular they may
themselves be compex objects or arrays of things. For example:

\begin{verbatim}
Drawing(
  color = "blue";

  # path is an array of objects
  path = [ Line(x0=0, y0=0, x1=10, y1=20); 
           Line(x0=0, y0=0, x1=10, y1=20, width=2);
           Circle(x=20; y=30; radius=5.3, fill=true);
         ];
  );
\end{verbatim}

Finally, you should use a SmartPointable for Person, as seen before in \ref{PP}.

\begin{verbatim}
#include <plearn/base/Object.h>
#include "Person.h"

using namespace PLearn;

int main(int argc, char** argv)
{
   Object* o = loadObject("me.psave"); 
   PP<Person> p = dynamic_cast<Person*>(o);

  cout<<p->firstname;

  return 0;
}
\end{verbatim}


\subsection{Human description versus saved object} 

The {\tt me.psave} file in the previous section may have been produced
either manually by a human being, or automatically by calling 
\begin{verbatim}
plearn::save("me.psave",me);
\end{verbatim}
on a previously constructed {\tt Person me} object.

The mechanism for building an object is the same in both cases: it automatically calls a series of {\tt readOptionVal} followed by {\tt build()}. However the options specified in both cases are not always the same:

\begin{itemize}
\item A hand-written description file will typically be used to give a small number of options for the {\em initial building} of an object (with the other options taking their default value).
\item A file resulting from a saved object, will typically include {\em everything} that is necessary to reconstruct a new instance in the full and exact same state as the instance that was saved. This may include options, such as the learnt synaptic weights of a neural network, that are not given at the time of {\em initial building}, but only when {\em reloading} a serialised object.
\end{itemize}

We call the options typically used for initial building {\em \bf build options}, and the second type {\em \bf learnt options}. Note that the behaviour of the {\tt build} method may have to be quite different when we are {\em reloading} a saved object (and providing it with {\em learnt options}) from when we are only doing an {\em initial building} (and providing it only with {\em build options}). It is natural that our "one and only" constructor may have to behave differently depending on the parameters it is given, but it is important to keep in mind the distinction between {\em build options} on one hand, and {\em learnt options} that are only present whe reloading, on the other hand.

There is a third conceptual category of options, that we call {\em \bf tuning options}, which are used mostly to {\em tune} the object {\em after} an intial building. They often overlap with {\em build options}, but not necessarily, the distinction is nevertheless more conceptual than real. 





%----------------------------------------------------------------------
\section{Matrix-Vectors Operations with Gradients}
%----------------------------------------------------------------------
\label{Var}

\subsection{Introduction to Var}

 The class Var is at the heart of PLearn and aims at providing matrix-variables in the mathematical sense. It is built on top of the Mat class, that provides matrix-variables in the more traditional sense of sequential computer languages.
 
 Var should be used for Matrix-Vectors operations when you need gradients on operations. Otherwise, use Mat and Vec classes.
 
 NO NUMERICAL COMPUTATION IS DONE AT THIS LEVEL. The purpose of the Var definitions is only to build the symbolic relationship between mathematical variables. 

 One can write arbitarily complex expressions using many implicit or
explicit intermediary variables, and predefined functions such as
in: $w=exp(-(abs(sqrt(lambda)*v)/3.0))$.  This will construct an
internal representation, only with a larger number of intermediate
nodes to represent intermediate states (variables) of the calculations.

 Each Var contains two Vec fields. 
 
 One is called value and holds the current value assigned to that variable, and the other is called gradient and is used to backpropagate gradients with respect to another variable.
 
 Every Var has an fprop() method that updates its value field according to the value field of its direct parents.
 
 Every Var also has a bprop() method that updates the gradient field of its direct parents according to its own gradient field (backpropagation algorithm). Note that it \emph{accumulates} gradients into its parents gradient field. 

 Example: 
 
\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var v(3,2); // declares a Variable of size 3x2
  Var lambda(1,1); // declares a scalar Variable

  v->matValue(1,0)=4.0;
  v->matValue(2,0)=5.0;
  v->matValue(0,1)=73.0;
  v->matValue(0,0)=78.0;
  v->matValue(2,1)=5.0;

  cout << v->matValue << endl;

  lambda->value = 2.0;

  Var w = lambda*v;

  w->fprop();

  cout << w->matValue << endl;
  return 0;
}
\end{verbatim}


 If the expression to be calculated involves intermediate variables, fprop must be called in a correct order on all those intermediate variables before it can be called on the result variable we are interested in. For example, suppose we have $z=dot(x,tanh(y))$ where $x,u \in R^3$.

 
 A Var builds a directed acyclic graph whose nodes are Var's, with the following structure: 
\nopagebreak
\begin{verbatim}

 x    u                           x
  \   |                           |   
   \  |                           |  
    \ |                           |  
     \|                           |  
     [+]                          |
      |                           |           
      y ---> tanh() --> w  -----> dot----> z

\end{verbatim}

 To obtain the correct value of z as a function of x and u, after setting x->value and u->value, we need to perform fprop on all the intermediate nodes as well as z. 

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var x(3,1);
  Var u(3,1);

  x->matValue(0,0)=1;
  x->matValue(1,0)=2;
  x->matValue(2,0)=3;
  u->matValue(0,0)=4;
  u->matValue(1,0)=5;
  u->matValue(2,0)=6;

  cout<<x->matValue<<endl;
  cout<<u->matValue<<endl;

  Var y = x + u;
    // y is also a 3x1 matrix
  Var w = tanh(y);
  Var z = dot(x,w);
    // z is a scalar variable result of the dot product 
    // of x and tanh(y)

  cout<<z->matValue<<endl;
  y->fprop();
  w->fprop();
  z->fprop();
  cout<<z->matValue<<endl;

  return 0;
}
\end{verbatim}

 To simplify the computation of values and gradients in a graph of
Var's, we use a VarArray (don't forget the include).

 A VarArray is simply an array of Vars, which has a method {\tt
fprop()} and a method {\tt bprop()} which calls the {\tt fprop()}
(resp. {\tt bprop()}) methods of all the elements of the array in the
right order (note that a right order for {\tt bprop} is the reverse of
the order for {\tt fprop}). The above function finds all the Var's on
the paths from the the inputs Vars to the output Var. There are may
be several input Vars so they are put in a VarArray. Once the path
is obtained, we can propagate values through it with the fprop method:

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var x(3,1);
  Var u(3,1);

  x->matValue(0,0)=1;
  x->matValue(1,0)=2;
  x->matValue(2,0)=3;
  u->matValue(0,0)=4;
  u->matValue(1,0)=5;
  u->matValue(2,0)=6;

  cout<<x->matValue<<endl;
  cout<<u->matValue<<endl;

  Var y = x + u;
    // y is also a 3x1 matrix
  Var w = tanh(y);
  Var z = dot(x,w);
    // z is a scalar variable result of the dot product
    // of x and tanh(y)

  cout<<z->matValue<<endl;

  VarArray path = propagationPath(x & u, z);
  path.fprop();

  cout<<z->matValue<<endl;
  return 0;
}
\end{verbatim}

 In the previous, the \texttt{VarArray} is useful but not essential. Let consider the following example:

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var x(3,1);
  Var u(3,1);

  x->matValue(0,0)=1;
  x->matValue(1,0)=2;
  x->matValue(2,0)=3;
  u->matValue(0,0)=4;
  u->matValue(1,0)=5;
  u->matValue(2,0)=6;

  cout<<x->matValue<<endl;
  cout<<u->matValue<<endl;

  Var z = dot(x,tanh(x+u));
    // z is a scalar variable result of the dot product
    // of x and tanh(y)

  cout<<z->matValue<<endl;

  VarArray path = propagationPath(x & u, z);
  path.fprop();

  cout<<z->matValue<<endl;
  return 0;
}
\end{verbatim}

 This example performs exactly the same thing as the previous one. But in this case, we don't have any reference to the previous \texttt{Var y,w} to do \texttt{fprop()}. That's why a \texttt{VarArray} could be essential.
 
 You can also use  \texttt{y->fprop\_from\_all\_sources()} instead of a \texttt{VarArray} but this reconstruct the path each time and so don't store it. It's not efficient for a multi fprop and it's not possible to back-propagated gradients.

 Once we have this path, we can also back-propagated gradients. For example, if we set the gradient of z to 1,

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var x(3,1);
  Var u(3,1);

  x->matValue(0,0)=1;
  x->matValue(1,0)=2;
  x->matValue(2,0)=3;
  u->matValue(0,0)=4;
  u->matValue(1,0)=5;
  u->matValue(2,0)=6;

  cout<<x->matValue<<endl;
  cout<<u->matValue<<endl;

  Var y = x + u;
    // y is also a 3x1 matrix
  Var w = tanh(y);
  Var z = dot(x,w);
    // z is a scalar variable result of the dot product
    // of x and tanh(y)

  cout<<z->matValue<<endl;

  VarArray path = propagationPath(x & u, z);
  path.fprop();

  cout<<z->matValue<<endl;

  z->gradient = 1.0;
  path.bprop();
  cout << "dz/dx = " << x->gradient << endl;
  cout << "dz/du = " << u->gradient << endl;

  return 0;
}
\end{verbatim}

 We obtain the partial derivatives of z with respect to x and u in their
 gradient field.


\subsection{Creating}

You can create Var with several methods.
The main are:
\begin{verbatim}
  Var(int the_length, int width_=1);
  Var(int the_length, int the_width, const char* name);
  Var(const Mat& mat);
\end{verbatim}

The last one id used as in the following example:
\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>
using namespace PLearn;

int main(int argc, char** argv)
{
  Mat mx(3,1);
  mx(0,0) = 1;
  mx(1,0)=2;
  mx(2,0)=3;
  Var x(mx);
  cout<<x->matValue<<endl;
  return 0;
}
\end{verbatim}

\subsection{Manipulating}

In the introduction to Var, you saw how to manipulate them.

Don't forget that all is symbolic (it will tricks you).

You can find numerous var in \texttt{PLearn\/plearn\/var}, some are shortcuted by overloaded operators (such as +).

\subsection{Loading and saving}

\subsubsection{Only the value}

With the following method, you can load and save THE VALUE of a var (not the symbolic path). 
\begin{verbatim}
#include <plearn/vmat/VMat.h>
#include <plearn/db/getDataSet.h>
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var y(3,1);
  y->matValue(0,0)=1;
  y->matValue(1,0)=2;
  y->matValue(2,0)=3;
  cout<<y->matValue;

  // save into a pmat file
  y->matValue.save("save.pmat");

  // save into an amat file
  VMat vm(y->matValue);
  vm->saveAMAT("save.amat");


  // load from a file
  VMat vm2 = getDataSet("save.pmat");
    // it could have been "save.amat"
  Var x(vm2.toMat());
  cout<<x->matValue;
  return 0;
}
\end{verbatim}

\subsubsection{All the var}

Var is a subclass of Object, so you can use the methods of Object
as in the following example. Note that it will save all the Var,
including the sub ones.

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Var x(3,1);
  Var u(3,1);

  x->matValue(0,0)=1;
  x->matValue(1,0)=2;
  x->matValue(2,0)=3;
  u->matValue(0,0)=4;
  u->matValue(1,0)=5;
  u->matValue(2,0)=6;

  cout<<x->matValue<<endl;
  cout<<u->matValue<<endl;

  Var z = dot(x,tanh(x+u));
    // z is a scalar variable result of the dot product
    // of x and tanh(y)

  cout<<z->matValue<<endl;

  VarArray path = propagationPath(x & u, z);
  path.fprop();

  cout<<z->matValue<<endl;

  save("z.psave",z);

  Object* o = loadObject("z.psave");

  // There is no PP<> nor * here,
  // because Var is already a PP<Variable>
  Var p = dynamic_cast<Variable*>(o);

  cout<<p->matValue<<endl;

  return 0;
}
\end{verbatim}


\subsection{Func}

In order to make the usage of Var more friendly, you can use Func. The Func class is mode for those who want to make fprop on different values of Var in an elegant way. The two following examples illustrate this: they do exactly the same thing, but the first one without Func and the second one with.

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Vec a(3),c(1);
  Vec da(3),dc(1);

  // Without Func
  Var x(3,1);
  Var y = dot(x,tanh(x));
    // y is a scalar variable result of the dot product
    // of x and tanh(x)
  VarArray path = propagationPath(x,y);

  a<<"1 2.3 4";

  x->value<<a;
  path.fprop();
  c=y->value;
  cout<<a<<endl;
  cout<<c<<endl;

  a<<"4 8.3 -12";
  x->value<<a;
  path.fprop();
  c=y->value;
  cout<<a<<endl;
  cout<<c<<endl;

  dc<<2.3;
  y->gradient<<dc;
  path.bprop();
  da<<x->gradient;
  cout<<dc<<endl;
  cout<<da<<endl;

  return 0;
}
\end{verbatim}

With Func:

\begin{verbatim}
#include <plearn/var/Var_all.h>
#include <plearn/math/TMat_maths.h>

using namespace PLearn;

int main(int argc, char** argv)
{
  Vec a(3),c(1);
  Vec da(3),dc(1);

  // With Func
  Var x(3,1);
  Var result(1,1);
  Func f(x, result ,dot(x,tanh(x)));
    // z is a scalar variable result of the dot product
    // of x and tanh(y)

  a<<"1 2.3 4";
  f->fprop(a,c);
  cout<<a<<endl;
  cout<<c<<endl;

  a<<"4 8.3 -12";
  f->fprop(a,c);
  cout<<a<<endl;
  cout<<c<<endl;

  dc<<2.3;
  f->fbprop(a,c,da,dc);
  cout<<dc<<endl;
  cout<<da<<endl;

  return 0;
}
\end{verbatim}


\chapter{Advanced}

\section{RandomVar}

\section{Function-like types}
\subsection{Ker}
\subsection{CostFunc}
\subsection{StatsIt}
\section{Optimizers}
\label{Optimizer}

%% plus a jour au niveau des repertoires 
% \section{Learning algorithms}
% 
%  While all the previously mentionned classes are to be found in the
%  PLearnLibrary/PLearnCore directory, the higher level learning algortihms
%  are to be found in PLearnLibrary/PLearnAlgo
% 
\section{ Miscalleanous utilities}

 The PLearnLibrary/PLearnUtils directory contains classes and
functions to perform various useful things such as graphically
displaying things. The Scripts directory contains a number of
perl-scripts and also binary programs to both help manage the
source-tree, and to manipulate matrix files.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{ PLearn coding guidelines and philosophy}

 Several people wrote significant parts of PLearn, and if you take a
closer look at the code, you will see a number of clearly different
coding styles and philosophies. However, as of this writing (09/2000),
the overall design and organization of most of the library is still to
be blamed (or praised\ldots) on me. So these remarks are my personal
view of things, and do not necessarily reflect the opinion of everybody
on the PLearn developer team, but I hope it will help you understand
the reasons why things are the way they are, and hopefully have you
choose to keep them that way\ldots

 Pascal 

\section{A few words on C++}
 Agreed, C++ \emph{can be} a very complex language. The main reason
being that it is extremely feature-rich, but that is also what
makes C++ so powerful and expressive, and thus appropriate for a
machine-learning library. Yet I insist on the \emph{can be} : it
doesn't always have to be, it depends a great deal on what features
you choose to use and when.

 People who discover C++ tend to first be overwhelmed with its wealth
of features, and then seem to want to use them all at once in even the
simplest piece of code (complex templates, deep multiple inheritance
trees, exceptions, multiple nested namespaces; add multi-threading on
top of that and you're sure to write the most unreadable, unportable
and compiler-bug trigerring error-prone code ever). Finally, after
great intellectual efforts, they discover that even their compiler
(not to mention their debugger!) has trouble understanding it all
and, if they manage to have it swallow the code, they realise that
no other compiler will (portability anybody?). This is still quite
true as of this writing (09/2000) and was even more so a few years
ago, yet tools will keep improving until some day, hopefully, they
all behave perfectly by the book, according to the standard, but
until this blessed day comes, beware\ldots\ Many people then give up,
frustrated, and decide to go back to C, which is a shame. C++ \emph{is}
a much better language than C, especially for writing Object Oriented
code, and it \emph{does} make the programmer's life much easier\ldots\
as long as \emph{you} keep things simple.


 So please, especially if you're a beginner, keep this in mind
when writing C++ code: having so many ``cool'' features in the language
doesn't mean that you must use them all at once. Choose wisely and,
if in doubt, always prefer the simplest solution\ldots

\section{Design goals and priorities}

 Any project implicitly or explicitly sets some goals and these
directly influence the way code is written. With PLearn, one of the
founding goal, was to be able to describe complex machine-learning
experiments by assembling simple building-blocks directly in C++,
without resorting to a layer of home-grown dedicated language (as
experience had proven us that it is hard to grow and maintain such
a language, which appears always too limited anyway). Obviously
we also want to have them run efficiently (hence the choice of C++
rather than a higher level interpreted language).

 Any system should ideally be simple to understand and use, lightning
fast, and extremely geneal. Yet there is always a tradeoff to be made
between these 3 highly desirable characteristics. Here is the priority
I gave them, in the design of the library, it logically follows from
the project's primary goals:

\begin{enumerate}
\item  readability, simplicity, ease of use (and portability)
\item  computational efficiency
\item  genericity
\end{enumerate}

\section{Usage of C++ features in PLearn}

 As I mentionned earlier, moderation is good in everything, including in
 moderation\ldots\ ;) 

\subsection*{Function and method prototypes without parameter names}
 C++ code is typically divided between .h files which contain class
layout, function and method prototypes, and .cc files which contain the
actual implementation. Ideally, it should be possible to understand
what a method or function does by looking it up only in the .h
file. Comments are part of achieving this, but having a meaningful
name for the parameters of the function also helps a great deal.

 C++ allows you to omit parameter names in prototypes (and only
give their types). This defies the purpose of clarity, and is thus
considered bad practice by the author and in PLearn in general. Except
for possible default values (that are to appear only in the .h),
the prototype in the .h file should be identical to the definition
in the .cc file and include parameter names.

 (i.e. people usually have trouble understanding what float* f(float*,
int, int, char, char*, float); is supposed to do, and defining a new
type for each argument is \emph{not} the right way of making this
more understandable\ldots\ giving them a meaningful name is.)

\subsection*{Basic data types}
 Conceptually, people usually think of 3 simple basic data types:
integers, reals, and booleans (possibly 4 if you add character). C++
has them in many flavours, including signed and unsigned, several
precisions, etc. These all have their use from a low-level hardware
perspective (which woud have been much better if they had been given
standard byte sizes by the standard\ldots), but to the mathematically
minded library-user they are an annoyance. So throughout most of
PLearn, unless otherwise dictated by low-level precision or space
considerations, we use only 3 types that correspond to the 3 concepts:

\begin{itemize}
\item \textbf{int} is used for integers
\item \textbf{bool} is used for booleans
\item \textbf{real} is used for reals

{\tt real} is defined throughout the whole library to be either {\tt
float} or {\tt double}, depending on a compilation flag (USEDOUBLE
or USEFLOAT).
\end{itemize}

 Also we encourage people \emph{not to} define a new type if it
conceptually corresponds to one of those three concepts, in particular
I for one (and I'm surely not alone) dislike to have to write\\
\texttt{namespace::subnamespace::classname::interiorclass::length\_type}\\
when the damn thing is just an integer, if you get my point. Please
use int, it saves the user keystrokes, code lookup time, and
eases understanding (i.e.: genericity-\,- but simplicity++ and
ease\_of\_use++, see section on desing priorities above).

 The use of unsigned int types is also a source of annoyance to me,
and of potential nasty bugs. Ex:
\verb!for (unsigned int i=10; i>=0; --i)!

So again, unless you really need the extra bit of precision,
use int (also saves a few keystrokes).

 A kind of string type is also usually seen as part of the set of basic
types, but we'll discuss this in the section on the standard library.

\subsection*{Namespaces}
 Namespaces are most useful to prevent name clashes between different
libraries. So ultimately, all of PLearn is to reside in the PLearn
namespace. However gdb currently seems to have trouble coping with
them, so the namespace directives are currently surrounded by ugly
\#ifdef USENAMESPACE which we usually keep undefined.

 Also, for now, I do not encourage the use of sub-namespaces to
organize the code within PLearn (with or without \#ifdefs). It's
already hard enough to get the organization right in terms of
concepts, class hierarchies, and files, without introducing yet
another hierarchy of things (which besides, would go mostly untested
as we always compile with USENAMESPACE undefined, for now anyway).

\subsection*{Exceptions and runtime errors}
 Exceptions can be a nice and useful feature, allowing you to build
sophisticated error recovery mechanisms and the like\ldots\ But
designing a consistent error-recovery scheme with an appropriate
exception class hierarchy is a complex task. Besides in PLearn, we
typically have no use for a sophisticated error recovery mechanism:
a runtime error is always a sign of a bug somewhere, and the policy
in PLearn is to never try to second-guess the programmer: all we want
is for the program to abort immediately with a somewhat meaningful
message, and the debugger to be able to trace the call. Unfortunately,
as of this writing, exceptions are poorly supported by debuggers
(and they can create a nightmare in multi-threaded code).

 So essentially we don't use exceptions in PLearn, but a very simple
runtime error mechanism: \texttt{error("my meaningful error message");}
will result in a call to function {\tt errormsg} that simply prints out
the message and exits the program. Thus it is easy to set a breakpoint
in {\tt errormsg} in the debugger and trace what happened. This is
a no-fuss solution that does the job. Notice that the {\tt errormsg}
function can easily be modified to throw an exception if you wish to
do a proper error recovery (in case brutally exiting the program is
not an acceptable behaviour).

 Exceptions can also be useful for other things, but for typical
runtime-errors, please use {\tt error(\emph{errormsg})}.

\subsection*{Templates}
 Templates is one of the most powerful features of C++. But it's also
the most complex, and the one with which compilers and debuggers
have the most trouble (almost all but the simplest template code is
hardly portable across compilers because of inconsistencies between
them, and it was much worse a few years back!). The early versions
of PLearn deliberately did not use \emph{any} template code at all
(many other librariy designers out there for whom portability was a
major concern made the same choice).

 As the compilers improved, I started allowing myself to use
\emph{simple} templates for things where they were \emph{really}
appropriate, (i.e. smart pointers and generic containers). And I
would recommend everybody to stick to this. Please, \emph{refrain}
from using templates as much as possible: it will make your code
easier to write, to read, to debug, to port, to understand, and
also faster to compile. It's usually easy to later ``templatize'' a
working and well-tested non-templated code if really needed. But it's
always annoying to have to ``de-templatize'' a complex template code
because the compiler on your new target platform cannot understand it
(chances are that you won't either).

\subsection*{Multiple inheritance and complex class hierarchies}
 Multiple inheritance poses a number of technical problems and a multiple
inheritance tree is also usually more difficult to understand
conceptually. Therefore, PLearn uses only single inheritance and I would
like to keep it that way. The only kind of ``multiple inheritance'' that we
have is for inheriting \emph{interfaces } (\`a la Java) i.e. abstract
classes with only purely virtual methods.

Also we often use concrete classes, and in general prefer flat class
hierarchies than very deep ones, as they are easier to comprehend.


\subsection*{const}
 const is number one on my list of C++ annoyances. But unfortunately
there is no way to really do without it, so try to use it consistently,
and try not to get too frustrated in case of code constipation,
pardon me, const problems\ldots\ there is always a (hopefully clean)
way around them.


\subsection*{public, private, protected}
 There are probably too many class members that are public in
PLearn. But, as we love our potential library users (they are mostly
us for now anyway), we tend to avoid paranoia, and to trust them
for not doing dirty things with our not-so-private members. Hell,
they have access to the source code anyway!

\section{Usage of the C++ standard library in PLearn} 

 In early versions of PLearn, we did not use much of the standard
library (as no compilers yet agreed on a standard), except for
iostreams. Now that there is a well established standard, and that
all compiler makers are working towards conforming to it, we are
slowly moving PLearn to using more of the standard library facilities.


\subsection*{Strings}
 Many places in PLearn still use char* to represent strings,
but they'll slowly be changed into using the std::string class
instead. Please use string from now on. Feel free to change any usage
of char* you meet into string.

 A number of useful additional functions for user-friendly string
manipulation can be found in file PLearnCore/stringutils.h A brief
(and certainly not up to date) description of it, as well as a pointer
to a quick overview of the basic string operations can be found here.

\subsection*{Streams}
 Several pieces of old PLearn code still use the C stream library
(FILE* \ldots), but the standard C++ stream facilities is the
officially approved way to go for new code.


\subsection*{Standard containers and algorithms}
 It's now OK to use STL containers wherever appropriate. Two other
generic containers were previously developed for PLearn: Array is
heavily used, and is a base class for a number of other specialised
array types, so it is not likely to vanish any time soon (although
I may have it derive from {\tt std::vector} one of these days). The
main advantage of Array over {\tt std::vector} is that runtime
bound-checking can be turned on or off with a compilation flag
(BOUNDCHECK), and there's also a user-friendly (but inefficient)
syntax to build arrays from simple elements using the \& operator. Hash
may also be progressively abandoned in favour of std::map, hash\_map
(is this one part of the C++ standard?) and the like\ldots


\section{Naming conventions}

 The following naming conventions are used throughout PLearn. They
are mostly inspired by the Java naming conventions. Anybody who
uses or wishes to extend PLearn should be aware of them (as it makes
understanding of the code easier) and try to respect them (as it will
make the understanding of their code easier to other people who will
have the privilege to dig into it).

\subsection*{To make it short and simple:}

\begin{itemize}
\item {\tt MyClassName}
\item {\tt myMethodName()}
\item {\tt my\_variable\_name} \emph{OR }
      {\tt myvariablename} \emph{(both for member variables or otherwise)}

\item {\tt my\_global\_function()} \emph{OR}
      {\tt myGlobalFunction()}
\item {\tt MY\_CONSTANT}  \emph{(for \#define constants or other)}

\end{itemize}

\subsection*{Remarks:}

\begin{itemize}
\item  A classname should always start with an uppercase.
\item  Methods, functions, and variable names should always start with a lowercase.
\item  Underscores(\_) should never be used in class names or method names.
\item  Typical methods that return a bool status should begin with is or has. Ex: {\tt isEmpty()} {\tt isNull()} {\tt hasChildren()}.
\item  In case you want to provide a read-only accessor method to a protected or private member variable, use {\tt varname\_} for the member variable and {\tt varname()} for the accessor method.
\item  The arguments of a constructor often carry initial values for member variables. We usually name the argument in the constructor `the\_varname' so that it doesn't clash with the targetted member variable (which is just `varname')

\end{itemize}

 A few reasonable exceptions are tolerated throughout the code (such as
function P for probability instead of a lowercase p, or a member
variable K for a kernel matrix\ldots) But exceptions that don't serve
any purpose should not be!

\section{Final word}

 The PLearn library is far from perfect, it still has a lot of
rough edges (my to-do list is growing every day), and there are
several things that I would do differently if I was to start all
over again. But it is nevertheless already a very usable tool, that
for the most part, I feel, meets its primary design goals. Besides I
consider good code design an iterative process: one starts with an
initially rough version and iteratively refines it under the light
of real-world experience. The code base is not carved in stone, it
is an evolving being, and the source code is there so that you can
tweak it and adapt it to your needs, and hopefully help make it better.

\chapter{Debugging}

 There are several types of problems you'll encounter, and each has a
proven solving technique.

\section{Compilation problems}

{\bf Solution: } learn how to program in C++

 No, I mean seriously, learn C++, {\em thoroughly}, until you are
able to truly and fully understand every single bit of the cryptic
message issued by the compiler, and why on earth it may have chosen
to insult your intelligence with it. Because that cryptic message
always contains the solution.

 In particular, you need to really understand the difference between
a const thingy and a non-const thingy, because to C++ they are often
two totally different beasts (although to a decent human, they may
look the same at first inspection).

 So make sure you truly understand {\em all} the subtle differences
between for ex.: \\
\verb!const char* MyObj::mymethod(const char* &foo, const int& bar)!  \\
and
\verb!char* MyObj::mymethod(const char *const foo, int& bar) const! \\


 On rare occasions, you might occasionaly stumble upon a compiler
{\em bug} (as in {\em compiler internal error!!!} ), in which case
you may try the following: upgrade your dusty compiler to the newest
less-buggy version; check on google to see if anybody else had the
same problem and if they found a workaround; try to find a workaround
yourself (split your call in several pieces, using intermediate
variables, add a cout here, reorder the instructions there\ldots\ 
and pray!); try posting an SOS on the appropriate newsgroups; write
a bug report! Somebody somewhere, is responsible for it and might be
interested in fixing the mess, or already has\ldots


\subsection{Frequently encountered compilation errors}

To save you some time, you may look up in the following list if
somebody stumbled upon the same problem.

\begin{itemize}

\item {\bf typical error msg } \\ 
explanation and fix.

\end{itemize}



\section{Linking problems}

Problems reported by the linker can have several causes:

\begin{itemize}
\item It doesn't find a function that's supposed to be defined somewhere in
  your code but isn't.  A frequent case is that of instantiating an object
  of a class derived from a base class with a pure virtual mamber function
  that you forgot to define in the subclass. Another case is declaring a
  function in the .h and forgetting to implement it in the .cc, or (more
  often) implementing it with a slightly different signature (forgot
  Classname:: ?, forgot to put a const somewhere?)
\item It doesn't find symbols because it doesn't find the required
  libraries. Examine the linking command, are all the necessary libraries there? Are they
  indeed located where you say they are? There should be no space between the
  -L and the library path.
\item Libraries are specified in an inappropriate order. A library that
  depends on another library should appear before it in the linking
  command; the most basic libraries should be last.
\end{itemize}



\section{Clean runtime errors}

What I mean by clean runtime errors, is that the program displayed a nice
error message and exited.

This most likely means that something in your program caused a call to the
PLERROR macro, which called the {\tt errormsg} function, which threw a
PLearnException, which got caught in the very external try/catch of your
main program, which printed it out (you main program {\em does} catch
PLearn exceptions and report them, doesn't it???).

Tracing the problem is easy: 
\begin{itemize}
\item Launch your favorite debugger ({\tt gdb}) from within your favorite 
development environment ({\tt emacs}). 
\item Put a breakpoint in the {\tt errormsg} function by typing: \\
\verb!br 'PLearn::errormsg(!{\it TAB} \\ 
Pressing the {\it TAB} key will complete the
signature of the function for you. Note that the single quote at the beginning is important for this to work.
\item {\tt run} your program until it reaches the breakpoint.
\item trace {\tt up} the call stack and figure out what and why it happens.
\end{itemize}

{\bf Hints for using gdb:} \\
{\tt gdb} is always at quite a lag behind, playing catch-up with the latest compiler. Sot it {\em has} problems.
Here are a few hints for working with it, or in spite of it\ldots
\begin{itemize}
\item printing a {\tt std::string} doesn't work. Cast it to a {\tt char*} first, as in \verb!p (char *) my_string!
\item {\tt gdb} often seems lost when you attempt to examine the insides of a complex
  object, replying that it can't find info on that class.  In this case,
  unfortunately, you'll have to insert instructions in the code to print the desired debug info
  (with \verb!cerr << ...!), recompile and rerun gdb.
\item If you want to see an object on which you have a {\tt PP} smart
  pointer (or similar type), you can access the raw pointer inside (it's
  called {\tt ptr}!), for ex: \verb!p my_var.ptr->value.length_!
\end{itemize}

I also suggest you learn using a good integrated development
environment (IDE) like Emacs. Emacs has multiple windows, a compilation
mode (pressing return on an error will bring you directly to the
problematic line of the problematic file), and a gdb mode (with
which you can easily follow the step by step execution, as an arrow
is always displayed before the next instruction to be executed, and
you can rapidly put a breakpoint (Ctrl-X SPACE) anywhere).

With the proper key definitions (learn how to define your own keys for
maximum efficiency!), a complete recompile of your code, and reload in
gdb is just one key away.  You won't have to touch the rat. And yes,
it even all works perfectly fine (multiple windows and all) inside
a {\em single} text terminal over a telnet connexion for ex. (invoke
it using \verb!emacs -nw!).


\section{Dirty runtime errors}

By this, I mean {\tt segmentation fault} and the like.

\begin{itemize}
\item First try running your code in {\tt gdb}, as above.
\item If this doesn't appear too helpful on its own (and probably won't),
  try running your program with {\tt valgrind}. It's a great tool for
  catching memory bugs (like writing or reading from memory areas you never
  allocated or initialized.). You can run it like that, from a shell: \\
  \verb!valgrind --gdb-attach=yes your_prg_and_its_args!
\end{itemize}



\chapter*{License}

This document is covered by the license appearing after the title page.

The PLearn software library and tools described in this document are
distributed under the following BSD-type license:

\begin{verbatim}

Redistribution and use in source and binary forms, with
or without modification, are permitted provided that the
following conditions are met:

  1. Redistributions of source code must retain the above
     copyright notice, this list of conditions and the
     following disclaimer.

  2. Redistributions in binary form must reproduce the above
     copyright notice, this list of conditions and the
     following disclaimer in the documentation and/or other
     materials provided with the distribution.

  3. The name of the authors may not be used to endorse or
     promote products derived from this software without
     specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY
EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
\end{verbatim}



\end{document}

