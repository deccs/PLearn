*1 ->BestAveragingPLearner(
learner_set = 5 [ *2 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = 2 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *3 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = 26 [ -0.906541406139044992 0.146415828902817624 -5.56578543204617215 -8.49499339741810289 0.522322174668725436 -1.13728497684963448 -1.16277362992203015 2.28603427175091412 -3.88097762731107654 0.662245075628264512 0.798320427989005932 -0.89660271226220678 -35.8939158294708136 0.158153793435415718 0.394923480650437697 -0.677413931361911192 -0.17023792622007311 10.8094372765771727 -1.09400148531677877 -26.2502164312712161 -0.203763217724730855 46.9753955441009765 0.516044837851629246 46.5925734657042483 -0.536670498966404841 -35.4560612791219896 ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/learner_0/" ;
seed = 1827 ;
stage = 101 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
*4 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = 2 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *5 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = 26 [ 4.93085120161816892 0.185254469187674492 -2.42089914425088892 -1.40088912897902707 0.341122241513307556 0.477036090124903278 1.15596484387416343 0.423312349566668633 0.69463032542311709 -0.611534874762301173 -1.2173491589966976 0.38980148818223781 4.35414858884758438 -0.0510323548204374214 -5.55152751737527073 7.98226199893536315 0.159736692587359785 16.549180896093084 1.67520488990206817 69.3826307594103611 -0.758027933954183109 -80.2144479833933985 1.41835929965043817 71.8371196527344722 0.981956155264107289 43.2188750567595434 ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/learner_1/" ;
seed = 1828 ;
stage = 101 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
*6 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = 2 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *7 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = 26 [ 11.4739383071553505 -0.807536706736800114 -12.3725593444659943 1.31656828638196544 31.4994251080105379 -0.641468634527297521 0.598030607968257022 -1.18768845553213231 -16.2510861339365675 -4.46663897212369054 -0.706690728362407206 -0.812703389316712155 -3.4145987392371433 -49.9770542540211054 -3.39074438442094728 -16.1534939928362888 -0.323555568106629277 10.2711128234135902 0.682277765370439604 -46.7380193527012509 -0.457559494892429475 -7.95756475597913848 -0.837358120897119806 -31.5297246477977957 -0.794213932356969576 -20.4071222813349316 ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/learner_2/" ;
seed = 1829 ;
stage = 101 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
*8 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = 2 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *9 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = 26 [ -2.12802559906056032 -0.081622438844817638 -0.406657539204947738 -1.11943087803049712 -1.64083985134614152 -0.514648414877513782 -0.30973875073864271 0.804587992842245359 -12.0374316320833064 0.520696163775043908 -2.17963946503474926 -4.97640819579939642 -126.693935059827908 0.0629434483832102959 -23.9509019857847569 -42.0937618711373176 0.00989154238095888913 11.0659888067516317 -0.760645349483056288 -12.4381713960506861 -0.971169900919895968 80.5687997426314411 -1.50430083553928373 -57.7659017755213569 0.526831611763645791 32.7719592755566893 ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/learner_3/" ;
seed = 1830 ;
stage = 101 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
*10 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = 2 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *11 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = 26 [ -3.35783765987458693 -1.08985405179403649 0.41726694866285885 -0.547515370187856454 -1.5967723156412299 1.07748790980217724 -0.144836906296251428 -0.134977068726146177 0.341785506486624535 -0.30216779080104722 0.210766022485035232 -2.3979734666415764 0.390367709306769006 -0.186825940357352421 0.15868763452799764 -27.4631883506189389 -0.00245120245528429679 9.22248948072370389 0.140255508784604271 45.7355311896603212 -0.520325776407888907 -46.4134363783896973 1.11968577120682244 40.5636528010930419 -0.0788543812936937649 8.78598429800281266 ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/learner_4/" ;
seed = 1831 ;
stage = 101 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
] ;
learner_template = *12 ->NNet(
nhidden = 4 ;
nhidden2 = 0 ;
noutputs = -1 ;
weight_decay = 9.99999999999999955e-07 ;
bias_decay = 0 ;
layer1_weight_decay = 0 ;
layer1_bias_decay = 0 ;
layer2_weight_decay = 0 ;
layer2_bias_decay = 0 ;
output_layer_weight_decay = 0 ;
output_layer_bias_decay = 0 ;
direct_in_to_out_weight_decay = 0 ;
penalty_type = "L2_square" ;
L1_penalty = 0 ;
fixed_output_weights = 0 ;
input_reconstruction_penalty = 0 ;
direct_in_to_out = 0 ;
rbf_layer_size = 0 ;
first_class_is_junk = 1 ;
output_transfer_func = "none" ;
hidden_transfer_func = "tanh" ;
cost_funcs = 1 [ "mse" ] ;
classification_regularizer = 0 ;
first_hidden_layer = *0 ;
first_hidden_layer_is_output = 0 ;
n_non_params_in_first_hidden_layer = 0 ;
transpose_first_hidden_layer = 0 ;
margin = 1 ;
do_not_change_params = 0 ;
optimizer = *13 ->ConjGradientOptimizer(
verbosity = 100 ;
expected_red = 1 ;
no_negative_gamma = 1 ;
sigma = 0.100000000000000006 ;
rho = 0.0500000000000000028 ;
constrain_limit = 0.100000000000000006 ;
max_extrapolate = 3 ;
max_eval_per_line_search = 20 ;
slope_ratio = 10 ;
nstages = 1  )
;
batch_size = 0 ;
initialization_method = "uniform_linear" ;
paramsvalues = TVec(0 0 *0 )
;
expdir = "" ;
seed = -1 ;
stage = 0 ;
n_examples = -1 ;
inputsize = -1 ;
targetsize = -1 ;
weightsize = -1 ;
forget_when_training_set_changes = 0 ;
nstages = 101 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
;
initial_seed = 1827 ;
total_learner_num = 5 ;
best_learner_num = 3 ;
comparison_statspec = "E[mse]" ;
splitter = *0 ;
cached_outputsize = 2 ;
learner_train_costs = 5 [ 378.53883283487005 1037.13608363349476 1728.02926321886116 1068.17736443550598 584.705657748810495 ] ;
best_learners = 3 [ *2  *10  *4  ] ;
expdir = "PYTEST__PL_BestAveragingPLearner_NNet__RESULTS:expdir/Split0/LearnerExpdir/" ;
seed = -1 ;
stage = 0 ;
n_examples = 150 ;
inputsize = 3 ;
targetsize = 2 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 1 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = ""  )
