import os.path
from plearn.pyplearn import *

plarg_defaults.datatrain  = "PLEARNDIR:examples/data/test_suite/eslt_mixture/data_train.amat"
plarg_defaults.datatest   = "PLEARNDIR:examples/data/test_suite/eslt_mixture/data_test.amat"

dataset = pl.ConcatRowsVMatrix(
sources = [ pl.AutoVMatrix(specification=plargs.datatrain,inputsize=2,targetsize=1),
	pl.AutoVMatrix(specification=plargs.datatest,inputsize=2,targetsize=1) ],
inputsize=2,
targetsize=1,
weightsize=0
)

learner = pl.HyperLearner(
    option_fields = [ "nstages" ],
    dont_restart_upon_change = [ "nstages" ] ,
    provide_strategy_expdir = 1 ,
    save_final_learner = 0 ,
    provide_learner_expdir = 1 ,
    forget_when_training_set_changes = 0 ,
    nstages = 1 ,
    report_progress = 1 ,
    verbosity = 1 ,
    learner = pl.RegressionTree(
        nstages = 10
        ,loss_function_weight = 1
#        ,missing_is_valid = 0
#        ,multiclass_outputs = []
        ,maximum_number_of_nodes = 50
        ,compute_train_stats = 1
        ,complexity_penalty_factor = 0.0
        ,output_confidence_target = 1
        ,verbosity = 2
        ,report_progress = 1
        ,forget_when_training_set_changes = 1
#        ,conf_rated_adaboost = 0
        ,leave_template = pl.RegressionTreeMulticlassLeaveFast(nb_class=2 )
        ),
    tester = pl.PTester(
    splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,200), (0,200), (200,1) ])),
    statnames = [ #'E[train.E[class_error]]', 'E[train.E[base_confidence]]', 'E[train.E[base_reward_l2]]', 'E[train.E[base_reward_l1]]',
                 'E[test1.E[class_error]]',  'E[test1.E[base_confidence]]',  'E[test1.E[base_reward_l2]]',  'E[test1.E[base_reward_l1]]',
                 'E[test2.E[class_error]]',  'E[test2.E[base_confidence]]',  'E[test2.E[base_reward_l2]]',  'E[test2.E[base_reward_l1]]'],
    save_test_outputs = 0 ,
    report_stats = 1  ,
    save_initial_tester = 0 ,
    save_learners = 0 ,
    save_initial_learners = 0  ,
    save_data_sets = 0  ,
    save_test_costs = 0  ,
    provide_learner_expdir = 1  ,
    save_test_confidence = 0  ,
    save_test_names = 0,
    ),
    strategy = [

    pl.HyperOptimize(
    which_cost = "E[test2.E[class_error]]" ,
    provide_tester_expdir = 1 ,
    oracle = pl.EarlyStoppingOracle(
    option = "nstages" ,
    range = [ 1, 5, 1 ],
    min_value = -3.40282e+38 ,
    max_value = 3.40282e+38 ,
    max_degradation = 3.40282e+38 ,
    relative_max_degradation = -1 ,
    min_improvement = -3.40282e+38 ,
    relative_min_improvement = -1 ,
    max_degraded_steps = 120 ,
    min_n_steps = 2 
    )  # end of EarlyStoppingOracle
    )  # end of sub_strategy.HyperOptimize
    ]  # end of HyperLearner strategy
    )
splitter = pl.FractionSplitter(
    splits = TMat(1,3, [ (0,1), (0,200), (200,1) ])
    )
tester = pl.PTester(
    expdir = plargs.expdir,
    dataset = dataset,
    splitter = splitter,
    learner = learner,
    statnames = [#'E[train.E[class_error]]', 'E[train.E[base_confidence]]', 'E[train.E[base_reward_l2]]', 'E[train.E[base_reward_l1]]',
                 'E[test1.E[class_error]]',  'E[test1.E[base_confidence]]',  'E[test1.E[base_reward_l2]]',  'E[test1.E[base_reward_l1]]',
                 'E[test2.E[class_error]]',  'E[test2.E[base_confidence]]',  'E[test2.E[base_reward_l2]]',  'E[test2.E[base_reward_l1]]'],
    provide_learner_expdir = 1,
    save_test_costs = 1,
    save_test_outputs = 1,
    save_test_confidence = 0,
    save_learners = 0

    )

def main():
    return tester
