import os.path
from plearn.pyplearn import *

plarg_defaults.data    = "PLEARNDIR:examples/data/test_suite/linear_4x_2y.pmat"

dataset = pl.SubVMatrix(
        inputsize = 4,
        targetsize = 1,
        weightsize = 0,
        source = pl.AutoVMatrix(
            specification = plargs.data,
            inputsize = 4,
            targetsize = 2,
            weightsize = 0
            ),
        width = 5
        )

learner = pl.HyperLearner(
    option_fields = [ "nstages" ],
    dont_restart_upon_change = [ "nstages" ] ,
    provide_strategy_expdir = 1 ,
    save_final_learner = 0 ,
    provide_learner_expdir = 1 ,
    forget_when_training_set_changes = 0 ,
    nstages = 1 ,
    report_progress = 1 ,
    verbosity = 1 ,
    learner = pl.RegressionTree(
        nstages = 10
        ,loss_function_weight = 1
#        ,missing_is_valid = 0
#        ,multiclass_outputs = []
        ,maximum_number_of_nodes = 50
        ,compute_train_stats = 1
        ,complexity_penalty_factor = 0.0
	,output_confidence_target = 1
        ,verbosity = 2
        ,report_progress = 1
        ,forget_when_training_set_changes = 1
#        ,conf_rated_adaboost = 0
        ,leave_template = pl.RegressionTreeLeave(output_confidence_target = 1)
        ),
    tester = pl.PTester(
    splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,0.75), (0,.75), (0.75,1) ])),
    statnames = [ #'E[train.E[mse]]', 'E[train.E[base_confidence]]', 'E[train.E[base_reward_l2]]', 'E[train.E[base_reward_l1]]',
                 'E[test1.E[mse]]',  'E[test1.E[base_confidence]]',  'E[test1.E[base_reward_l2]]',  'E[test1.E[base_reward_l1]]',
                 'E[test2.E[mse]]',  'E[test2.E[base_confidence]]',  'E[test2.E[base_reward_l2]]',  'E[test2.E[base_reward_l1]]'],
    save_test_outputs = 0 ,
    report_stats = 1  ,
    save_initial_tester = 0 ,
    save_learners = 0 ,
    save_initial_learners = 0  ,
    save_data_sets = 0  ,
    save_test_costs = 0  ,
    provide_learner_expdir = 1  ,
    save_test_confidence = 0  ,
    save_test_names = 0,
    ),
    strategy = [

    pl.HyperOptimize(
    which_cost = "E[test2.E[mse]]" ,
    provide_tester_expdir = 1 ,
    oracle = pl.EarlyStoppingOracle(
    option = "nstages" ,
    range = [ 1, 61, 20 ],
    min_value = -3.40282e+38 ,
    max_value = 3.40282e+38 ,
    max_degradation = 3.40282e+38 ,
    relative_max_degradation = -1 ,
    min_improvement = -3.40282e+38 ,
    relative_min_improvement = -1 ,
    max_degraded_steps = 120 ,
    min_n_steps = 2 
    )  # end of EarlyStoppingOracle
    )  # end of sub_strategy.HyperOptimize
    ]  # end of HyperLearner strategy
    )
splitter = pl.FractionSplitter(
    splits = TMat(1,3, [ (0,1), (0,0.75), (0.75,1) ])
    )
tester = pl.PTester(
    expdir = plargs.expdir,
    dataset = dataset,
    splitter = splitter,
    learner = learner,
    statnames = [#'E[train.E[mse]]', 'E[train.E[base_confidence]]', 'E[train.E[base_reward_l2]]', 'E[train.E[base_reward_l1]]',
                 'E[test1.E[mse]]',  'E[test1.E[base_confidence]]',  'E[test1.E[base_reward_l2]]',  'E[test1.E[base_reward_l1]]',
                 'E[test2.E[mse]]',  'E[test2.E[base_confidence]]',  'E[test2.E[base_reward_l2]]',  'E[test2.E[base_reward_l1]]'],
    provide_learner_expdir = 1,
    save_test_costs = 1,
    save_test_outputs = 1,
    save_test_confidence = 0,
    save_learners = 0 
    )

def main():
    return tester
