
                      Contrastive divergence multi-layer RBMs


Boltzmann machines:

X (may be) observed, H is (always) hidden r.v.
Their joint is given by the Boltzmann distribution
associated with an energy function energy(x,h):
  P(X=x,H=h) = exp(-energy(x,h)) / Z
where Z is the appropriate normalization constant:
  Z = sum_{x,h} exp(-energy(x,h)).

In ordinary Boltzmann machines, the energy function is a 
quadratic polynomial. Let z=(x,h), then
  energy(z) = sum_i b_i z_i    +    sum_{ij} w_{ij} z_i z_j
where z_i \in {0,1}. There is no need for a constant term 
since it would cancel out in Z.

If X=x is observed while H remains hidden, the likelihood
involves a sum over all configurations of H:

  P(X=x) = sum_h P(X=x,H=h) = sum_h exp(-energy(x,h)) / Z

Unfortunately, the exact gradient of log P(x) wrt b or w
is intractable since it involves two intractable sums
(the one over h for the numerator of the above, and the
one over h and x, for Z, the denominator).

The gradient can be written as a sum of the corresponding two terms:

  d(-log P(x))/dtheta =
  sum_h      P(H=h|X=x) d_energy(h,x)/dtheta          [this is the POSITIVE phase contribution]
- sum_{h,x}  P(H=h,X=x) d_energy(h,x)/dtheta          [this is the NEGATIVE phase contribution]

The derivation of this result is easy (we do a similar derivation
for the restricted Boltzmann machine below).

The standard way to estimate the gradient, to avoid these sums, is
to perform an MCMC scheme to obtain one or more samples from P(h|x)
with x ~ training set and from P(x,h).

For a reason that I do not remember exactly, the w matrix
is normally constrained to be symmetric. I believe it has
to do with the MCMC scheme normally used for sampling
from P(X) or from P(H|X). However, we will not be using
that scheme, so I do not think that this restriction
is important (to be verified somehow).

Restricted Boltzmann machines:

If we set the weight between h_i and h_j to 0 
and the weight between x_i and x_j to 0, we obtain a RBM.
The advantage of an RBM is that all the H_i's become independent
when conditioning on X, and (symmetrically) all the X_i become independent
when conditioning on H.


Energy functions for Restricted Boltzmann Machines:
(Note that w_{ij} = w_{ji})

 * energy term for binomial unit i with value v_i and inputs u_j, parameters (b_i, w_{i.}): 
     
    b_i v_i + sum_j w_{ij} v_i u_j
   
       ==> P(v_i=1 | u) = exp(- b_i - sum_j w_{ij} u_j) / (1 + exp(- b_i - sum_j w_{ij} u_j)) = sigmoid(-b_i - sum_j w_{ij} u_j)
       NOTE THE MINUS

 * energy term for fixed-variance Gaussian unit i with value v_i and inputs u_j, parameters (a_i,b_i, w_{i,.}):

    b_i v_i + a_i^2 v_i^2 + sum_j w_{ij} v_i u_j
       ==> P(v_i | u) = (1/Z) exp(-(b_i v_i + a_i^2 v_i^2 + sum_j w_{ij} v_i u_j)) = (1/Z)(-0.5(v_i - mu)/sigma^2)
       ==> P(v_i | u) = N(v_i; mu, sigma^2) with sigma^2 = 0.5/a_i^2, mu = -0.5(b_i + sum_j w_{ij} u_j)/a_i^2
       NOTE HOW THESE BLOW UP WHEN a_i IS TOO SMALL. MAY WANT TO USE (a_i + epsilon)^2 INSTEAD, with epsilon fixed.

 * energy term for softmax units i with value v_i and inputs u_j, parameters (b_i, w_{i.}): 
     
    b_i v_i + sum_j w_{ij} v_i u_j
   
       ==> P(v_i=1 | u) = exp(- b_i - sum_j w_{ij} u_j) / sum_i " = softmax(- b_i - sum_j w_{ij} u_j)
       NOTE THE MINUS

Likelihood gradient for a RBM with observed inputs x, hidden outputs y:

 use Z = sum_{x,y} exp(-energy(x,y))
    P(x,y) = exp(-energy(x,y))/Z
    P(y|x) = exp(-energy(x,y)) / sum_y exp(-energy(x,y))

 For ANY energy-based (Boltzmann) distribution:
  d/dtheta (- log P(x)) = d/dtheta (- log sum_y P(x,y)) = d/dtheta (- log sum_y exp(-energy(x,y))/Z)
                        = (Z/(sum_y exp(-energy(x,y)))) sum_y exp(-energy(x,y))/Z (d_energy(x,y)/dtheta + (1/Z) dZ/dtheta)
                        = sum_y P(y|x) d_energy(x,y)/dtheta - (1/Z) sum_{x,y} exp(-energy(x,y)) d_energy(x,y)/dtheta
                        = sum_y P(y|x) d_energy(x,y)/dtheta - sum_{x,y} P(x,y) d_energy(x,y)/dtheta
                        = E[d_energy(x,y)/dtheta | x] - E[d_energy(x,y)/dtheta]
                          where E is over the model's distribution
                        = "positive phase contribution" - "negative phase contribution"
 The positive phase tries to lower the energy of observed x while the negative phase tries to increase the energy of all x ~ P.

 For a RBM, P(y|x) factorizes into P(y_i|x) and energy is a sum over energy_i(x,y_i), and theta={theta_i} so that 
  sum_y P(y|x) d_energy(x,y)/dtheta_i = sum_{y_i} P(y_i|x) d_energy_i(x,y_i)/dtheta_i
 with theta_i the parameters associated with y_i.
  
 With Contrastive Divergence we replace the expectation over (x,y) by a sample taken after 1 (or more) Gibbs sampling steps
    observed x = x0 -- (P(y|x0)) --> y0 -- (P(x|y0)) --> x1 -- (P(y|x1)) --> y1
 and the pair (x1,y1) serves as that sample in the case of 1 step (= "CD1").

  * output binomial unit i <-> input binomial unit j
      weight w_{ij}:
       positive phase contribution: P(y_{0i}=1|x_0) 1*x_{0j} + (1 - P(y_{0i}=1|x_0)) 0*x_{0j} = P(y_{0i}=1|x_0) x_{0j}
       negative phase contribution: P(y_{1i}=1|x_1) 1*x_{1j} + (1 - P(y_{1i}=1|x_1)) 0*x_{1j} = P(y_{1i}=1|x_1) x_{1j}
      bias b_i:
       positive phase contribution: P(y_{0i}=1|x_0) 
       negative phase contribution: P(y_{1i}=1|x_1) 

  * output binomial unit i <-> input Gaussian unit j
      bias b_i and weight w_{ij} as above
      parameter a_j:
       positive phase contribution: 2 a_j x_{0j}^2
       negative phase contribution: 2 a_j x_{1j}^2
      
  * output softmax unit i <-> input binomial unit j
      same formulas as for binomial units, except that P(y_i=1|x) is computed differently (with softmax instead of sigmoid)


Basic operations in each RBM layer:

 * layer::upActivation: compute parameters of p(output_variables | input_variables)
             i.e. compute activation (weighted sum) in the case of binomial units, and (mu,sigma) in the case of Gaussian units
 * layer::fprop(input,E[output|input]): find E(output_variables | input_variables). This ALWAYS calls upActivation.
             call upActivation and then compute & return corresponding expectation (p for binomial = sigmoid(activation), mu for Gaussian)
 * layer::upSample(): sample output_variables from p(output_variables | input_variables). upActivation MUST have been called before.
             sample from binomial or from Gaussian
 * layer::downActivation(): compute parameters of p(input_variables | output_variables)
             similar to upActivation, but downward, i.e. on input variables
 * layer::downExpectation(): find E(input_variables | output_variables). This ALWAYS calls downActivation.
             similar to upExpectation but downward, i.e. on input variables
 * layer::downSample(): sample input_variables from p(input_variables | output_variables). downActivation MUST have been called before.
             similar to upSample but on input variables
 * layer::accumulatePosStats(): accumulate positive phase statistics
             for binomial and softmax output units: accumulate input_variable[i]*output_prob[j] in pos_corr[i][j]
                                                    accumulate output_prob[j] in pos_mean[j]
             for Gaussian input units: accumulate 2 a[i] input_variable[i]^2 in pos_square[i]
             for all: increment pos_count
 * layer::accumulateNegStats(): accumulate negative phase statistics
             for binomial output units: accumulate input_variable[i]*output_prob[j] in neg_corr[i][j]
             for Gaussian input units: accumulate 2 a[i] input_variable[i]^2 in neg_square[i]
             for all: increment neg_count
 * layer::layerCDupdate(): update parameters using positive and negative phase statistics
             for binomial and softmax output units: 
                  gradient estimator for b_j = pos_mean[j]/pos_count - neg_corr[i][j]/neg_count
                  gradient estimator for w_ij = pos_corr[i][j]/pos_count - neg_corr[i][j]/neg_count
                  clear pos_corr, neg_corr
             for Gaussian input units:
                  gradient estimator for a_i = pos_square[i]/pos_count - neg_square[i]/neg_count
                  clear pos_square
             clear pos_count,neg_count


Combined operations, in a supervised RBM network:
 A supervised RBM network is an OnlineLearningModule that has a sequence of layers. 
 The last_layer is fully supervised. The 2nd to last is the last_hidden_layer.
 There is also a cost_layer that follows the last_layer, which computes the supervised cost to minimize.

 * network::computeRepresentation(input_variables):
     v <- input_variables
     for each layer except the last:
        layer->input_variables <- v.copy()
        v.resize(output_variables.size())
        layer->fprop(layer->input_variables,v)
     return v

 * network::fprop(input_variables)
     computeRepresentation(input_variables)
     if last_layer_takes_activations: (e.g. for undirected softmax last_layer)
       last_layer->fprop(last_hidden_layer->output_activation,last_layer->output)
     else
       last_layer->fprop(last_hidden_layer->output,last_layer->output)
     return last_layer->output

 * network::unsupervised_learning_from_example(input_variables):
     v <- input_variables
     for each layer except the last:
        layer->input_variables <- v.copy()
        layer->fprop(layer->input_variables,layer->output)
        v <- layer->output
        layer->upSample() 
        layer->accumulatePosStats()
        layer->downSample()
        layer->upSample()
        layer->accumulateNegStats()
        layer->CDupdate()

 * network::supervised_learning_from_example(input_variables, output_variables):
     unsupervised_learning_from_example(input_variables)
     if last_layer_takes_activations: (e.g. for undirected softmax last_layer)
       last_layer->fprop(v=last_hidden_layer->output_activation,last_layer->output)
     else
       last_layer->fprop(v=last_hidden_layer->output,last_layer->output)
     cost_layer->fprop((last_layer->output,output_variables),cost)
     cost_layer->bpropUpdate((last_layer->output,output_variables),cost,(dout,tmp), 1)
     last_layer->bpropUpdate(v,out,din,dout)
     for each layer except the last, going backwards:
        dout <- din.copy()
        layer->bpropUpdate(layer->input_variables,layer->output, din, dout)


 * network::unconditionalGenerate(): sample an input, unconditionally
     last_layer->clearActivations() // so that the first upSample() only samples from the biases
     repeat n_MCMC_sampling_iterations
       last_layer->upSample()
       last_layer->downActivation()
       last_hidden_layer->output_activation_external_contribution <- last_layer->input_activation.copy()
       last_hidden_layer->upActivation() // adds activation from inputs with external contribution from last_layer
       last_hidden_layer->upSample()
       last_hidden_layer->downActivation()
       last_hidden_layer->downSample()
       last_layer->input_variables <- last_hidden_layer->output_variables.copy()
       last_layer->upActivation()
     v <- last_hidden_layer->output_variables
     for each layer except the last, going backwards:
       layer->output_variables <- v.copy()
       layer->downActivation()
       layer->downSample()
       v <- layer->input_variables
     return v


 * network::conditionalGenerate(output): sample an input, conditional on the given output value
     last_layer->output_variables <- output.copy()
     last_layer->downActivation() // compute part of the activation of last hidden units due to output units
     last_hidden_layer->output_activation_external_contribution <- last_layer->input_activation.copy()
     repeat n_MCMC_sampling_iterations
       last_hidden_layer->downActivation()
       last_hidden_layer->downSample()
       last_hidden_layer->upActivation()
       last_hidden_layer->upSample()
     v <- last_hidden_layer->output_variables
     for each layer except the last, going backwards:
       layer->output_variables <- v.copy()
       layer->downActivation()
       layer->downSample()
       v <- layer->input_variables
     last_hidden_layer->output_activation_external_contribution.clear()
     return v

-------------------------------------------------------------------------------
Other architecture and pseudo-code proposed
-------------------------------------------------------------------------------

The units themselves, stored in layers (class RBMLayer), are separated
from the weighted links between layers (class RBMParameters, inheriting
from OnlineLearningModule). The top-level architecture of the network (say,
DeepBeliefNetwork) is a PLearner (maybe a PDistribution) with functions for
sampling.

RBMLayer stores:
  - layer_params: parameters describing the distribution
  - expectations: expectation of each unit
  - sample: sample from the distribution
  - some flags to know what is up-to-date

RBMParameters stores (and has to update):
  - weights: weights between up and down layers
  - bias (and parameters like the quadratic term, in gaussian units) for both
    up and down layer
  - input_vec: a pointer to its current input vector (sample or expectation),
    and a flag to know if it is up or down
  - up_pos_stats: statistics of the positive phase for up layer
  - down_pos_stats: statistics of the positive phase for down layer
  - up_neg_stats: statistics of the negative phase for up layer
  - down_neg_stats: statistics of the negative phase for down layer
  - a learning rate

The methods are:
  * RBMParameters::setAsUpInput( Vec ) : set the input vector, and flag to 'up'
  * RBMParameters::setAsDownInput( Vec ) : same, but 'down'
  * RBMParameters::setAsPosStats( Vec down_stats, Vec up_stats ) :
      down_pos_stats << down_stats;
      up_pos_stats << up_stats;
  * RBMParameters::setAsNegStats( Vec down_stats, Vec up_stats ) :
      down_neg_stats << down_stats;
      up_neg_stats << up_stats;
  * RBMParameters::update() (from statistics accumulated)
  * implement fprop(), bpropUpdate() ?
  * RBMParameters::computeUnitParams( int i, const Vec& params ) : put in
    params the parameters describing the distribution of unit i (i is an index
    in the up layer if input vector is 'down', and vice-versa), and
    invalidates 'sample' and 'expectation'
  * RBMParameters:: computeUnitParams( const Vec& all_params ) : same thing,
    for every unit in the appropriate layer

  * RBMLayer::getUnitParams( int i, RBMParams rbmp ) :
      calls rbmp->computeUnitParams( i, layer_params.subvec(...) )
  * RBMLayer::getUnitParams( RBMParams rbmp ) :
      calls rbmp->computeUnitParams( layer_params ) by default, or
      rbmp->computeUnitParams( i, layer_params ) for i in a subset of the
    units, for "sparse" layers
  * RBMLayer::computeSample()
      get 'sample' from 'layer_params'
  * RBMLayer::computeExpectation()
      get 'expectation' from 'layer_params'

If a DeepBeliefNetwork has two RBMLayer's (input and output) and one
RBMParameters (rbmp) linking both of them, a simple up propagation of
input_vec to a sample (out_sample) would typically call:

    input.sample << input_vec;
    rbmp.setAsDownInput( input.sample );
    output.getUnitParams( rbmp );
    output.computeSample();
    out_sample << output.sample;

If we wanted the expectation (out_exp) instead of a sample, it would have
been:

    input.sample << input_vec;
    rbmp.setAsDownInput( input.sample );
    output.getUnitParams( rbmp );
    output.computeExpectation();
    out_exp << output.expectation;

The learning of one example (input_vec) by contrastive divergence:

    // positive phase
    input.sample << input_vec;
    rbmp.setAsDownInput( input.sample );
    output.getUnitParams( rbmp );
    output.computeSample();
    rbmp.setAsPosStats( input.sample, output.sample );

    // negative phase
    rbmp.setAsUpInput( output.sample );
    input.getUnitParams( rbmp );
    input.computeSample();
    rbmp.setAsDownInput( input.sample );
    output.getUnitParams( rbmp );
    output.computeSample();
    rbmp.setAsNegStats( input.sample, output.sample );

    // update
    rbmp.update();

If we have three sequential layers (input, hidden, output) and two
RBMParameters:
  - rbmp_ih between input and hidden, frozen (because learned previously);
  - rbmp_ho between hidden and output, which we train;
the learning of one example (input_vec) will look like:

    // propagation to hidden
    input.sample << input_vec;
    rbmp_ih.setAsDownInput( input.sample );
    hidden.getUnitParams( rbmp_ih );
    hidden.computeExpectation(); // not computeSample()

    // positive phase
    rbmp_ho.setAsDownInput( hidden.expectation );
    output.getUnitParams( rbmp_ho );
    output.computeSample();
    rbmp_ho.setAsPosStats( hidden.expectation, output.sample );

    // negative phase
    rbmp_ho.setAsUpInput( output.sample );
    hidden.getUnitParams( rbmp_ho );
    hidden.getExpectation();
    rbmp_ho.setAsDownInput( hidden.expectation );
    output.getUnitParams( rbmp_ho );
    output.computeSample();
    rbmp_ho.setAsNegStats( hidden.expectation, output.sample );

    // update
    rbmp_ho.update();


