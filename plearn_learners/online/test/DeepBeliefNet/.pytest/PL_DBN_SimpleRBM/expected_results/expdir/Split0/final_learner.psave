*1 ->HyperLearner(
tester = *2 ->PTester(
expdir = "" ;
dataset = *3 ->MemoryVMatrix(
data = 2  3  [ 
1 	0 	0 	
0 	1 	1 	
]
;
fieldinfos = 0 [ ] ;
fieldnames = []
;
deep_copy_memory_data = 1 ;
writable = 0 ;
length = 2 ;
width = 3 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
extrasize = 0 ;
metadatadir = "" ;
source = *0  )
;
splitter = *4 ->FractionSplitter(
round_to_closest = 0 ;
splits = 1  2  [ 
(0 , 1 )	(0 , 1 )	
]
;
one_is_absolute = 0  )
;
statnames = 4 [ "E[train.E[NLL]]" "E[train.E[class_error]]" "E[test.E[NLL]]" "E[test.E[class_error]]" ] ;
statmask = []
;
learner = *5 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
cd_decrease_ct = 0 ;
up_down_learning_rate = 0 ;
up_down_decrease_ct = 0 ;
grad_learning_rate = 0.100000000000000006 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 20 10 ] ;
up_down_nstages = 0 ;
use_classification_cost = 1 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *6 ->RBMBinomialLayer(
use_signed_samples = 0 ;
size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
bias_decay_type = "none" ;
bias_decay_parameter = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.0299999999999999989 0 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
;
verbosity = 1  )
*8 ->RBMBinomialLayer(
use_signed_samples = 0 ;
size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
bias_decay_type = "none" ;
bias_decay_parameter = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ -0.0041988074813960885 0.00291521845148070419 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
] ;
i_output_layer = 1 ;
connections = 1 [ *9 ->RBMMatrixConnection(
weights = 2  2  [ 
-0.222066209664342068 	0.582925561708350082 	
0.516883916989072545 	-0.316272804129796303 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
L2_decrease_constant = 0 ;
L2_shift = 100 ;
L2_decrease_type = "one_over_t" ;
L2_n_updates = 0 ;
down_size = 2 ;
up_size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 2 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
] ;
classification_module = *10 ->RBMClassificationModule(
previous_to_last = *9  ;
last_layer = *8  ;
last_to_target = *11 ->RBMMatrixConnection(
weights = 2  2  [ 
-0.603392333131359426 	0.370787384786479657 	
0.09708625652197031 	-0.668099599496062679 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
L2_decrease_constant = 0 ;
L2_shift = 100 ;
L2_decrease_type = "one_over_t" ;
L2_n_updates = 0 ;
down_size = 2 ;
up_size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 2 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
;
target_layer = *12 ->RBMMultinomialLayer(
size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
bias_decay_type = "none" ;
bias_decay_parameter = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ -0.00487910443291659449 0.00487910443291660317 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
;
joint_connection = *13 ->RBMMixedConnection(
sub_connections = 1  2  [ 
*9  	*11  	
]
;
up_init_positions = 1 [ 0 ] ;
down_init_positions = 2 [ 0 2 ] ;
n_up_blocks = 1 ;
n_down_blocks = 2 ;
down_size = 4 ;
up_size = 2 ;
learning_rate = 0.100000000000000006 ;
momentum = 0 ;
input_size = 4 ;
output_size = 2 ;
name = "RBMMixedConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
;
last_size = 2 ;
input_size = 2 ;
output_size = 2 ;
name = "RBMClassificationModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *7  ;
verbosity = 1  )
;
final_module = *0 ;
final_cost = *0 ;
partial_costs = []
;
use_sample_for_up_layer = 0 ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
use_mean_field_contrastive_divergence = 0 ;
train_stats_window = -1 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
up_down_stage = 0 ;
generative_connections = []
;
random_gen = *7  ;
seed = 1827 ;
stage = 30 ;
n_examples = 2 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 30 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
;
perf_evaluators = {};
report_stats = 1 ;
save_initial_tester = 1 ;
save_stat_collectors = 1 ;
save_split_stats = 1 ;
save_learners = 1 ;
save_initial_learners = 0 ;
save_data_sets = 0 ;
save_test_outputs = 1 ;
call_forget_in_run = 1 ;
save_test_costs = 1 ;
save_test_names = 1 ;
provide_learner_expdir = 0 ;
should_train = 1 ;
should_test = 1 ;
template_stats_collector = *0 ;
global_template_stats_collector = *0 ;
final_commands = []
;
save_test_confidence = 0 ;
enforce_clean_expdir = 1 ;
redirect_stdout = 0 ;
redirect_stderr = 0  )
;
option_fields = 1 [ "nstages" ] ;
dont_restart_upon_change = 1 [ "nstages" ] ;
strategy = 1 [ *14 ->HyperOptimize(
which_cost = "2" ;
min_n_trials = 0 ;
oracle = *15 ->EarlyStoppingOracle(
option = "nstages" ;
values = []
;
range = 3 [ 0 31 2 ] ;
min_value = -1.79769313486231571e+308 ;
max_value = 1.79769313486231571e+308 ;
max_degradation = 1.79769313486231571e+308 ;
relative_max_degradation = -1 ;
min_improvement = -1.79769313486231571e+308 ;
relative_min_improvement = -1 ;
max_degraded_steps = 31 ;
min_n_steps = 0 ;
nreturned = 16 ;
best_objective = 0.614096318051678525 ;
best_step = 16 ;
met_early_stopping = 0  )
;
provide_tester_expdir = 0 ;
sub_strategy = []
;
rerun_after_sub = 0 ;
provide_sub_expdir = 1 ;
save_best_learner = 0 ;
splitter = *0 ;
auto_save = 0 ;
auto_save_diff_time = 10800 ;
auto_save_test = 0 ;
best_objective = 0.614096318051678525 ;
best_results = 4 [ 0.651261219307483818 0.5 0.614096318051678525 0 ] ;
best_learner = *5  ;
trialnum = 16 ;
option_vals = []
;
verbosity = 0  )
] ;
provide_strategy_expdir = 1 ;
save_final_learner = 1 ;
learner = *5  ;
provide_learner_expdir = 0 ;
expdir_append = "" ;
forward_nstages = 0 ;
random_gen = *0 ;
stage = 1 ;
n_examples = 2 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 1 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
