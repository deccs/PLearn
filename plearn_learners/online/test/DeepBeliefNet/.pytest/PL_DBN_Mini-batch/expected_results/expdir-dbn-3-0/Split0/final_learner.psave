*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.0566666666666666707 0.0600000000000000047 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -3.67929816976774715 -3.6682448752547705 0.0750909232339263683 0.0795841166700318875 0.0708342668804167325 0.0750421938062638405 0.0749057540871664457 0.07281350621284427 0.0763556633275116747 0.0782689083009728281 0.072824643124686117 0.0779183009350939287 0.0699000332593961438 0.0712420215383051392 0.073542444248528932 0.0767792116507820255 0.0778439304287265182 0.0706109057057301009 0.0751034493617696863 0.069940057614123502 0.0783087691931432239 0.0765286316068690409 0.0731593533332815099 0.0755157467085580819 0.0766351376284480079 0.070479449352692139 0.0718806226985668345 0.0701457067916425731 0.0768776599755875978 0.0739384583091209219 0.0743774129171129589 0.0801217793115617943 0.0721628274764351541 0.0806814897703578976 0.0708951835495260224 0.0715097933984782386 0.0756688379895598395 0.0740952778784406407 0.0799916253106679881 0.0747857117152906925 0.0783304419111606476 0.0727520148249376497 0.0772393904668482456 0.0753918317216105416 0.0783821915944977049 0.0704261841624362062 0.0751946302171443287 0.0696449037214908612 0.0745767703531106385 0.070806479283302623 0.0709348311649994623 0.0696759908129132854 0.0703636071845372135 0.0718591719674553375 0.0765280528752296935 0.0760744758082740613 0.0823326087023871778 0.0723685391237849779 0.0779853133866276332 0.0775462066951605189 0.0753792470513583723 0.0729536446087890172 0.0725329279936358651 0.0776784049340394772 0.0800016351796151021 0.0753005795642522346 0.0787062629788652934 0.0740323485729651176 0.0751659610584930055 0.0698937309834748999 0.0789209919201119686 0.0769177427996144136 0.0767115469459718896 0.0767304756154562617 0.0759158170119265813 0.0792541201190776479 0.0726706650970279366 0.0732572878386490989 0.0763562455137006407 0.0776622930565265407 0.0744300500286751709 0.0736199596196006473 0.0758170804080609273 0.0803895298645543877 0.0725294734781802286 0.0817744617003312024 0.0760032369969883548 0.0742856132339138747 0.0753395223184904345 0.0777583837745135925 0.0758727019124877389 0.0755613483759634968 0.0714384499890213798 0.0738360175084723652 0.0728876094213855713 0.0753375538997586996 0.0708094847711961267 0.0750639894616385306 0.0754455419716839742 0.0785276661645328 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-0.52038541925781967 	-0.607667740189380523 	
-0.547335303272597051 	-0.574510722075016633 	
0.0504029420063143857 	-0.0174374020209189032 	
-0.0726720177154327324 	-0.0166870493884907455 	
0.0985284220175968173 	0.0611863005277123173 	
0.0754034367023085489 	-0.0400349156555762642 	
0.078973421957143769 	-0.0396774616380166784 	
0.108170790392739913 	-0.00765013072823586982 	
0.0574395119975671803 	-0.0591070156090361745 	
-0.061007039891299214 	0.0066718476208302898 	
0.0736287540104566957 	0.0253895592031331274 	
-0.0777417566768631441 	0.033988152696632544 	
0.085793260023404358 	0.10336889613750673 	
0.0595732996791215677 	0.0876320649751073655 	
0.0985639370941749221 	-0.0196922373217131852 	
0.023366080547435969 	-0.0378252019980260118 	
-0.0169121891224506757 	-0.0268755261362537863 	
0.105509436301355369 	0.0612729979063185229 	
0.0295185514598919063 	0.00279503185259742009 	
0.108172318468795839 	0.0798166168810517801 	
-0.0129827416114516835 	-0.043273012491637404 	
-0.0427436926119571375 	0.0360769453606456306 	
0.0504779492722270823 	0.0383236706034821642 	
0.0687895317968882231 	-0.0469326547384686793 	
-0.0666313507642620761 	0.0584517370219266724 	
0.0872457685108091324 	0.0837080805890952351 	
0.0598201510048938442 	0.0675784349064649376 	
0.0865288471252173008 	0.0951316360468640598 	
0.0237140180718280608 	-0.0408629407609415601 	
0.0631379942820747275 	0.00308499348420874673 	
0.111272744450818958 	-0.0550198793991546961 	
-0.0495399255127684165 	-0.0544110084214884313 	
0.0657230040930184001 	0.0531562468007424349 	
-0.0793895470235106288 	-0.0385651446308253806 	
0.0680320003763357217 	0.0900858662837026314 	
0.0308277344266279264 	0.10910237774397652 	
-0.0428935242523314775 	0.0609697782115297127 	
0.0970561821731235064 	-0.0338666308471151159 	
-0.0596192092162303872 	-0.0408316442859519985 	
-0.00304223746333419452 	0.0449917804586676268 	
0.0133410948519769729 	-0.0696020236616901877 	
0.03997782323945865 	0.0611241954582473629 	
0.0212044378814250263 	-0.0481804311018778769 	
-0.0798320840154110589 	0.109307593668522079 	
0.00216013628189293694 	-0.0601016310390021027 	
0.0733821940828805336 	0.099497308314277666 	
-0.00418577457569986339 	0.0342672749731996601 	
0.0961049167980579794 	0.101328682742033507 	
-0.0262656255829718105 	0.0753752819357317028 	
0.0923863548467529772 	0.0682949741016277145 	
0.108756281771888105 	0.0481458386888888659 	
0.100093215436711402 	0.0963736142319992356 	
0.11044140819668434 	0.064159753976061315 	
0.0742272888131287334 	0.0536989130170025461 	
0.0670662090171207786 	-0.0727680558490813728 	
0.0412975622692688532 	-0.035973626288952322 	
-0.0755336957322752522 	-0.0843988974337767928 	
0.031683218853364746 	0.0813611862515050827 	
-0.0130739435676640054 	-0.034526988248239604 	
0.0136140272169084763 	-0.0489930421672095315 	
-0.011061723879014709 	0.0359297344246217523 	
0.0128932585850817186 	0.0830364377215482841 	
0.0676125872825022733 	0.039953970286474183 	
0.00349451945220510861 	-0.0426454815726958619 	
-0.0795372606084337741 	-0.0206274492374718434 	
-0.0679556269290350762 	0.0989090112668678106 	
0.00106926327384114202 	-0.0675641733945039902 	
0.0247260524176569838 	0.0384630055092971754 	
0.026378225328460677 	0.00413268501827163039 	
0.108363320390186382 	0.0809527489082843277 	
0.00744067734895159909 	-0.0793276345356500878 	
-0.0685828648959103254 	0.0524331672735784751 	
-0.0430299179219996233 	0.0311991517220432564 	
0.00875455007682279102 	-0.0221527377393929761 	
0.0396190903019198737 	-0.0299243858711141855 	
-0.0259299398002285457 	-0.0553743962254750755 	
0.0654815998567056939 	0.0381233449386994272 	
0.0857406226041131925 	0.000868266886166538395 	
0.0818156967821113412 	-0.0819606571238428866 	
-0.0510867284702254815 	0.0130209282921754724 	
0.0185073534397708767 	0.0332937538289315785 	
0.0564972252169523639 	0.0187982842748548977 	
-0.0595800360354162978 	0.0745776702050969659 	
-0.0626526219961449776 	-0.0481068295040314731 	
0.0760290724928658901 	0.0318015323295316663 	
-0.0680175615269424244 	-0.0780292036804604988 	
0.045426527393173266 	-0.0379064295013739616 	
0.000245257330670841593 	0.0561754669591406422 	
0.0266789063222490352 	-0.00109026801003190752 	
-0.065426210107723759 	0.0254095633358379196 	
-0.0161558737254881811 	0.0270927473390010429 	
0.0315749936922243776 	-0.0121516449151251385 	
0.0458707558030447202 	0.0955607640219145738 	
0.0311126203336938301 	0.0378846159519728373 	
-0.00581538096481791413 	0.104733200172821811 	
0.0640125283786390359 	-0.0373943635204284364 	
0.0738255534250779194 	0.0867777875959012679 	
-0.0404066042800288808 	0.0760341306135597778 	
0.0678668982597476489 	-0.0441082122306330204 	
0.00207766362528058381 	-0.0638437672563030023 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0113262925564693168 	0.00641492602461605013 	-0.00159847381051862899 	-0.00789459485609227303 	0.00244219358215985814 	-0.0081261550019702377 	-0.00389482222121642152 	0.00389091998488833111 	-0.00541050652884287036 	-0.00262556755390811825 	0.00952868237595928119 	-0.00969494151094163828 	-0.00706508174692422209 	-0.00727612306607582256 	-0.00846038975666718249 	0.000773966054525186621 	-0.00583361570628981342 	-0.00201278590637816437 	0.00872572454424036352 	-0.00165701502752675124 	-0.00799891102918076635 	6.47096589051982863e-05 	-0.00973055555769559294 	-0.00215375660638213173 	0.00716715790392904832 	-0.00168040418721199583 	-0.00686749154366765677 	0.00769175181889198388 	-0.00685037181174525354 	0.00827079361448006777 	0.00779395048534614263 	0.00260805740919305227 	-5.93787847705055239e-05 	-0.00761901303209245716 	0.00277648344971009441 	0.000531124508030605003 	-0.00733566395363501652 	0.00928862170370055307 	0.000345824306290504029 	0.00218347321736047685 	-0.00879584583154094379 	-0.00473551449789763775 	-0.0031015010128094731 	0.00679600317669165795 	0.000498927731410178546 	0.00534312277919853518 	0.00347021641974513528 	0.00337220069515059041 	-0.00622143586125560328 	-0.00127655934433769597 	0.00436484410802257493 	0.00725999145664699228 	-0.00881265446020709255 	-0.00919797829396393728 	0.00462042560691856407 	-0.00919982500002390104 	-0.00889966122589246934 	-0.000627033368822297178 	-0.00140435990570596876 	0.00348752003687191961 	-0.00440996403305462647 	0.00445091226375020181 	0.00153199411182978963 	0.00824276166398772887 	-0.00589422826971325482 	0.00185054823285728731 	0.00735205392812524582 	-0.00932065008082455862 	-0.000164838547741595403 	-0.00854643924540077898 	-0.00311837434025636013 	0.00638201655108370635 	0.00754628751573688424 	-0.00801299059807394388 	0.00976747753260353083 	0.00557945832622598354 	0.00675698139843258164 	-0.00560185246073486524 	-0.00964174761582759464 	-7.80623115802624038e-05 	0.00871036682392008037 	-0.00725561868064580548 	0.00559531193002933518 	-0.00346921625696461865 	0.00740028832034525432 	-0.00169509809182802015 	0.00873888335497757102 	0.00140994409075873494 	0.000764624405132729979 	0.00994480655086805825 	0.00577877274202991901 	4.74923655357136959e-05 	0.0011353196069151506 	0.00198775187931363694 	-0.00960880431385865638 	0.00658056776284521566 	-0.00755775334700503273 	0.00570729827446314446 	-0.00240907164842276734 	0.00409745863965042725 	
-0.0101580843643666804 	0.00220138685265901506 	0.00692342144895578045 	0.00135253779638701581 	0.00758775338859351851 	-0.00865001298121899007 	0.00640432763468906565 	0.0073460586540288822 	0.00283515709363264898 	-0.00681396943575839856 	0.00820134115900921293 	0.00112607669227921393 	0.00574348711096823398 	-0.00194574531389705811 	0.00329305905762568817 	0.00804650884764271553 	0.00239784445053587304 	0.00133416850160433245 	0.00696031416500525382 	-0.00361325852754340766 	0.00317535270330150578 	0.00103041205817527436 	-0.00107245742990319179 	0.00824480614344477378 	-0.00809761517277059889 	-0.00879378992409047752 	-0.001666700745558108 	-0.00611935317774526394 	0.00666747922470936009 	0.00432649046970583293 	-0.00400025833426162231 	-0.00463514088619843348 	-0.0079062264555447067 	0.00944076042171451517 	-0.00757762707639256846 	-0.00123984285446245143 	-0.00897459440508197211 	0.000655808806812932781 	0.00231099853159869245 	-0.00825376021216044781 	-0.00174048155380268415 	0.00564452860462577328 	0.00216398564598699068 	0.00972317260517675808 	0.0005894678762475515 	-0.00478986565376872571 	-0.00236489833631729068 	0.00300955478073557537 	0.00195524074096567512 	-0.008242175021364 	0.000893913377985542366 	0.00245114206440323395 	-0.00658616856263531582 	0.00207207872110719412 	-0.00590827784857623703 	0.0011243017725706564 	0.00526390526226897665 	0.00672078045843925789 	0.00946230513202510858 	-0.00944895595370550713 	0.00809963710105650325 	0.00668437931449794229 	0.00840677515883615084 	0.00155183361481183628 	0.00554616377539399619 	0.00369188595568001928 	0.00893215807626812804 	0.0038724076595626016 	-0.00037357198734062414 	-0.000527998815233036468 	-0.00956064192855578081 	0.000329684082084518717 	0.00668352527862810502 	0.00965851149565611841 	0.00987050937326929348 	-0.0099791740953306448 	-0.00523683447063627659 	-0.00363046515829083902 	-0.000876817464300999236 	-0.000631879126818990543 	-0.000721424646885170237 	-0.0028956935867619593 	-0.00880904917847242369 	-0.00291213218439031248 	0.00754820876362416286 	-0.00574797924889403674 	-0.00355974802588750845 	0.00773960097716254198 	0.000825076402684549767 	-0.00337517142319696765 	0.00729551532351534106 	-0.0057509537499364459 	0.00784142735362793053 	-0.000854038366632214711 	0.0055918402973764306 	0.00466771002147996824 	-0.00891365004316409248 	0.00999552474884863457 	0.0055919687039443864 	-0.00440332167642452834 	
]
;
bias = 2 [ -0.0027464009200991687 0.00274640092009921163 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
