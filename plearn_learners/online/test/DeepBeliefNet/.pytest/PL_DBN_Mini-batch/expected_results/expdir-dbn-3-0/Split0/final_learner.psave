*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ -0.0366666666666666669 0.00666666666666666102 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ 1.53902645376136871 1.53287975428339629 -0.0312147953074692446 -0.0294089837995962014 -0.0332254359754929479 -0.0312729910165803898 -0.031337297801657657 -0.0322931732664276522 -0.0307168476645442133 -0.0299032370506452719 -0.0322362597564401221 -0.0300658087861667284 -0.0337132966902711079 -0.0330063519633913213 -0.0319526809075127843 -0.0305010601914717933 -0.0300595751302068989 -0.0333453981731375165 -0.031189436649062794 -0.0336975121433344196 -0.0298852413171584765 -0.0305994805190471578 -0.0320663224992080997 -0.0310699420524318121 -0.030584652837473407 -0.0334023993667867669 -0.0326828630412137472 -0.0335795035960490401 -0.0304638120370469452 -0.0317220858809491094 -0.0316265756182914151 -0.0292071758059737133 -0.0325445124058321641 -0.029013888976878191 -0.033183672118466935 -0.0328873465337548229 -0.0309734938745898115 -0.0317100129632481575 -0.0292539910023831874 -0.0313268334355716674 -0.0299027173724071768 -0.0322582052551700776 -0.0303201886035900474 -0.0311813892235213268 -0.0298693303330919979 -0.0334306704042711608 -0.0311465322109097838 -0.0338524031445776655 -0.0314481349918532271 -0.0332346913193916696 -0.0331844403669249235 -0.0338359999766364022 -0.0334772946143155892 -0.0326980273258471177 -0.0306676619914250277 -0.0308017325675320995 -0.0284511445660079014 -0.0324489420355161678 -0.0300073084557735716 -0.0301922490262648557 -0.0310712384174130704 -0.0321749457907859679 -0.0323690439605787972 -0.0301330257416131397 -0.0292590804159707125 -0.0311920075101714996 -0.0297501091442765597 -0.0316610623392811 -0.0311612496890834763 -0.0337225971049988568 -0.0296801177648348541 -0.0304676212840513418 -0.0305221824006458066 -0.0305090406317516799 -0.0308619966007405155 -0.0295263822097292898 -0.0323008750762722244 -0.0320545738378344852 -0.0307710263448516402 -0.030137673139787536 -0.0314795380785417023 -0.0318584641026296855 -0.0309334555960045672 -0.0291118716229199805 -0.0323765044863651361 -0.0286353177034468567 -0.0308329579852668588 -0.031553786794131268 -0.0310879002563737676 -0.0301110316176923624 -0.0308590144816007807 -0.0309979789761982427 -0.03291144265784475 -0.0317489009060902619 -0.0322338900012070564 -0.0311316805018305547 -0.033228271245262099 -0.0312443584642127445 -0.0310961107000570017 -0.0298148705216259614 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
0.79462416258962465 	0.708714243527043597 	
0.761998366676349015 	0.740775020620458968 	
0.0226943280880259717 	-0.0447216182192758244 	
-0.10009407462972382 	-0.0438497816063247309 	
0.0703707575926479229 	0.0334548677323289537 	
0.0476428910453497237 	-0.0672954006544962124 	
0.0511830682459991013 	-0.0669563184281088825 	
0.0801683150285066315 	-0.0350901897856310818 	
0.0297700754459803221 	-0.0863071571688051042 	
-0.0884358798295634407 	-0.0205168498180810371 	
0.0457300090726118977 	-0.00208590229100311846 	
-0.105186540949654017 	0.006732431702763466 	
0.0575563274048417409 	0.0754245728078506705 	
0.0315579437060435203 	0.0598837553157687899 	
0.0706343225711335149 	-0.0470730124064806105 	
-0.00421645301082355407 	-0.0650203148334948522 	
-0.0444050850121608179 	-0.0540511413881740455 	
0.0773087287795562877 	0.0335183768639642499 	
0.00186554106834445734 	-0.0244995991630909751 	
0.0798908511929773829 	0.0519485452565484548 	
-0.0404751825032169527 	-0.0704307226449379931 	
-0.0702394663586567713 	0.00879089047462784309 	
0.0226487394230743266 	0.0108431732277497316 	
0.0410553313229231956 	-0.0741763522916748241 	
-0.0940903046347904976 	0.0311470759934990814 	
0.0590918674143132289 	0.0558994235960910898 	
0.0318667714006530753 	0.0399381174535612532 	
0.0583437399332065801 	0.0672624822911873227 	
-0.00387367108475061709 	-0.0680596541373065939 	
0.0353481012032452399 	-0.0242762383155908402 	
0.083386517156818496 	-0.082302162135573731 	
-0.0769547663495500217 	-0.081524334781875582 	
0.0377948276579106596 	0.0255837394320384687 	
-0.106816981343190745 	-0.0657179439567690954 	
0.0399753496513197276 	0.0623108236320968623 	
0.00290332606056676679 	0.08133074804665473 	
-0.0704222816215416686 	0.0336047028930634359 	
0.0691918342425827532 	-0.0611797083510401407 	
-0.0870383227439321255 	-0.0679638727055128233 	
-0.0306499782137995141 	0.0176249314951256002 	
-0.0141853244497741303 	-0.0967429104019290886 	
0.0121371252759188818 	0.0335667972566529998 	
-0.00635787894805693154 	-0.0753529140981873957 	
-0.107360916545427676 	0.0818040613513960208 	
-0.0253387487790428627 	-0.0872369130621838129 	
0.0452598136045025967 	0.0716463224903839818 	
-0.0317748574273547177 	0.00693568372810476983 	
0.0678199164401574323 	0.0733700685586171908 	
-0.0538775004412728534 	0.0479114135103793429 	
0.0642549430671540273 	0.0405568825393273005 	
0.0805876143191117528 	0.0204575116057137754 	
0.0718049811619611705 	0.0684355624851287758 	
0.0821990644715877711 	0.0363721051404711296 	
0.0462311843960937913 	0.0260791998330627967 	
0.0394038995096594249 	-0.0999389675785798404 	
0.0136507259485087098 	-0.0631992131473531477 	
-0.102976822434378459 	-0.111547534488010386 	
0.00382928876327718075 	0.0537300023582303332 	
-0.0405719525474573933 	-0.0616964972800696718 	
-0.0139044957155045681 	-0.0761367303277837026 	
-0.0386525129667407846 	0.00858319571692932326 	
-0.0148752188040222021 	0.0554537101395898707 	
0.0396963613959412723 	0.0124229888629342044 	
-0.0240123528480145863 	-0.069796346852707955 	
-0.106957235807517578 	-0.0477874390598453103 	
-0.0954916388431744922 	0.0714313522539851836 	
-0.0264248652925035306 	-0.0946935663866832755 	
-0.00299625944636697705 	0.0110374205950532541 	
-0.00126753154630362638 	-0.023162089752242758 	
0.0800663163332292899 	0.0530678501692746982 	
-0.0200502363615609122 	-0.106442809755268306 	
-0.0960408266959102835 	0.0251383747863423365 	
-0.0705169052477177538 	0.00392991003699512485 	
-0.0188168034216517552 	-0.0493735234870806283 	
0.0119816962908368373 	-0.0571501697112642218 	
-0.0533613095498321269 	-0.0824821516515972797 	
0.037601890176097448 	0.0106255616686625007 	
0.0578390563376181485 	-0.026544430348332905 	
0.0540839976398827249 	-0.109157006150016195 	
-0.0785395659553341924 	-0.0141935715313082876 	
-0.00915496268241485639 	0.00592599973018796081 	
0.028692236865362649 	-0.00861361276408664084 	
-0.0870776017849616557 	0.047204941361393235 	
-0.0900678405487130573 	-0.0752326945865099961 	
0.0480986783680973085 	0.00429041514857957888 	
-0.0954333095600831266 	-0.105148324559747111 	
0.0177957040907608458 	-0.0651098337754503209 	
-0.027414448415076783 	0.0287391027379765053 	
-0.000959124330880182954 	-0.0283703541737347111 	
-0.0928532700604430689 	-0.00180532451434606864 	
-0.0437055843389625165 	-0.000204179264151569566 	
0.00394504798016846129 	-0.0394027362192218775 	
0.0179031403969577736 	0.0678102918079838274 	
0.00338295098680184946 	0.0104645816629280099 	
-0.0335755941582558393 	0.0770737654427485486 	
0.0362969814104082827 	-0.0646396942668429481 	
0.0457373159154405157 	0.0589930110876363406 	
-0.0679740552805807308 	0.0485994264692320571 	
0.0401347630464296556 	-0.0713543483124261801 	
-0.0254079337733598767 	-0.0909656505381771646 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
-0.00194486746516770023 	-0.00690309077309282301 	-0.00129917141308795643 	-0.00774035838581879892 	0.00287387832640887114 	-0.00781964883705902301 	-0.00358354802922155723 	0.00426866842059896081 	-0.00514602812731984691 	-0.00242892329329646127 	0.00989872933524002518 	-0.00948315263269114764 	-0.00660574718922594256 	-0.00685777843444654051 	-0.00810556413843992185 	0.00101876209609721427 	-0.00562525674839697235 	-0.0015737748237753587 	0.00902208120517115908 	-0.0011981899890972517 	-0.00780467806644808207 	0.00031782479332407421 	-0.00937279690427458324 	-0.00186247670944258785 	0.00742200220466920219 	-0.00123865006690160578 	-0.00646949922289207207 	0.00814384698228735882 	-0.00660847791658081014 	0.00860634267371974959 	0.00813096270192557695 	0.00274439892910540795 	0.0003300633112460526 	-0.00749985120846198994 	0.00320564686823331417 	0.000944462847820864808 	-0.0070524086922477882 	0.00962798872911302395 	0.000486159004431979094 	0.00249048994039886449 	-0.00859850276346362831 	-0.00436486723219704515 	-0.00287069829213080661 	0.00710249870539886915 	0.000692800347361197458 	0.00578689503731380853 	0.00376367335259855879 	0.00383933303037925066 	-0.00590335896931601465 	-0.000844442549739712455 	0.00479513619971176901 	0.00772626865924771165 	-0.0083658845931873331 	-0.00879901725232397 	0.00488312872858213259 	-0.0089311071118296035 	-0.00883186741233565366 	-0.000243088710357947948 	-0.00120019664017580316 	0.00370805705714521419 	-0.00412217491304890486 	0.00481781229905189207 	0.00191006771939728859 	0.00845790860981385402 	-0.00575300216332364032 	0.00215541415757722647 	0.00753616516304099308 	-0.00899082282992851728 	0.000129345537143261161 	-0.00808639127158941595 	-0.00293933319580840955 	0.00662716406584913306 	0.00779317700209307667 	-0.00776854909378277281 	0.0100406096748009467 	0.00574381738844291761 	0.0071309018832318976 	-0.00524228595476171084 	-0.00936920073022265605 	0.000137690697849392278 	0.00902771310466269142 	-0.00691149812494487852 	0.0058778936514806172 	-0.00334138263363737646 	0.0077793939497520035 	-0.00161011058928650403 	0.00901063999725531389 	0.00173327713431316007 	0.00105346535294773523 	0.0101596134780142025 	0.00605066170878855707 	0.000330079813410994751 	0.00154852204530678077 	0.00232393712931801104 	-0.00923552789717206092 	0.00687569179944930078 	-0.00712623014494468722 	0.00601157034614300569 	-0.00211605889135666218 	0.00428703523455266702 	
0.00311307565727032484 	0.0155194036503678995 	0.0066241190515251118 	0.0011983013261135276 	0.00715606864434450204 	-0.00895651914613020822 	0.00609305344269421047 	0.00696831021831824816 	0.00257067869210961643 	-0.00701061369637004644 	0.0078312941997284724 	0.00091428781402874801 	0.00528415255326995272 	-0.00236408994552634233 	0.00293823343939841929 	0.00780171280607068734 	0.00218948549264305235 	0.000895157419001529485 	0.00666395750407443917 	-0.00407208356597290894 	0.00298111974056882237 	0.000777296923756397892 	-0.00143021608332421428 	0.0079535262465052943 	-0.00835245947351073541 	-0.00923554404440090314 	-0.00206469306633367189 	-0.0065714483411406276 	0.00642558532954491668 	0.00399094141046618753 	-0.0043372705508410098 	-0.00477148240611077745 	-0.00829566855156123328 	0.00932159859808398723 	-0.0080067904949157713 	-0.00165318119425271297 	-0.00925784966646914752 	0.000316441781400469762 	0.0021706638334572188 	-0.00856077693519882894 	-0.0019378246218799914 	0.00527388133892518155 	0.00193318292530832419 	0.00941667707646952346 	0.000395595260296533618 	-0.00523363791188400339 	-0.00265835526917071333 	0.00254242244550691686 	0.00163716384902611598 	-0.00867429181596196357 	0.000463621286296348335 	0.00198486486180250504 	-0.00703293842965505706 	0.00167311767946725417 	-0.00617098097023980469 	0.000855583884376374146 	0.00519611144871211586 	0.00633683579997489522 	0.00925814186649493755 	-0.00966949297397879 	0.00781184798105079899 	0.00631747927919625203 	0.00802870155126864972 	0.00133668666898569552 	0.00540493766900438256 	0.00338702003096007708 	0.00874804684135233566 	0.003542580408666526 	-0.000667756072225480189 	-0.000988046789044427255 	-0.00973968307300368367 	8.45365673190943224e-05 	0.00643663579227191345 	0.00941406999136493519 	0.00959737723107187586 	-0.0101435331575475546 	-0.0056107549554355934 	-0.00399003166426399082 	-0.00114936434990594444 	-0.00084763213624864742 	-0.00103877092762778172 	-0.00323981414246291488 	-0.00909163089992367016 	-0.00303996580771755554 	0.00716910313421741281 	-0.00583296675143557802 	-0.0038315046681652561 	0.00741626793360812119 	0.000536235454869546141 	-0.0035899783503431466 	0.00702362635675670387 	-0.00603354119781173651 	0.00742822491523631445 	-0.00119022361663658361 	0.00521856388068984642 	0.00437258598487588138 	-0.00934517324522442586 	0.00969125267716877334 	0.00529895594687826692 	-0.00459289827132676378 	
]
;
bias = 2 [ 0.000349142846218535117 -0.000349142846218485027 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
random_gen = *3  ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
