*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.0566666666666666707 0.0600000000000000047 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -3.67929816976774804 -3.66824487525477094 0.0750909232339263683 0.0795841166700319153 0.0708342668804167186 0.0750421938062638266 0.0749057540871664318 0.07281350621284427 0.0763556633275116886 0.0782689083009728281 0.0728246431246861031 0.0779183009350939149 0.069900033259396116 0.0712420215383051392 0.073542444248528932 0.0767792116507820116 0.0778439304287265044 0.0706109057057301009 0.0751034493617696725 0.0699400576141234881 0.0783087691931432239 0.0765286316068690131 0.073159353333281496 0.0755157467085580958 0.0766351376284479802 0.070479449352692139 0.0718806226985668067 0.0701457067916425731 0.0768776599755876117 0.0739384583091209358 0.074377412917112945 0.0801217793115618082 0.0721628274764351402 0.0806814897703578837 0.0708951835495260363 0.0715097933984782524 0.0756688379895598257 0.0740952778784406269 0.0799916253106679881 0.0747857117152906786 0.0783304419111606337 0.0727520148249376497 0.0772393904668482317 0.0753918317216105277 0.078382191594497691 0.0704261841624362062 0.0751946302171443148 0.0696449037214908473 0.0745767703531106385 0.070806479283302623 0.0709348311649994623 0.0696759908129132854 0.0703636071845372274 0.0718591719674553236 0.0765280528752297073 0.0760744758082740474 0.0823326087023871639 0.0723685391237849779 0.0779853133866276194 0.0775462066951605328 0.0753792470513584278 0.0729536446087890034 0.0725329279936358651 0.0776784049340394911 0.0800016351796151021 0.0753005795642522208 0.0787062629788652796 0.0740323485729651315 0.0751659610584929916 0.0698937309834748721 0.0789209919201119547 0.0769177427996143859 0.0767115469459719035 0.076730475615456234 0.0759158170119265813 0.079254120119077634 0.0726706650970279228 0.0732572878386490711 0.076356245513700613 0.0776622930565265546 0.0744300500286751571 0.0736199596196006334 0.0758170804080609134 0.0803895298645544015 0.0725294734781802286 0.0817744617003312163 0.0760032369969883548 0.0742856132339138608 0.0753395223184903928 0.0777583837745135925 0.0758727019124877528 0.075561348375963483 0.0714384499890213659 0.0738360175084723652 0.0728876094213855852 0.0753375538997586996 0.070809484771196099 0.0750639894616385306 0.0754455419716839742 0.0785276661645328 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-0.520385419257819781 	-0.607667740189380523 	
-0.547335303272597051 	-0.574510722075016744 	
0.0504029420063143579 	-0.0174374020209189066 	
-0.0726720177154327324 	-0.0166870493884907455 	
0.0985284220175968173 	0.0611863005277123242 	
0.0754034367023085489 	-0.0400349156555762711 	
0.0789734219571437829 	-0.0396774616380166784 	
0.108170790392739927 	-0.00765013072823587503 	
0.0574395119975671942 	-0.0591070156090361884 	
-0.061007039891299214 	0.00667184762083029067 	
0.0736287540104566957 	0.0253895592031331205 	
-0.0777417566768631441 	0.033988152696632544 	
0.0857932600234043719 	0.10336889613750673 	
0.0595732996791215608 	0.0876320649751073794 	
0.0985639370941749221 	-0.0196922373217131783 	
0.0233660805474359655 	-0.0378252019980260187 	
-0.0169121891224506757 	-0.0268755261362537863 	
0.105509436301355383 	0.0612729979063185298 	
0.0295185514598919028 	0.00279503185259740924 	
0.108172318468795839 	0.0798166168810517801 	
-0.0129827416114516904 	-0.043273012491637404 	
-0.0427436926119571375 	0.0360769453606456375 	
0.0504779492722270892 	0.0383236706034821711 	
0.0687895317968882092 	-0.0469326547384686793 	
-0.0666313507642620623 	0.0584517370219266724 	
0.0872457685108091324 	0.0837080805890952351 	
0.0598201510048938442 	0.0675784349064649376 	
0.0865288471252173008 	0.0951316360468640737 	
0.0237140180718280573 	-0.0408629407609415601 	
0.0631379942820747275 	0.00308499348420874066 	
0.111272744450818944 	-0.0550198793991546892 	
-0.0495399255127684443 	-0.0544110084214884521 	
0.0657230040930184001 	0.0531562468007424349 	
-0.0793895470235106288 	-0.0385651446308253806 	
0.0680320003763357217 	0.0900858662837026314 	
0.0308277344266279299 	0.109102377743976534 	
-0.0428935242523314705 	0.0609697782115297265 	
0.0970561821731235064 	-0.0338666308471151228 	
-0.0596192092162303872 	-0.0408316442859519985 	
-0.00304223746333419842 	0.0449917804586676198 	
0.0133410948519769677 	-0.0696020236616901877 	
0.039977823239458643 	0.0611241954582473629 	
0.0212044378814250332 	-0.0481804311018778769 	
-0.0798320840154110589 	0.109307593668522079 	
0.00216013628189292914 	-0.0601016310390021097 	
0.0733821940828805058 	0.099497308314277666 	
-0.00418577457569986513 	0.034267274973199667 	
0.0961049167980579933 	0.101328682742033521 	
-0.0262656255829718105 	0.0753752819357316889 	
0.0923863548467529772 	0.0682949741016277007 	
0.108756281771888105 	0.0481458386888888659 	
0.100093215436711416 	0.0963736142319992356 	
0.110441408196684354 	0.0641597539760613289 	
0.0742272888131287473 	0.0536989130170025392 	
0.0670662090171207786 	-0.0727680558490813728 	
0.0412975622692688671 	-0.0359736262889523289 	
-0.07553369573227528 	-0.0843988974337768205 	
0.031683218853364746 	0.0813611862515050827 	
-0.0130739435676640071 	-0.0345269882482395971 	
0.0136140272169084781 	-0.0489930421672095315 	
-0.0110617238790147124 	0.0359297344246217523 	
0.0128932585850817134 	0.0830364377215482702 	
0.0676125872825022595 	0.039953970286474183 	
0.00349451945220510905 	-0.042645481572695855 	
-0.0795372606084337602 	-0.0206274492374718503 	
-0.0679556269290350762 	0.0989090112668678245 	
0.00106926327384114094 	-0.0675641733945039902 	
0.0247260524176569838 	0.0384630055092971893 	
0.0263782253284606909 	0.00413268501827161912 	
0.108363320390186396 	0.0809527489082843138 	
0.00744067734895160083 	-0.0793276345356500878 	
-0.0685828648959103254 	0.0524331672735785029 	
-0.0430299179219996233 	0.0311991517220432529 	
0.00875455007682278755 	-0.0221527377393929692 	
0.0396190903019199014 	-0.0299243858711141751 	
-0.0259299398002285457 	-0.0553743962254750755 	
0.0654815998567056939 	0.0381233449386994203 	
0.0857406226041131786 	0.000868266886166540347 	
0.0818156967821113135 	-0.0819606571238428866 	
-0.0510867284702254815 	0.0130209282921754654 	
0.0185073534397708732 	0.0332937538289315854 	
0.0564972252169523848 	0.0187982842748549012 	
-0.0595800360354162978 	0.0745776702050969659 	
-0.0626526219961449915 	-0.0481068295040314869 	
0.0760290724928658762 	0.0318015323295316593 	
-0.0680175615269424105 	-0.0780292036804604849 	
0.0454265273931732799 	-0.0379064295013739685 	
0.000245257330670842243 	0.0561754669591406422 	
0.0266789063222490318 	-0.00109026801003190839 	
-0.0654262101077237451 	0.0254095633358379092 	
-0.0161558737254881811 	0.0270927473390010463 	
0.0315749936922243846 	-0.0121516449151251368 	
0.0458707558030447271 	0.0955607640219145738 	
0.0311126203336938266 	0.0378846159519728512 	
-0.00581538096481792107 	0.104733200172821811 	
0.0640125283786390359 	-0.0373943635204284225 	
0.0738255534250779194 	0.0867777875959012679 	
-0.0404066042800288877 	0.0760341306135597778 	
0.0678668982597476489 	-0.0441082122306330204 	
0.00207766362528058642 	-0.0638437672563030162 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0113262925564693046 	0.00641492602461607182 	-0.00159847381051862942 	-0.00789459485609226956 	0.00244219358215985944 	-0.00812615500197023596 	-0.00389482222121642196 	0.00389091998488833198 	-0.00541050652884287209 	-0.00262556755390811651 	0.00952868237595928119 	-0.00969494151094163654 	-0.00706508174692422036 	-0.00727612306607582256 	-0.00846038975666717902 	0.000773966054525185103 	-0.00583361570628981082 	-0.00201278590637816524 	0.00872572454424036872 	-0.00165701502752675081 	-0.00799891102918076635 	6.47096589051986929e-05 	-0.00973055555769559467 	-0.00215375660638213347 	0.00716715790392904832 	-0.001680404187211998 	-0.00686749154366765591 	0.00769175181889198388 	-0.00685037181174525441 	0.00827079361448006603 	0.00779395048534614783 	0.0026080574091930527 	-5.93787847705065132e-05 	-0.0076190130320924563 	0.00277648344971009181 	0.000531124508030603811 	-0.00733566395363501739 	0.00928862170370055307 	0.000345824306290504408 	0.00218347321736047728 	-0.00879584583154094032 	-0.00473551449789763948 	-0.0031015010128094731 	0.00679600317669165534 	0.000498927731410179305 	0.00534312277919853432 	0.00347021641974513614 	0.00337220069515059215 	-0.00622143586125560415 	-0.00127655934433769662 	0.00436484410802257493 	0.00725999145664699315 	-0.00881265446020709428 	-0.00919797829396393901 	0.00462042560691856407 	-0.00919982500002390277 	-0.00889966122589246761 	-0.000627033368822296744 	-0.00140435990570596876 	0.00348752003687192004 	-0.00440996403305462647 	0.00445091226375020094 	0.0015319941118297879 	0.00824276166398773061 	-0.00589422826971325569 	0.00185054823285728774 	0.00735205392812524408 	-0.00932065008082455515 	-0.000164838547741596135 	-0.00854643924540077551 	-0.00311837434025635969 	0.00638201655108370895 	0.00754628751573688337 	-0.00801299059807394562 	0.00976747753260353083 	0.00557945832622598354 	0.00675698139843258425 	-0.00560185246073486697 	-0.00964174761582759464 	-7.80623115802627968e-05 	0.00871036682392008384 	-0.00725561868064580808 	0.00559531193002933518 	-0.00346921625696461778 	0.00740028832034525172 	-0.00169509809182802015 	0.00873888335497757969 	0.00140994409075873408 	0.000764624405132731822 	0.00994480655086805825 	0.00577877274202991901 	4.74923655357142787e-05 	0.00113531960691515082 	0.00198775187931363737 	-0.00960880431385865812 	0.00658056776284521652 	-0.00755775334700503447 	0.00570729827446314186 	-0.00240907164842276648 	0.00409745863965042811 	
-0.0101580843643666735 	0.00220138685265899988 	0.00692342144895578479 	0.00135253779638701537 	0.00758775338859351851 	-0.00865001298121899007 	0.00640432763468906825 	0.0073460586540288822 	0.00283515709363264812 	-0.0068139694357583977 	0.0082013411590092164 	0.00112607669227921393 	0.00574348711096823051 	-0.0019457453138970579 	0.00329305905762568817 	0.00804650884764271379 	0.00239784445053587 	0.00133416850160433375 	0.00696031416500525121 	-0.00361325852754340766 	0.00317535270330150622 	0.00103041205817527566 	-0.00107245742990319201 	0.00824480614344477725 	-0.00809761517277060063 	-0.00879378992409048099 	-0.001666700745558108 	-0.00611935317774526567 	0.00666747922470935835 	0.0043264904697058338 	-0.00400025833426162318 	-0.00463514088619843001 	-0.00790622645554470496 	0.0094407604217145117 	-0.00757762707639256846 	-0.00123984285446245295 	-0.00897459440508197558 	0.000655808806812931914 	0.00231099853159869245 	-0.00825376021216044954 	-0.00174048155380268545 	0.00564452860462577415 	0.00216398564598699284 	0.00972317260517676155 	0.0005894678762475515 	-0.00478986565376872571 	-0.00236489833631728895 	0.00300955478073557494 	0.00195524074096567555 	-0.00824217502136400347 	0.000893913377985541715 	0.00245114206440323265 	-0.00658616856263531496 	0.00207207872110719196 	-0.0059082778485762379 	0.00112430177257065445 	0.00526390526226897665 	0.00672078045843925789 	0.00946230513202510858 	-0.0094489559537055054 	0.00809963710105650672 	0.00668437931449794315 	0.00840677515883614737 	0.00155183361481183758 	0.00554616377539399793 	0.00369188595568001798 	0.00893215807626812457 	0.003872407659562599 	-0.000373571987340624682 	-0.000527998815233036035 	-0.00956064192855578254 	0.00032968408208451953 	0.00668352527862810675 	0.00965851149565612362 	0.00987050937326928828 	-0.00997917409533064133 	-0.00523683447063628092 	-0.00363046515829083816 	-0.000876817464300998911 	-0.000631879126818990543 	-0.000721424646885172405 	-0.00289569358676195973 	-0.00880904917847242369 	-0.00291213218439031335 	0.00754820876362416199 	-0.00574797924889403674 	-0.00355974802588750888 	0.00773960097716254111 	0.000825076402684549659 	-0.00337517142319696678 	0.00729551532351534193 	-0.00575095374993644676 	0.00784142735362793226 	-0.000854038366632214494 	0.00559184029737643234 	0.00466771002147996564 	-0.00891365004316409248 	0.00999552474884863457 	0.00559196870394438553 	-0.00440332167642452574 	
]
;
bias = 2 [ -0.00274640092009917911 0.00274640092009921337 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
