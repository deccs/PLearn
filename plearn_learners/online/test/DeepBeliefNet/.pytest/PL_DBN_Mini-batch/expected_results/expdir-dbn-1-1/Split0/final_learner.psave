*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 1.17000000000000082 0.900000000000000577 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -4.32711526727717022 -4.3372701645486238 0.0884972513670912453 0.0931047158365755634 0.0841804577845747942 0.0884423692492627839 0.0882859838041619854 0.0861706449956605863 0.0897606441010612016 0.0917997185462621629 0.0862172150073365201 0.0914492689853110274 0.0832344574341433024 0.0846255461316875179 0.086897933435698016 0.0902140465230860666 0.0913138521627376021 0.0839526766363259125 0.0885437376916390906 0.0832835086330831892 0.0917704045377616545 0.0900370148671758574 0.0865570415437719592 0.0889061535637738487 0.0901933883949007087 0.083855126464766741 0.0852683942355133007 0.083532078336021498 0.0903033950528041307 0.087349502272501281 0.0877663854611010485 0.0936361074968803525 0.0855698088882395069 0.0941943261400616239 0.0842970734238651792 0.0849357771997706346 0.0891822142770181264 0.0874879941894524393 0.0935054566357249178 0.0882701258129414135 0.0917743293773878727 0.0861543718441722672 0.0906792393721227302 0.0889428130004461664 0.0918448751690769255 0.0838195887654502175 0.088673345702564188 0.0829929657926603698 0.0880565159446428936 0.0841799095124265706 0.0842893022098406414 0.0830294042875595467 0.0837011826816978638 0.0852232267568197449 0.0899532197532659367 0.0894885518089336696 0.0958346480546612284 0.0857821218519718293 0.0914478410021243027 0.0910177787617019729 0.0888371373050060309 0.0863973972481843211 0.0859149352705649016 0.0911501112497726668 0.0935250257635063392 0.0888385233716558198 0.0921673857226444071 0.0874503485910435724 0.0886068150786281233 0.0832175599229860452 0.0923866976451308552 0.0904643653202136522 0.0902225674836392155 0.0901632676756105172 0.089346078747887997 0.0927602015627450316 0.0860875669223204326 0.086636914767091594 0.0897427212560572563 0.0911794384643066502 0.0878912474958726958 0.0870217265658023015 0.089368170197947544 0.0939061363420257006 0.0859158022475398631 0.0952932285977266119 0.0894471842536392059 0.0877395566357450918 0.0887800292092797427 0.0913084084576755023 0.089352658573633309 0.0890067708000333718 0.0848339068749338343 0.0872732569112319445 0.0863292264483929844 0.0887496467528825772 0.0841889624230460348 0.0885658836328168247 0.088839997890117095 0.0920015433771734364 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-1.24792831633213597 	-1.39735089256445932 	
-1.2613956625633862 	-1.38981579762817375 	
0.0761048699587760225 	0.00801901792621093762 	
-0.0437362423957267515 	0.0100258312296207363 	
0.122341829544572872 	0.0843382980897796897 	
0.100681906572919158 	-0.0142979123332143618 	
0.104194045090286028 	-0.0139423394592549325 	
0.132369740996299834 	0.0170023995994674736 	
0.0833785830127285188 	-0.0326773524247471261 	
-0.0326950623956562686 	0.0326269485130347772 	
0.0983250247890316564 	0.0495618447986045443 	
-0.0492018798408611485 	0.0594823721799443636 	
0.109567946177656486 	0.125725738863893627 	
0.0840674972530368464 	0.110534760298992382 	
0.12312706019800275 	0.00537144577668966644 	
0.0499502891283985229 	-0.0115941354457338875 	
0.0106130835455938467 	-0.000502204039447316742 	
0.129155197592288079 	0.0843559859284681718 	
0.0555094106422285502 	0.0279252235392405679 	
0.131579496299484372 	0.102446402857112664 	
0.0146207819569676885 	-0.0165110880938397521 	
-0.0152098035716024798 	0.0611314970453571208 	
0.0756480514037247004 	0.0624429547810556249 	
0.0943313046294627644 	-0.0209162148785304661 	
-0.0387538020308656958 	0.0831676274390826392 	
0.111079692147122572 	0.106413612787671669 	
0.0844859003750915022 	0.0909281536163425025 	
0.110255534107209507 	0.117569964096915211 	
0.0503402481910374192 	-0.0145363440385552298 	
0.0882877347052690442 	0.0278747608862448884 	
0.13579989243262322 	-0.0293047418304829208 	
-0.0208853376616612955 	-0.0270185613474963164 	
0.0903303247636411538 	0.0767358706059570739 	
-0.04999537211703068 	-0.0111852725638231943 	
0.0922451774733284852 	0.112807474834139387 	
0.0557920505124698748 	0.13176204053668622 	
-0.0156166793851998647 	0.085422366288600074 	
0.121727203196954181 	-0.00852357251789235063 	
-0.0308060743325063273 	-0.013656142939411418 	
0.0233263322247821842 	0.0694023941057379939 	
0.0405156370159508103 	-0.0424488523830184525 	
0.0652001999783928532 	0.0848180390433775772 	
0.0479443611943429562 	-0.0216705924806779755 	
-0.0520331275937088097 	0.133010909353283802 	
0.0295060359707903092 	-0.0331018324098504846 	
0.0973891803189232824 	0.121966636503981624 	
0.0223348997781607252 	0.058958206082786721 	
0.119610467943873047 	0.123597553887780973 	
0.000476921336380206943 	0.0993550689442175561 	
0.116236242367810105 	0.0912979105807741886 	
0.132418046816531965 	0.0714706742660448091 	
0.123533091063945721 	0.118700555327761526 	
0.133945660716787401 	0.087131676224561902 	
0.0986966479771140132 	0.0772562696165317725 	
0.0928489721357925596 	-0.0461591939206654617 	
0.0674164705057713198 	-0.00995972789837364786 	
-0.0457363065061925228 	-0.0558365841657046599 	
0.0569120685437913346 	0.104659972014240071 	
0.0144387081701442682 	-0.00799004058277001834 	
0.0405014545351480848 	-0.022447051109867406 	
0.0156885394621569495 	0.0607053011427125325 	
0.0385488185786774379 	0.10645334041582398 	
0.0923477123362821395 	0.0638716009610263563 	
0.0305985475582648929 	-0.0161337302924452024 	
-0.0503582362547266155 	0.0062688895039419313 	
-0.0403763892900047272 	0.122732268245548809 	
0.0285286154269412187 	-0.0403524371964778528 	
0.0505460324818351181 	0.0628354760976757576 	
0.0524402592962677147 	0.0292665783345892605 	
0.131792667337911978 	0.103591992774134056 	
0.0348344614551319917 	-0.0519031455810079895 	
-0.0405527523441988058 	0.0773380740705313652 	
-0.0154457459363229466 	0.0563698254393016004 	
0.0355900832138369844 	0.00386744655745152946 	
0.0656871478796531016 	-0.00408206902396727328 	
0.00206405204327912793 	-0.0282454046662434823 	
0.0902178471958940686 	0.0620365098886469374 	
0.110386287835553584 	0.0255196613515526888 	
0.107379950901278345 	-0.0551879644255911656 	
-0.0230972154790073485 	0.0387229438492729464 	
0.044449321979716315 	0.0577741337594893656 	
0.0816879272017193014 	0.0433059394724301799 	
-0.0320513493983501443 	0.0988418390166333621 	
-0.033678793373187646 	-0.0207102496453733416 	
0.100614235785147152 	0.0558074948349463126 	
-0.0385665850321436632 	-0.0497831257878785238 	
0.0713897633525990005 	-0.0119680204600129698 	
0.026486493415709144 	0.0803429688797962643 	
0.0527857984995237159 	0.0241688198442964464 	
-0.0372283475335263153 	0.0509203961830493809 	
0.0107724740413416079 	0.0520979069590650906 	
0.057648503478319589 	0.0133097617517652072 	
0.0706270442107162499 	0.118412798126190016 	
0.0567206293871870756 	0.0621572219754823949 	
0.020160473323243909 	0.127871237627920936 	
0.0895405314619520387 	-0.0116162226188489346 	
0.0979661989894221458 	0.109552112759567374 	
-0.0133191795274148882 	0.100124728352003506 	
0.0933963703177931454 	-0.0181627406802816228 	
0.0294391786966599518 	-0.0367752161076390013 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.053238693449869097 	0.0806262914109139861 	-0.00322832263047528444 	-0.0091034307405599528 	0.000362212364114244175 	-0.00974991141665568217 	-0.00553090895961827218 	0.00203960694798924419 	-0.00690742803008835907 	-0.00394282619132612245 	0.00766613026441769277 	-0.011021549599272245 	-0.00924724742099556664 	-0.00930398259817479673 	-0.0102344772667839687 	-0.000696014066066441171 	-0.00720779799897976366 	-0.00411788273161691094 	0.00709460022217443462 	-0.00383944268079425407 	-0.00933301520711202551 	-0.00140595604819702198 	-0.0115574854661330828 	-0.00373112402975689502 	0.00573110929815871806 	-0.00379954945814822871 	-0.00882869991630134097 	0.00553558683983973367 	-0.00831084406338638421 	0.0065247246929201622 	0.00612490476129661041 	0.00142932511701680202 	-0.00199249906965874666 	-0.00874289066291807949 	0.000708105471669862236 	-0.00145190000566321697 	-0.00887602388839884258 	0.00757538439212778955 	-0.000839859074017534706 	0.000533248145951293207 	-0.010122585017289425 	-0.006600730991961898 	-0.00452815842694289077 	0.00528765362002428258 	-0.000826747184378848416 	0.00322234347196983725 	0.00185752294625764376 	0.00115790562636331872 	-0.0078704505018446589 	-0.00335996956149444293 	0.00229723571371282442 	0.00504812464862783739 	-0.0109458737169870982 	-0.0111640298400931398 	0.00314859000401087989 	-0.0107333863626845761 	-0.00990496283984226497 	-0.00252614321577472297 	-0.00276674250666862197 	0.00208774392453801947 	-0.00600209242006417235 	0.00262090610153620359 	-0.000361770208588622748 	0.00685332269176408115 	-0.00706721837785403203 	0.000315119951773165207 	0.00605543728940713833 	-0.0110544512908535408 	-0.00178970847570509976 	-0.0107338376993417629 	-0.00439294534012347158 	0.00496981016904086883 	0.00609072055761556916 	-0.0094892060786338113 	0.00821754095252104876 	0.00432696950688535569 	0.00487749096412092194 	-0.00741430702567230475 	-0.011118380498022792 	-0.00145075801315798915 	0.00701661058502487615 	-0.00903557532195551315 	0.00408713070637453744 	-0.00462316435906414899 	0.00550622837347921126 	-0.00274284051463609185 	0.00719964435159268709 	-0.000287628302747018974 	-0.000843487492493124051 	0.00859268413927025305 	0.00423301492662385512 	-0.00153895089395540523 	-0.000865210986956573697 	0.000232639542571767957 	-0.0114273613766537781 	0.0049815735378366836 	-0.00963711400233785605 	0.00411475321119588507 	-0.00399444886549325893 	0.00278501374815410966 	
-0.0520704852577664259 	-0.072009978533638816 	0.00855327026891241141 	0.00256137368085467649 	0.00966773460663913377 	-0.00702625656653353865 	0.00804041437309092194 	0.0091973716909279548 	0.00433207859487812468 	-0.00549671079834038699 	0.0100638932705507892 	0.00245268478060985074 	0.007925652785039582 	8.2114218201916571e-05 	0.00506714656774250906 	0.00951648896823437118 	0.00377202674322583281 	0.00343926532684308336 	0.00859143848707118879 	-0.00143083087427590722 	0.00450945688123279009 	0.00250107776527749674 	0.000754472478534290274 	0.00982217356681956526 	-0.00666156656700028771 	-0.00667464465315429755 	0.000294507627075602169 	-0.00396318819869305537 	0.00812795147635048988 	0.00607255939126580702 	-0.00233121261021206711 	-0.00345640859402216458 	-0.00597310617065646351 	0.0105646380525400863 	-0.00550924909835233834 	0.000743181659231372058 	-0.00743423447031809313 	0.00236904611838570497 	0.00349668191190673173 	-0.00660353514075127067 	-0.00041374236805414525 	0.00750974509869004048 	0.00359064306012042006 	0.0112315221618441846 	0.00191514279203657987 	-0.0026690863465400191 	-0.00075220486282978811 	0.00522384984952284966 	0.00360425538155473811 	-0.00615876480420723439 	0.00296152177229528453 	0.00466300887242236325 	-0.00445294930585530147 	0.00403813026723639189 	-0.00443644224566854591 	0.00265786313523137634 	0.00626920687621874192 	0.00861989030539164758 	0.0108246877329877655 	-0.00804917984137160265 	0.00969176548806604046 	0.00851438547671192966 	0.0103005394792546022 	0.00294127258703543544 	0.00671915388353477427 	0.00522731423676413808 	0.0102287747149861774 	0.00560620886959161801 	0.00125129794062288401 	0.00165939963870793657 	-0.00828607092868861861 	0.00174189046412734513 	0.00813909223674941749 	0.0111347269762160014 	0.011420445953351779 	-0.00872668527598998052 	-0.00335734403632461471 	-0.00181801059335338542 	0.000599815417894180702 	0.000740816574758737609 	0.000972331592010054584 	-0.00111573694545227201 	-0.00730086795481763289 	-0.00175818408229077628 	0.00944226871049019638 	-0.0047002368260860147 	-0.00202050902250264187 	0.00943717337066829302 	0.00243318830031040477 	-0.00202304901159921406 	0.00884127313892139541 	-0.00416451049044531257 	0.00984195794749967087 	0.000901073970109655432 	0.00741039736017155316 	0.00626670424648849683 	-0.00683428938783130994 	0.0115880698121159 	0.00717734592101487625 	-0.00309087678492820641 	
]
;
bias = 2 [ -0.0480886388473655835 0.0480886388473659929 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 1 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
