*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 1.17000000000000082 0.900000000000000577 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -4.32711526727717022 -4.3372701645486238 0.0884972513670912592 0.093104715836575605 0.0841804577845747803 0.0884423692492627839 0.0882859838041619716 0.0861706449956606002 0.0897606441010612016 0.0917997185462621212 0.0862172150073365617 0.0914492689853110274 0.0832344574341433024 0.0846255461316875041 0.0868979334356979743 0.0902140465230860805 0.0913138521627375882 0.0839526766363259125 0.0885437376916390906 0.0832835086330831614 0.0917704045377616684 0.0900370148671758574 0.0865570415437719454 0.0889061535637738626 0.0901933883949007226 0.0838551264647667549 0.0852683942355133145 0.0835320783360215119 0.0903033950528041307 0.0873495022725012532 0.0877663854611010485 0.0936361074968803386 0.0855698088882395069 0.09419432614006161 0.0842970734238651653 0.0849357771997706762 0.0891822142770180987 0.0874879941894524393 0.0935054566357249317 0.0882701258129414273 0.0917743293773878865 0.086154371844172295 0.0906792393721227302 0.0889428130004461526 0.0918448751690769255 0.0838195887654502175 0.0886733457025641741 0.0829929657926603837 0.0880565159446428936 0.0841799095124265567 0.0842893022098406275 0.0830294042875595883 0.0837011826816979054 0.0852232267568197588 0.0899532197532659367 0.0894885518089337112 0.0958346480546612006 0.0857821218519718431 0.0914478410021243027 0.0910177787617019729 0.0888371373050060309 0.0863973972481843489 0.0859149352705648878 0.0911501112497726806 0.0935250257635063392 0.0888385233716558337 0.0921673857226443793 0.0874503485910435585 0.0886068150786280956 0.0832175599229860452 0.0923866976451308552 0.0904643653202136383 0.0902225674836392155 0.090163267675610545 0.0893460787478880109 0.0927602015627450316 0.0860875669223204326 0.0866369147670916218 0.0897427212560572424 0.0911794384643066641 0.0878912474958726958 0.0870217265658022876 0.089368170197947544 0.0939061363420257145 0.0859158022475398353 0.0952932285977265842 0.0894471842536392336 0.087739556635745064 0.0887800292092797427 0.0913084084576754745 0.0893526585736332812 0.0890067708000333441 0.0848339068749338482 0.0872732569112319445 0.0863292264483929705 0.0887496467528825772 0.0841889624230460348 0.0885658836328168386 0.088839997890117095 0.0920015433771734364 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-1.24792831633213641 	-1.39735089256445977 	
-1.26139566256338598 	-1.38981579762817442 	
0.0761048699587760225 	0.00801901792621092548 	
-0.0437362423957267585 	0.0100258312296207294 	
0.122341829544572858 	0.0843382980897796758 	
0.100681906572919172 	-0.014297912333214367 	
0.104194045090286055 	-0.0139423394592549255 	
0.132369740996299834 	0.0170023995994674701 	
0.0833785830127285188 	-0.0326773524247471192 	
-0.0326950623956562547 	0.0326269485130347633 	
0.0983250247890316426 	0.0495618447986045374 	
-0.0492018798408611416 	0.0594823721799443497 	
0.109567946177656472 	0.125725738863893627 	
0.0840674972530368603 	0.110534760298992382 	
0.123127060198002722 	0.00537144577668967425 	
0.0499502891283985506 	-0.0115941354457338875 	
0.0106130835455938329 	-0.000502204039447324223 	
0.129155197592288162 	0.0843559859284681857 	
0.0555094106422285502 	0.0279252235392405644 	
0.131579496299484344 	0.102446402857112651 	
0.014620781956967692 	-0.0165110880938397452 	
-0.0152098035716024937 	0.0611314970453571208 	
0.0756480514037247004 	0.0624429547810556387 	
0.0943313046294627644 	-0.0209162148785304799 	
-0.0387538020308657027 	0.0831676274390826531 	
0.111079692147122572 	0.106413612787671669 	
0.0844859003750914883 	0.0909281536163424886 	
0.110255534107209494 	0.117569964096915225 	
0.0503402481910374122 	-0.0145363440385552316 	
0.0882877347052690303 	0.0278747608862448711 	
0.13579989243262322 	-0.0293047418304829138 	
-0.0208853376616612921 	-0.0270185613474963199 	
0.0903303247636411122 	0.0767358706059570739 	
-0.049995372117030687 	-0.0111852725638232134 	
0.0922451774733284713 	0.112807474834139387 	
0.0557920505124698887 	0.131762040536686248 	
-0.0156166793851998647 	0.0854223662886001156 	
0.121727203196954167 	-0.00852357251789233848 	
-0.0308060743325063342 	-0.0136561429394114215 	
0.0233263322247821737 	0.0694023941057379939 	
0.0405156370159508172 	-0.0424488523830184247 	
0.0652001999783928116 	0.0848180390433775633 	
0.0479443611943429771 	-0.0216705924806779616 	
-0.0520331275937088236 	0.133010909353283829 	
0.0295060359707902987 	-0.0331018324098504776 	
0.0973891803189232685 	0.121966636503981637 	
0.0223348997781607182 	0.058958206082786728 	
0.119610467943873061 	0.123597553887780973 	
0.000476921336380212797 	0.09935506894421757 	
0.116236242367810105 	0.0912979105807741331 	
0.132418046816531965 	0.0714706742660448091 	
0.123533091063945707 	0.118700555327761512 	
0.133945660716787401 	0.0871316762245619159 	
0.0986966479771140132 	0.0772562696165317586 	
0.0928489721357925596 	-0.0461591939206654617 	
0.0674164705057713337 	-0.00995972789837363745 	
-0.0457363065061925367 	-0.0558365841657046738 	
0.0569120685437913346 	0.104659972014240071 	
0.0144387081701442752 	-0.00799004058277002355 	
0.0405014545351480917 	-0.0224470511098674094 	
0.0156885394621569529 	0.0607053011427125255 	
0.0385488185786774309 	0.106453340415823924 	
0.0923477123362821534 	0.0638716009610263702 	
0.0305985475582649033 	-0.0161337302924452197 	
-0.0503582362547266432 	0.00626888950394193043 	
-0.0403763892900047203 	0.122732268245548823 	
0.0285286154269412222 	-0.0403524371964778528 	
0.0505460324818351181 	0.0628354760976757298 	
0.0524402592962677425 	0.0292665783345892501 	
0.131792667337911978 	0.103591992774134042 	
0.0348344614551319917 	-0.0519031455810079895 	
-0.0405527523441988128 	0.0773380740705313791 	
-0.0154457459363229466 	0.0563698254393016143 	
0.0355900832138369774 	0.00386744655745153596 	
0.0656871478796531155 	-0.00408206902396727068 	
0.00206405204327912055 	-0.0282454046662434892 	
0.0902178471958940686 	0.0620365098886469582 	
0.110386287835553543 	0.0255196613515526888 	
0.107379950901278345 	-0.0551879644255911656 	
-0.0230972154790073589 	0.0387229438492729394 	
0.0444493219797162872 	0.0577741337594893933 	
0.0816879272017193153 	0.0433059394724301938 	
-0.0320513493983501305 	0.0988418390166333621 	
-0.0336787933731876529 	-0.020710249645373352 	
0.100614235785147138 	0.0558074948349462988 	
-0.0385665850321436701 	-0.0497831257878785238 	
0.0713897633525990144 	-0.011968020460012975 	
0.0264864934157091371 	0.0803429688797962643 	
0.0527857984995237089 	0.0241688198442964533 	
-0.0372283475335263223 	0.0509203961830493809 	
0.0107724740413416009 	0.0520979069590651045 	
0.0576485034783195821 	0.0133097617517652107 	
0.0706270442107162638 	0.118412798126190044 	
0.0567206293871870618 	0.0621572219754824226 	
0.0201604733232439125 	0.127871237627920936 	
0.0895405314619520526 	-0.0116162226188489415 	
0.0979661989894221319 	0.109552112759567388 	
-0.0133191795274148917 	0.100124728352003464 	
0.0933963703177931454 	-0.0181627406802816124 	
0.0294391786966599553 	-0.0367752161076390013 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0532386934498691039 	0.080626291410914 	-0.00322832263047528618 	-0.00910343074055995106 	0.000362212364114244121 	-0.0097499114166556787 	-0.00553090895961826957 	0.00203960694798923942 	-0.00690742803008835993 	-0.00394282619132612332 	0.0076661302644176893 	-0.0110215495992722432 	-0.0092472474209955649 	-0.00930398259817479673 	-0.0102344772667839652 	-0.00069601406606644052 	-0.00720779799897976973 	-0.00411788273161691355 	0.00709460022217443288 	-0.0038394426807942519 	-0.00933301520711203071 	-0.0014059560481970222 	-0.0115574854661330828 	-0.00373112402975689155 	0.00573110929815871979 	-0.00379954945814822828 	-0.00882869991630134444 	0.00553558683983973367 	-0.008310844063386379 	0.00652472469292016567 	0.00612490476129661301 	0.00142932511701680137 	-0.00199249906965874969 	-0.00874289066291808817 	0.00070810547166986473 	-0.00145190000566321892 	-0.00887602388839884258 	0.00757538439212778435 	-0.00083985907401753579 	0.000533248145951293207 	-0.0101225850172894268 	-0.00660073099196189974 	-0.00452815842694289251 	0.00528765362002427998 	-0.000826747184378847982 	0.00322234347196983508 	0.00185752294625763747 	0.0011579056263633172 	-0.00787045050184466237 	-0.00335996956149444206 	0.00229723571371282529 	0.00504812464862783306 	-0.0109458737169871017 	-0.0111640298400931398 	0.00314859000401088119 	-0.010733386362684583 	-0.0099049628398422615 	-0.00252614321577472253 	-0.00276674250666862241 	0.00208774392453802034 	-0.00600209242006417062 	0.00262090610153620576 	-0.000361770208588623127 	0.00685332269176408982 	-0.00706721837785403463 	0.000315119951773163635 	0.00605543728940713746 	-0.0110544512908535425 	-0.00178970847570510063 	-0.0107338376993417629 	-0.00439294534012347332 	0.00496981016904087317 	0.00609072055761557003 	-0.0094892060786338165 	0.00821754095252105222 	0.00432696950688535222 	0.00487749096412092194 	-0.00741430702567230215 	-0.0111183804980227972 	-0.00145075801315799045 	0.00701661058502487094 	-0.00903557532195551488 	0.00408713070637454264 	-0.00462316435906414726 	0.00550622837347920779 	-0.00274284051463609098 	0.00719964435159268969 	-0.000287628302747019787 	-0.000843487492493124485 	0.00859268413927025132 	0.00423301492662385252 	-0.00153895089395540544 	-0.000865210986956572504 	0.000232639542571764704 	-0.0114273613766537781 	0.0049815735378366862 	-0.00963711400233785431 	0.00411475321119588767 	-0.0039944488654932624 	0.00278501374815411009 	
-0.0520704852577663635 	-0.0720099785336388437 	0.00855327026891241488 	0.00256137368085467693 	0.00966773460663913203 	-0.00702625656653354299 	0.00804041437309091674 	0.0091973716909279548 	0.00433207859487812468 	-0.00549671079834038612 	0.0100638932705507927 	0.00245268478060984901 	0.00792565278503957853 	8.21142182019163135e-05 	0.00506714656774250906 	0.00951648896823437118 	0.00377202674322583238 	0.00343926532684308249 	0.00859143848707118879 	-0.00143083087427590722 	0.00450945688123279183 	0.00250107776527749891 	0.000754472478534290491 	0.00982217356681956699 	-0.00666156656700028684 	-0.00667464465315429408 	0.000294507627075601302 	-0.0039631881986930545 	0.00812795147635048294 	0.00607255939126580789 	-0.00233121261021206321 	-0.00345640859402216501 	-0.00597310617065646178 	0.0105646380525400863 	-0.00550924909835233834 	0.000743181659231372709 	-0.0074342344703180914 	0.0023690461183857041 	0.00349668191190673303 	-0.00660353514075127761 	-0.000413742368054145467 	0.00750974509869004048 	0.00359064306012041789 	0.0112315221618441811 	0.00191514279203658074 	-0.00266908634654002041 	-0.000752204862829785074 	0.00522384984952284793 	0.00360425538155473507 	-0.00615876480420723092 	0.00296152177229528409 	0.00466300887242236325 	-0.004452949305855298 	0.00403813026723639362 	-0.00443644224566854158 	0.0026578631352313759 	0.00626920687621874539 	0.00861989030539164758 	0.0108246877329877689 	-0.00804917984137160786 	0.00969176548806604046 	0.0085143854767119314 	0.0103005394792546022 	0.00294127258703543674 	0.0067191538835347734 	0.00522731423676414068 	0.0102287747149861774 	0.00560620886959162148 	0.00125129794062288292 	0.00165939963870793614 	-0.00828607092868862208 	0.00174189046412734599 	0.00813909223674941923 	0.0111347269762160014 	0.0114204459533517721 	-0.00872668527598998399 	-0.00335734403632461254 	-0.00181801059335338347 	0.000599815417894182979 	0.000740816574758738585 	0.000972331592010053391 	-0.00111573694545227136 	-0.00730086795481763896 	-0.00175818408229077715 	0.00944226871049019811 	-0.00470023682608601296 	-0.00202050902250264274 	0.00943717337066829129 	0.00243318830031040434 	-0.0020230490115992106 	0.00884127313892139541 	-0.00416451049044531257 	0.00984195794749967087 	0.0009010739701096563 	0.00741039736017155316 	0.00626670424648849596 	-0.00683428938783131341 	0.0115880698121158966 	0.00717734592101487798 	-0.00309087678492820641 	
]
;
bias = 2 [ -0.0480886388473655974 0.0480886388473659929 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 1 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
