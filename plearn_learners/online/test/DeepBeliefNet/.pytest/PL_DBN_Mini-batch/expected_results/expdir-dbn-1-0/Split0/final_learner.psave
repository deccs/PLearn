*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.52000000000000024 0.450000000000000233 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -3.21580575368705368 -3.22364753521804737 0.0657827866426371755 0.0696030904799730815 0.0622029618057324957 0.0657378684765310972 0.0656101265818516688 0.0638544637987858155 0.0668341550566126791 0.0685139935739243339 0.0638885967214564421 0.0682193222523920229 0.0614189353126122703 0.0625664766511173087 0.0644591111231603425 0.0672080258882709475 0.068118922416383898 0.0620144498236062866 0.0658168511287076929 0.0614584698111661498 0.0685006396586318178 0.0670479847182284955 0.0641700406260315298 0.0661248069558832557 0.0671701269075536539 0.0619280966934446925 0.0631002357645635142 0.0616579996278061038 0.067283462359264759 0.0648275672466712555 0.0651764494044027171 0.0700494806732006176 0.0633482123265595443 0.0705131377405389115 0.0622909603789631242 0.062816786792906254 0.0663347352041287891 0.0649449035714201317 0.0699396681514389412 0.0655818667632351998 0.0685066157524031605 0.0638341419302660973 0.0675948606542311481 0.066125477314180614 0.0685631827581078962 0.0618955421308295742 0.0659183468910491538 0.0612163654801688092 0.0654024349135763905 0.0621983451516724475 0.0622920880548175557 0.0612458129415098251 0.0618062259590422894 0.0630664460752235617 0.0669921649854180873 0.0666066772938697094 0.0718850881647959405 0.0635225507551099022 0.0682316342600248621 0.0678732444344292418 0.066056804056856086 0.0640291125303126818 0.0636386992597940543 0.0679831833666539737 0.0699530259034038676 0.0660419388372846944 0.0688321552553833454 0.0649094861976334953 0.0658691841957568108 0.0614068151019241601 0.0690146718658728037 0.0673971388239837654 0.0672023840821927287 0.067165533087422416 0.0664861857760034314 0.0693207953501458057 0.0637773254435999026 0.0642392433002831748 0.0668207490601321202 0.0679989486904433588 0.0652705848529419319 0.0645560824978383824 0.0664835106333893228 0.0702736876926789017 0.0636389201503628765 0.0714316391373439191 0.0665688382090241643 0.0651440873146577892 0.0660134349623082289 0.0681014908729601215 0.066483264784777063 0.0662017489390426123 0.0627373532592977873 0.064759889243550986 0.0639710264357981478 0.0659921336077071846 0.0622046577630927452 0.0658226101336753244 0.0660693261083197814 0.068692607110742876 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-1.21415711267087589 	-1.29354388830904177 	
-1.24418997827235622 	-1.27717900530481865 	
0.0690673896090493872 	0.00106171994505329303 	
-0.0516350068945717194 	0.00282024601463587519 	
0.11576289542965755 	0.0779696628865055724 	
0.0937738356356867114 	-0.021341106697606714 	
0.0972995083962690244 	-0.0209936897396545835 	
0.125729266175554216 	0.0102265283424613773 	
0.0763061532337257764 	-0.0398982061240517327 	
-0.0404402347009997706 	0.0256125208841107149 	
0.0915328264772420214 	0.0429378683671718664 	
-0.0570336912737006985 	0.0526007297112317876 	
0.102969530366209081 	0.119573904600153644 	
0.0772888280315299631 	0.104255387702343244 	
0.116394649377435544 	-0.00151413154731653296 	
0.042691841196573814 	-0.0187388372631490177 	
0.00309655765104493563 	-0.00765739105447752182 	
0.122622375403801068 	0.0780030163934584547 	
0.0483846049070615694 	0.0210722938700518593 	
0.125103439244352993 	0.0962171519640014627 	
0.00709479590682871551 	-0.0237722892465301594 	
-0.0227695901334794421 	0.0543427620501140754 	
0.0687163096186778344 	0.0558421452465020021 	
0.0873560612567313155 	-0.0280358619475560913 	
-0.0464106966487873446 	0.0764830303301708148 	
0.104489235992809293 	0.100178142145328428 	
0.0776732347849002358 	0.0845290052909978551 	
0.103692129703154029 	0.111410227121787497 	
0.0430717292444947816 	-0.0217089627191627901 	
0.0813883488134935357 	0.0210933819137022749 	
0.129102379174570181 	-0.036355898240278843 	
-0.0286792898569442761 	-0.034418242614459485 	
0.0835488383450222333 	0.0702781455282296547 	
-0.0580004135006431942 	-0.01856040113472247 	
0.0855508878825002456 	0.106579346680886644 	
0.0488784468778965461 	0.125566752615730387 	
-0.023122679386145515 	0.0787930530316436201 	
0.114978759718911597 	-0.0154694984082932637 	
-0.0386528393637206938 	-0.0209924608991451864 	
0.0160783249246924942 	0.0627623210970354728 	
0.0331228024081457323 	-0.0498308212634323566 	
0.0582388085345984102 	0.0783366438529952969 	
0.0406519677826411435 	-0.0288869980516132489 	
-0.0597141338098050589 	0.126602072017401146 	
0.0220616100720658521 	-0.0404334267520467042 	
0.0907453618703058101 	0.115803257937635892 	
0.0150504297724695993 	0.0522433262471396417 	
0.113094839239612333 	0.117470889171381862 	
-0.00690135564924855734 	0.0928396049715910776 	
0.109649827478102729 	0.0849798591361091565 	
0.125891761693266213 	0.0650552724959696516 	
0.11704082920771855 	0.112558749468915059 	
0.127449941476074358 	0.0808065072573193877 	
0.0919423334473952608 	0.0707898574066043729 	
0.0858278120887288193 	-0.0534235543680405545 	
0.060280040625982266 	-0.0170601239435519865 	
-0.0538103520979965749 	-0.0635244256416778175 	
0.0499377763793946439 	0.0982902763280064928 	
0.00693050343376365452 	-0.015191684253758728 	
0.0331727775095305918 	-0.0296617801682230349 	
0.0083328011499871589 	0.0539681702117705206 	
0.0314617608986332009 	0.100064949873964096 	
0.0855326426254968963 	0.057315017051513345 	
0.023207493781608253 	-0.0233352076821683845 	
-0.0583191191212871773 	-0.000979764064585384288 	
-0.0479906282582027444 	0.116284453036889113 	
0.0210591810317722547 	-0.0477397138282999317 	
0.0434376062540039742 	0.0561817288505665896 	
0.0452950663181666685 	0.022414002260599572 	
0.125304222726260239 	0.0973538514926476223 	
0.0273905390733705199 	-0.0593483422458846235 	
-0.0482520815783283041 	0.0706049670949486785 	
-0.0230148144711252271 	0.0495507483466000181 	
0.0282514195131074383 	-0.00321472486741668142 	
0.058562138849964071 	-0.0111312665818238642 	
-0.00555360888280791425 	-0.0355896183418070028 	
0.0834121315444082828 	0.0554918556198370494 	
0.103621345570545739 	0.0187585478098261545 	
0.100422626762839626 	-0.0625169307095753274 	
-0.0307622944804058426 	0.0317687524264961274 	
0.0373219821352471226 	0.0511030992694271741 	
0.074764936607399371 	0.0365997076737267432 	
-0.0396251857033068436 	0.0922725594729125048 	
-0.0415625864709825432 	-0.0281025005267726037 	
0.0938474228099761276 	0.0492258097438833461 	
-0.0465543952870261582 	-0.0573943961338660089 	
0.0642999004945939145 	-0.0190406742732633638 	
0.0192566912094867988 	0.0737614039978816 	
0.0456318762720610838 	0.0172826898145707897 	
-0.0449514150475808227 	0.0440256246457320088 	
0.00338020415539046389 	0.0453054325727234586 	
0.0505121972965595842 	0.00636915220948123736 	
0.0637718544343126165 	0.112154363518923855 	
0.0496769642818689003 	0.0555319134645490819 	
0.0129640742770456147 	0.121565282319786111 	
0.0825645251590735457 	-0.0186625708087929665 	
0.0912876914719137483 	0.103302329171365018 	
-0.0207879822675519077 	0.0935891931065968435 	
0.0864228173229119323 	-0.0252615256322490621 	
0.0219937469394293449 	-0.0441223905892084711 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.056905686516290202 	0.0506708704397472037 	-0.00281005636301307664 	-0.00883585699550448571 	0.000968317251690557616 	-0.0093402359268631753 	-0.00511697102021179805 	0.00254076500836063982 	-0.00654591324086042751 	-0.00364155904253430198 	0.00817896291237939568 	-0.0107260314649677869 	-0.00859582448416375787 	-0.00872110586451123153 	-0.00976548188772113045 	-0.000336870451277782902 	-0.00688041685678251157 	-0.00350102615490139463 	0.00751567670499836502 	-0.00318769815895596524 	-0.00901948279713809913 	-0.00105238899124976762 	-0.0110583305687190266 	-0.00333929250749426037 	0.0060623229349569584 	-0.00317578753170242017 	-0.00827366343925372769 	0.00617556755864134051 	-0.00795541585758343002 	0.00698929690863082324 	0.00654178299480514744 	0.00169294246983757121 	-0.00144916085077765396 	-0.00849923651446167841 	0.00130887417565956178 	-0.00089281611779064025 	-0.00850108920620314297 	0.00801754174355075178 	-0.000575280972634687588 	0.000958759987538856137 	-0.00981588084176744473 	-0.00608657171273093572 	-0.00418528552938027959 	0.00562735261577514308 	-0.000518050642663960611 	0.00384599591075757358 	0.00226942270388939653 	0.00182406737587418894 	-0.00745302084548695766 	-0.00275203624784230985 	0.00289670326500193623 	0.00571329210131102903 	-0.0103166826500750639 	-0.0106067278271120887 	0.00349608088964599092 	-0.0103525295822042718 	-0.00969075522674989025 	-0.00199977291888563851 	-0.00244342369869020694 	0.00242178409774834041 	-0.00559882884989377876 	0.00311628278103911289 	0.000164874834633516076 	0.00718502450411627643 	-0.0068113234290610343 	0.000672392566058982845 	0.0063538034110592204 	-0.0105935035307277263 	-0.00137094737061349472 	-0.010079814546680034 	-0.0041041553287970798 	0.00529336414233272726 	0.00643952878798065547 	-0.00912602857564504683 	0.00860528804414868211 	0.00461363049429684268 	0.00539813907327492664 	-0.00692511721474696647 	-0.0107749454556943548 	-0.00112986939806045779 	0.00746157809029361716 	-0.00855606835453529696 	0.00444295613423474709 	-0.00436795887262757948 	0.00603238991047170842 	-0.0025171971459563942 	0.00758185921101216329 	0.000155711332240578772 	-0.000431246983178085804 	0.00890166994818770117 	0.00461909965740889532 	-0.00113556307955706365 	-0.000295616485385759048 	0.000702331257979741893 	-0.0109428013806251619 	0.00538394407367557247 	-0.00903117295401474444 	0.00450712775405929817 	-0.00359892962931220245 	0.00308890717513798105 	
-0.0557374783241876143 	-0.0420545575624722071 	0.00813500400145022833 	0.00229379993579923065 	0.00906162971906280222 	-0.00743593205632606721 	0.00762647643368444868 	0.00869621363055657695 	0.00397056380565017839 	-0.00579797794713223652 	0.00955106062258910364 	0.00215716664630538537 	0.00727422984820777236 	-0.000500762515461652936 	0.00459815118867967342 	0.00915734535344571443 	0.00344464560102859417 	0.00282240875012756531 	0.00817036200424728354 	-0.00208257539611419844 	0.00419592447125884897 	0.00214751070833023739 	0.000255317581120266405 	0.00943034204455690979 	-0.00699278020379851418 	-0.00729840657960003237 	-0.000260528849972028196 	-0.00460316891749462144 	0.00777252327054753483 	0.0056079871755551321 	-0.00274809084372059894 	-0.00372002594684294049 	-0.00651644438953754689 	0.0103209839040837165 	-0.00611001780234204234 	0.000184097771358787942 	-0.00780916915251383265 	0.00192688876696273451 	0.00323210381052388331 	-0.00702904698233882633 	-0.000720446543576197204 	0.00699558581945907473 	0.00324777016255779717 	0.0108918231660932469 	0.00160644625032169033 	-0.00329273878532777625 	-0.0011641046204615515 	0.00455768810001198118 	0.00318682572519702039 	-0.0067666981178593601 	0.00236205422100616838 	0.00399784141973917768 	-0.0050821403727673237 	0.00348082825425537461 	-0.00478393313130366128 	0.00227700635475103566 	0.00605499926312638454 	0.0080935200085025874 	0.01050136892500937 	-0.00838322001458193487 	0.00928850191789566682 	0.0080190087972090273 	0.00977389443603242022 	0.00260957077468325057 	0.00646325893474177654 	0.00487004162247831052 	0.00993040859333413004 	0.00514526110946576711 	0.000832536835531275934 	0.00100537648604621553 	-0.00857486094001503295 	0.0014183364908354893 	0.00779028400638433292 	0.0107715494732272214 	0.0110326988617241439 	-0.00901334626340149873 	-0.00387799214547862245 	-0.00230720040427873562 	0.000256380375565748214 	0.000419927959661204188 	0.000527364086741303703 	-0.00159524391287246608 	-0.0076566933826778278 	-0.00201338956872734688 	0.00891610717349773998 	-0.00492588019476571104 	-0.00240272388192210636 	0.00899383373568070354 	0.00202094779099536506 	-0.00233203482051662749 	0.00845518840813633092 	-0.00456789830484366499 	0.00927236344592883947 	0.000431382254701682337 	0.00692583736414298292 	0.00586433371064961143 	-0.00744023043615439552 	0.0111956952692525424 	0.00678182668483380286 	-0.00339477021191207651 	
]
;
bias = 2 [ -0.0323078363819910008 0.032307836381991098 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 1 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
