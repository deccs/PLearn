*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.52000000000000024 0.450000000000000233 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -3.21580575368705368 -3.22364753521804781 0.0657827866426371755 0.0696030904799730954 0.0622029618057324957 0.0657378684765310972 0.0656101265818516827 0.0638544637987858155 0.066834155056612693 0.06851399357392432 0.0638885967214564421 0.0682193222523920367 0.0614189353126122703 0.0625664766511173087 0.0644591111231603703 0.0672080258882709475 0.0681189224163839119 0.0620144498236062935 0.0658168511287077068 0.0614584698111661498 0.0685006396586318317 0.0670479847182284955 0.0641700406260315298 0.0661248069558832696 0.0671701269075536539 0.0619280966934446855 0.0631002357645635142 0.0616579996278061107 0.0672834623592647452 0.0648275672466712555 0.0651764494044027171 0.0700494806732006453 0.0633482123265595304 0.0705131377405389115 0.0622909603789631242 0.0628167867929062956 0.0663347352041287752 0.0649449035714201317 0.0699396681514389273 0.0655818667632351859 0.0685066157524031466 0.0638341419302661112 0.0675948606542311481 0.066125477314180614 0.0685631827581079101 0.0618955421308295811 0.0659183468910491677 0.0612163654801688162 0.0654024349135764044 0.0621983451516724406 0.0622920880548175557 0.061245812941509839 0.0618062259590423102 0.0630664460752235617 0.0669921649854180873 0.0666066772938697232 0.0718850881647959683 0.0635225507551099161 0.0682316342600248621 0.0678732444344292557 0.0660568040568560999 0.0640291125303126818 0.0636386992597940543 0.0679831833666539737 0.0699530259034038676 0.0660419388372846805 0.0688321552553833454 0.0649094861976335091 0.065869184195756797 0.0614068151019241601 0.0690146718658728037 0.0673971388239837654 0.0672023840821927426 0.0671655330874224299 0.0664861857760034314 0.0693207953501458057 0.0637773254435998888 0.0642392433002831748 0.0668207490601321341 0.0679989486904433588 0.0652705848529419042 0.0645560824978384101 0.0664835106333893366 0.0702736876926789017 0.0636389201503628904 0.0714316391373439191 0.0665688382090242059 0.0651440873146577892 0.0660134349623082289 0.0681014908729601215 0.0664832647847770769 0.0662017489390426123 0.0627373532592977873 0.064759889243550986 0.0639710264357981478 0.0659921336077071846 0.0622046577630927522 0.0658226101336753244 0.0660693261083197952 0.0686926071107428898 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-1.21415711267087545 	-1.29354388830904199 	
-1.24418997827235556 	-1.27717900530481843 	
0.0690673896090493733 	0.00106171994505328718 	
-0.0516350068945717125 	0.00282024601463587909 	
0.11576289542965755 	0.0779696628865056002 	
0.0937738356356867114 	-0.0213411066976067106 	
0.0972995083962690521 	-0.020993689739654587 	
0.125729266175554244 	0.0102265283424613773 	
0.0763061532337257903 	-0.0398982061240517327 	
-0.0404402347009997568 	0.0256125208841107184 	
0.0915328264772420214 	0.0429378683671718595 	
-0.0570336912737006846 	0.0526007297112317876 	
0.102969530366209094 	0.119573904600153644 	
0.0772888280315299769 	0.104255387702343258 	
0.116394649377435544 	-0.00151413154731652386 	
0.0426918411965738348 	-0.0187388372631490142 	
0.00309655765104493259 	-0.00765739105447751315 	
0.122622375403801082 	0.0780030163934584825 	
0.0483846049070615694 	0.0210722938700518524 	
0.125103439244352965 	0.0962171519640014489 	
0.00709479590682871725 	-0.0237722892465301559 	
-0.0227695901334794282 	0.0543427620501140685 	
0.0687163096186778483 	0.0558421452465020091 	
0.0873560612567313016 	-0.0280358619475561018 	
-0.0464106966487873446 	0.0764830303301708425 	
0.104489235992809307 	0.100178142145328428 	
0.0776732347849002358 	0.0845290052909978551 	
0.103692129703154029 	0.111410227121787497 	
0.0430717292444947747 	-0.0217089627191627867 	
0.0813883488134935357 	0.0210933819137022818 	
0.129102379174570153 	-0.036355898240278843 	
-0.0286792898569442622 	-0.034418242614459478 	
0.0835488383450222472 	0.0702781455282296547 	
-0.0580004135006431804 	-0.018560401134722463 	
0.0855508878825002456 	0.106579346680886644 	
0.0488784468778965461 	0.125566752615730415 	
-0.0231226793861455185 	0.0787930530316436339 	
0.114978759718911597 	-0.0154694984082932637 	
-0.0386528393637206868 	-0.0209924608991451864 	
0.0160783249246924942 	0.0627623210970354867 	
0.0331228024081457323 	-0.0498308212634323566 	
0.0582388085345983963 	0.0783366438529952969 	
0.0406519677826411505 	-0.0288869980516132593 	
-0.0597141338098050589 	0.126602072017401146 	
0.0220616100720658487 	-0.0404334267520467042 	
0.0907453618703057824 	0.115803257937635892 	
0.015050429772469601 	0.0522433262471396487 	
0.113094839239612374 	0.117470889171381862 	
-0.00690135564924855734 	0.0928396049715910776 	
0.109649827478102743 	0.0849798591361091427 	
0.125891761693266185 	0.0650552724959696654 	
0.117040829207718577 	0.112558749468915059 	
0.127449941476074358 	0.0808065072573193877 	
0.0919423334473952747 	0.0707898574066043729 	
0.0858278120887288193 	-0.0534235543680405545 	
0.0602800406259822799 	-0.0170601239435519865 	
-0.053810352097996561 	-0.0635244256416778175 	
0.0499377763793946508 	0.0982902763280064928 	
0.00693050343376365886 	-0.0151916842537587263 	
0.0331727775095305988 	-0.0296617801682230176 	
0.00833280114998716931 	0.0539681702117705275 	
0.031461760898633194 	0.100064949873964068 	
0.0855326426254968963 	0.0573150170515133658 	
0.0232074937816082634 	-0.0233352076821683845 	
-0.0583191191212871565 	-0.000979764064585391878 	
-0.0479906282582027513 	0.116284453036889127 	
0.0210591810317722582 	-0.0477397138282999595 	
0.0434376062540039742 	0.0561817288505665896 	
0.0452950663181666685 	0.0224140022605995755 	
0.125304222726260267 	0.0973538514926476223 	
0.0273905390733705234 	-0.0593483422458846235 	
-0.0482520815783283041 	0.0706049670949486785 	
-0.0230148144711252271 	0.0495507483466000181 	
0.0282514195131074453 	-0.00321472486741666928 	
0.058562138849964078 	-0.0111312665818238624 	
-0.00555360888280790905 	-0.0355896183418070028 	
0.0834121315444082828 	0.0554918556198370494 	
0.103621345570545725 	0.018758547809826151 	
0.10042262676283964 	-0.0625169307095753413 	
-0.0307622944804058357 	0.0317687524264961343 	
0.0373219821352471087 	0.051103099269427181 	
0.0747649366073993987 	0.0365997076737267432 	
-0.0396251857033068436 	0.0922725594729125048 	
-0.0415625864709825293 	-0.028102500526772628 	
0.0938474228099761137 	0.0492258097438833461 	
-0.0465543952870261582 	-0.0573943961338660089 	
0.0642999004945939284 	-0.0190406742732633638 	
0.0192566912094867988 	0.0737614039978816 	
0.0456318762720610976 	0.0172826898145707966 	
-0.0449514150475808227 	0.0440256246457320088 	
0.00338020415539047082 	0.0453054325727234586 	
0.0505121972965595842 	0.0063691522094812443 	
0.0637718544343126165 	0.112154363518923827 	
0.0496769642818689003 	0.0555319134645490958 	
0.0129640742770456077 	0.121565282319786139 	
0.0825645251590735596 	-0.018662570808792963 	
0.0912876914719137483 	0.10330232917136499 	
-0.0207879822675519077 	0.0935891931065968158 	
0.0864228173229119323 	-0.0252615256322490621 	
0.0219937469394293449 	-0.0441223905892084572 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0569056865162901743 	0.0506708704397472176 	-0.00281005636301307577 	-0.00883585699550448571 	0.000968317251690560001 	-0.00934023592686317183 	-0.00511697102021179719 	0.00254076500836063809 	-0.00654591324086042751 	-0.00364155904253430198 	0.00817896291237938874 	-0.0107260314649677869 	-0.00859582448416375787 	-0.00872110586451122979 	-0.00976548188772112871 	-0.00033687045127778274 	-0.00688041685678250983 	-0.00350102615490139246 	0.00751567670499836849 	-0.00318769815895596437 	-0.00901948279713810086 	-0.00105238899124976588 	-0.0110583305687190249 	-0.00333929250749425864 	0.00606232293495695927 	-0.00317578753170242103 	-0.00827366343925372769 	0.00617556755864134225 	-0.00795541585758342655 	0.00698929690863082757 	0.0065417829948051457 	0.00169294246983757034 	-0.00144916085077765526 	-0.00849923651446167841 	0.00130887417565956113 	-0.000892816117790639924 	-0.00850108920620314644 	0.00801754174355075351 	-0.000575280972634687263 	0.000958759987538854185 	-0.00981588084176744299 	-0.00608657171273093746 	-0.00418528552938027872 	0.00562735261577514568 	-0.000518050642663959635 	0.00384599591075757401 	0.00226942270388939913 	0.00182406737587419068 	-0.00745302084548695939 	-0.00275203624784231202 	0.0028967032650019371 	0.00571329210131102903 	-0.0103166826500750639 	-0.0106067278271120852 	0.0034960808896459957 	-0.0103525295822042684 	-0.00969075522674989545 	-0.00199977291888563807 	-0.00244342369869020607 	0.00242178409774834215 	-0.00559882884989377615 	0.00311628278103911376 	0.000164874834633516618 	0.00718502450411628076 	-0.00681132342906103257 	0.000672392566058983279 	0.006353803411059223 	-0.0105935035307277298 	-0.00137094737061349494 	-0.0100798145466800323 	-0.00410415532879708153 	0.00529336414233273073 	0.00643952878798065634 	-0.00912602857564504336 	0.00860528804414868211 	0.00461363049429684442 	0.00539813907327492751 	-0.00692511721474696734 	-0.0107749454556943496 	-0.0011298693980604567 	0.0074615780902936189 	-0.00855606835453529349 	0.00444295613423474883 	-0.00436795887262757861 	0.00603238991047171016 	-0.00251719714595639247 	0.00758185921101216503 	0.000155711332240578094 	-0.000431246983178083744 	0.00890166994818770464 	0.00461909965740889619 	-0.00113556307955706127 	-0.000295616485385759753 	0.00070233125797974276 	-0.0109428013806251619 	0.0053839440736755716 	-0.00903117295401473924 	0.00450712775405930251 	-0.00359892962931220289 	0.00308890717513798062 	
-0.0557374783241875241 	-0.0420545575624722279 	0.00813500400145023526 	0.00229379993579922892 	0.00906162971906279702 	-0.00743593205632607068 	0.00762647643368445302 	0.00869621363055657348 	0.00397056380565017752 	-0.00579797794713223392 	0.00955106062258910884 	0.00215716664630538277 	0.00727422984820777323 	-0.000500762515461652285 	0.00459815118867967255 	0.00915734535344571443 	0.00344464560102859026 	0.00282240875012756401 	0.00817036200424728007 	-0.00208257539611419887 	0.00419592447125884897 	0.00214751070833023739 	0.00025531758112026467 	0.00943034204455691152 	-0.00699278020379851591 	-0.00729840657960003063 	-0.00026052884997202928 	-0.00460316891749462404 	0.00777252327054752876 	0.00560798717555513124 	-0.00274809084372059807 	-0.00372002594684294266 	-0.00651644438953755296 	0.0103209839040837199 	-0.00611001780234204147 	0.000184097771358786262 	-0.00780916915251383091 	0.00192688876696273255 	0.00323210381052388245 	-0.0070290469823388246 	-0.000720446543576197204 	0.00699558581945906952 	0.0032477701625577963 	0.01089182316609324 	0.0016064462503216899 	-0.00329273878532777712 	-0.00116410462046155259 	0.00455768810001197944 	0.00318682572519701952 	-0.00676669811785936097 	0.00236205422100616881 	0.00399784141973917508 	-0.00508214037276732457 	0.00348082825425537245 	-0.00478393313130366302 	0.00227700635475103479 	0.00605499926312637934 	0.00809352000850258567 	0.01050136892500937 	-0.00838322001458193834 	0.00928850191789566508 	0.00801900879720902557 	0.00977389443603241675 	0.0026095707746832497 	0.00646325893474177394 	0.00487004162247831052 	0.0099304085933341283 	0.00514526110946576277 	0.000832536835531273549 	0.00100537648604621423 	-0.00857486094001503295 	0.001418336490835488 	0.00779028400638433465 	0.0107715494732272214 	0.0110326988617241387 	-0.00901334626340150047 	-0.00387799214547862332 	-0.00230720040427873432 	0.000256380375565747564 	0.000419927959661202995 	0.000527364086741302185 	-0.0015952439128724663 	-0.0076566933826778304 	-0.00201338956872734514 	0.00891610717349773998 	-0.00492588019476571277 	-0.00240272388192210766 	0.00899383373568070354 	0.0020209477909953655 	-0.00233203482051662705 	0.00845518840813633266 	-0.00456789830484366326 	0.00927236344592883947 	0.000431382254701681849 	0.00692583736414298379 	0.00586433371064961143 	-0.00744023043615439812 	0.0111956952692525424 	0.00678182668483380286 	-0.00339477021191207391 	
]
;
bias = 2 [ -0.0323078363819910008 0.032307836381991098 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 1 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
