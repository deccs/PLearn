*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 1 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ -0.550000000000000266 -0.440000000000000224 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ 3.22297502090243659 3.22850343798757411 -0.0655674198722276252 -0.062053150214301786 -0.0694639415907335606 -0.0656967869581215752 -0.065802796160687807 -0.0676665281073794145 -0.0646008478691122157 -0.0630437566075335576 -0.0675636254713856965 -0.0633361959019119736 -0.07039456083162067 -0.0690432124347641341 -0.0669936710720746148 -0.0641822519514770734 -0.0633215475695771551 -0.0696978904345579992 -0.0655365737634271694 -0.0703843254243849137 -0.0629756492516730521 -0.0643907155410799181 -0.0672190493187708321 -0.0652833514948132215 -0.0643953690592243555 -0.0698244386567378611 -0.0684178046176994181 -0.070175871658150521 -0.0640983927904116846 -0.0665726831989223305 -0.0664040143492933971 -0.0616877132603564568 -0.0681706276454905474 -0.0612647343384444543 -0.0694090319721886173 -0.0688279871752820044 -0.065124427046754807 -0.0665585108343436371 -0.06176234586166722 -0.0658212640585509184 -0.0630170514137075588 -0.0675889446130172045 -0.0638338044249902314 -0.0655297688361054925 -0.0629649661551778539 -0.0698847192903202657 -0.0654629364108216816 -0.0706810954132212621 -0.0660285024336473153 -0.0695005153829066358 -0.0693978927744081375 -0.0706556651377230061 -0.0699537487859004659 -0.0684365451391091284 -0.0645398814851921021 -0.0647616493444653218 -0.0601662010225776089 -0.0679644403313142687 -0.0632144607207602016 -0.0636181859919971865 -0.0652850922111074677 -0.0674441928560244042 -0.0678073923733376188 -0.0634914797452603014 -0.0617561876343264912 -0.0655494061977655029 -0.0627296640677947603 -0.0664271156689422437 -0.065479249890638011 -0.0704179681617658759 -0.0626083718349836893 -0.064150644361228526 -0.0642433194221907755 -0.0641793160292923603 -0.0648969996254884218 -0.0623260735216023057 -0.0677062572193665863 -0.0672066873746975657 -0.0647069715718852079 -0.0634935571762970802 -0.0661137956042305575 -0.0668230777159821848 -0.065072373398281716 -0.0614871327505506909 -0.0678324572139960141 -0.060563054793671571 -0.0648627663702872337 -0.0662330568700429945 -0.0653362603423534583 -0.0634672818945638401 -0.0648919074644516009 -0.0651717128396615553 -0.0688591344930329918 -0.0666241742120582819 -0.0675404276392551489 -0.0654246462891826669 -0.0694808269603974654 -0.0656411525931498013 -0.0653383347553044974 -0.0628748982730635009 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
1.29220320314167791 	1.23360776084591173 	
1.27872961480206149 	1.26508818796771783 	
0.0069235175860513018 	-0.0596493482467894826 	
-0.114101462969043332 	-0.0580988569046345868 	
0.0533565400353935848 	0.0170491494543559517 	
0.0316429427052850737 	-0.0820287849666461455 	
0.0351032969514864235 	-0.0817381734261192205 	
0.0634469142848316375 	-0.0505021675106046772 	
0.014137289366929498 	-0.100685202722473471 	
-0.102704511553851074 	-0.0351291077576920061 	
0.0293595458726126149 	-0.0177656145449792656 	
-0.119403330826722831 	-0.00820792272976666147 	
0.0404489624105316137 	0.0584112377699046725 	
0.0149953341430634594 	0.0433154538714251372 	
0.0541231875169777901 	-0.0622654971409482144 	
-0.0194619452202611093 	-0.0794991574421131941 	
-0.0591309423094542805 	-0.0684592801496005793 	
0.0601840005623679453 	0.0170691892439329349 	
-0.0136891222072263608 	-0.039575609358793222 	
0.0626097695542838922 	0.0351989189500988772 	
-0.0551720135255094613 	-0.0846389760005528818 	
-0.0849388090255431411 	-0.00635662292228355869 	
0.00653694458356685482 	-0.00490949374195461755 	
0.025174974506576929 	-0.0887952349207536823 	
-0.108549115284084272 	0.0158403099288679516 	
0.0421390225675163585 	0.0392398494581973761 	
0.0154309454120496441 	0.0236842030028510397 	
0.0413412467827884642 	0.0504401859701714833 	
-0.0191193899502736138 	-0.08251035941577535 	
0.0192847607045263832 	-0.0395532286748599901 	
0.0669408894051742587 	-0.0970130995022018688 	
-0.0910475086595164268 	-0.0953504375875404153 	
0.0213870941412512595 	0.00954489994435697882 	
-0.120632544614303922 	-0.0796475324973987819 	
0.0232968722877611584 	0.0456841016756074983 	
-0.0133317017153690605 	0.0646234660009369355 	
-0.0852584387614009065 	0.0180954559630503165 	
0.0528352112592731377 	-0.0761141873516854583 	
-0.101081872518667654 	-0.0819376680973578908 	
-0.0459535875418153952 	0.00213824328063651464 	
-0.0291065541060039762 	-0.110727468696116979 	
-0.00395890797306439925 	0.0175274950300004298 	
-0.0215090092317983955 	-0.0896712774928562911 	
-0.121964926858960723 	0.0657677050018809078 	
-0.0401380015563763196 	-0.101276123247230621 	
0.0284324854550349684 	0.0548329660062637989 	
-0.0470073236675853032 	-0.00839467261894551002 	
0.050587620206005407 	0.0563509932653329312 	
-0.0690597481883651748 	0.0320654114562946221 	
0.0473208662992663717 	0.0241074559380521324 	
0.0635123940506462092 	0.00420828933025829861 	
0.0545511436002203212 	0.0514803846774994078 	
0.0649765752170751026 	0.0198470196543507962 	
0.0296433978562453126 	0.00993493870292423004 	
0.0237424984143941274 	-0.114145802727042472 	
-0.00187765399950315642 	-0.0778128677930624846 	
-0.11660429249840995 	-0.124884172554877521 	
-0.0122602490947308022 	0.0374355868395197869 	
-0.0553151493711838416 	-0.0760245423841495044 	
-0.0289047938738029066 	-0.0903658074172669634 	
-0.0538309537866579202 	-0.00676968804299702548 	
-0.0306764133596947423 	0.0392628660717239467 	
0.0233107731838695861 	-0.00345790159285788712 	
-0.038913966807943845 	-0.0840691835333684523 	
-0.1208547591377305 	-0.0619500968665968668 	
-0.110200228557434984 	0.055487230833530736 	
-0.0411706677281680478 	-0.108628478414043314 	
-0.0187242146065062405 	-0.00456879672499675878 	
-0.0167862916672534696 	-0.0382422711585357969 	
0.0627512565214791151 	0.0362753147015339727 	
-0.0348078718895850139 	-0.120238587017427401 	
-0.110455941578583558 	0.00991234463564251607 	
-0.0851807528351593429 	-0.0111410784080641697 	
-0.0339580751298678082 	-0.064010781625045407 	
-0.00353598286695875046 	-0.0718191036224426066 	
-0.0677595142334457279 	-0.0964041755975349052 	
0.0213022386562033324 	-0.00517260018543138581 	
0.0414241226751148814 	-0.0419398819675565818 	
0.0382120973673575268 	-0.123359848456372476 	
-0.0929881295964480187 	-0.028957920723804504 	
-0.0247109665646048741 	-0.0095171443374491814 	
0.0126175422127598955 	-0.0241006135509846675 	
-0.101730186036494905 	0.0316157246083580354 	
-0.104029401939315813 	-0.0890897101669621966 	
0.0316467628517260943 	-0.0115046536306472307 	
-0.109160552150135121 	-0.118572727552158932 	
0.0022625759233003695 	-0.0796744517052890427 	
-0.0428683774538702808 	0.0130289732273120729 	
-0.0164520832841672862 	-0.0433770308053599285 	
-0.107146840803663976 	-0.0166419341475811042 	
-0.0587359674711478499 	-0.0153743704526102878 	
-0.0115441064666440916 	-0.0542664942214843918 	
0.00150219021435402328 	0.0512020860335166139 	
-0.0124047942645855256 	-0.00513744872628248746 	
-0.0492572403497689437 	0.0606313130687570201 	
0.0204587837638680707 	-0.0793406716447456889 	
0.0289676756495262401 	0.0423600752752206211 	
-0.0829466709775956157 	0.0328361137204496514 	
0.0242568225615223537 	-0.0860029078247910583 	
-0.0401690630785093983 	-0.104937097054671441 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0571179363884330715 	0.0501099146229689527 	-0.00283641365247566234 	-0.00951556532440867887 	0.00160876019819252369 	-0.00935152806483453836 	-0.00510740503617761622 	0.00287368433171549366 	-0.00675304534641368946 	-0.00413678788857376519 	0.00850030537003727132 	-0.0111684868748137111 	-0.00780306127119202719 	-0.00814942063470409928 	-0.00954679294574280884 	-0.000614088438469789061 	-0.00731516352452465501 	-0.0028230486503627826 	0.00748388346081026168 	-0.00239904703937962724 	-0.00951902894901785444 	-0.00129605959454318293 	-0.0107927282259586959 	-0.00342207145289506265 	0.00580774854206700473 	-0.0024777638275730496 	-0.00780547079113386166 	0.0069294054970583099 	-0.00824672112506308688 	0.00713823191991569926 	0.00664356302299650738 	0.000940279142242216406 	-0.0010248551437070741 	-0.00932895795875588948 	0.0019383382713005692 	-0.000361220844477940796 	-0.00861518843955717123 	0.00815415350633160937 	-0.00131097896514859947 	0.000974099005917070733 	-0.0103129990867254599 	-0.00575765436393235394 	-0.00452824694320300147 	0.00556878198151231681 	-0.0010249005712966218 	0.004552974919782014 	0.00222249556539440762 	0.00266082274728519832 	-0.00740263579388739362 	-0.00210709456730666638 	0.00352362954929475369 	0.00654536123261181737 	-0.0095974870123731338 	-0.0101344825179493607 	0.00326867246220256596 	-0.0105244789083738383 	-0.0107385022345107915 	-0.00160905283676741439 	-0.00289771267188897131 	0.00203421491244993972 	-0.00567387788282249471 	0.00341582289983727132 	0.000530202561715857222 	0.00677671540668820307 	-0.00754837941802427234 	0.000622980909090498601 	0.00580204713289287147 	-0.010464364672504254 	-0.00141249642388021853 	-0.00928429527767735997 	-0.00468360331918606185 	0.00499672932982297285 	0.00616881440923875996 	-0.00939918330075985124 	0.00845612416447832915 	0.00398191050011536835 	0.00574267253302497213 	-0.0066673288401297515 	-0.0109720985382393086 	-0.00153878814978031697 	0.00753065086080979308 	-0.00836043286960834464 	0.00431079972904480253 	-0.00515779667115612295 	0.00639998094998550388 	-0.00349161079685592372 	0.00742192480911468139 	0.000247062267102250406 	-0.00049851531787022845 	0.00848067040967163607 	0.00447065128420599551 	-0.00123456184000690075 	0.000244823631494027938 	0.000862566839725850102 	-0.0106291315660229611 	0.00532573396950207847 	-0.00838831631330394685 	0.0044853194341249198 	-0.00367181364364815377 	0.00256206525739502682 	
-0.0559497281963304352 	-0.0414936017456938935 	0.00816136129091281359 	0.00297350826470341861 	0.00842118677256085274 	-0.00742463991835468594 	0.00761691044965026598 	0.008363294307201714 	0.00417769591120347328 	-0.00530274910109274251 	0.00922971816493122627 	0.00259962205615130865 	0.00648146663523603908 	-0.00107244774526877771 	0.00437946224670130238 	0.00943456334063768817 	0.00387939226877071506 	0.00214443124558895588 	0.00820215524843536173 	-0.00287122651569053644 	0.00469547062313856872 	0.00239118131162365357 	-1.02847616400707399e-05 	0.00951312098995769732 	-0.0067382058109085579 	-0.00799643028372943286 	-0.000728721498091911349 	-0.0053570068559115969 	0.00806382853802718735 	0.00545905216427026996 	-0.00284987087191196581 	-0.00296736261924756715 	-0.00694075009660812675 	0.0111507053483779327 	-0.00673948189798301463 	-0.000347497501953908123 	-0.00769506991915977923 	0.00179027700418187365 	0.00396780180303779595 	-0.00704438600071702684 	-0.000223328298618172413 	0.00666666847066049294 	0.0035907315763805325 	0.0109503938003560793 	0.00211329617895435196 	-0.00399971779435220366 	-0.00111717748196656238 	0.0037209327286009679 	0.00313644067359748323 	-0.00741163979839501007 	0.00173512793671334853 	0.00316577228843840713 	-0.00580133601046927804 	0.00300858294509262448 	-0.00455652470386023242 	0.0024489556809206268 	0.00710274627088726841 	0.00770279992638437608 	0.0109556578982081369 	-0.00799565082928353418 	0.0093635509508243446 	0.00771946867841088492 	0.00940856670895008629 	0.00301787987211131481 	0.00720031492370501285 	0.00491945327944680409 	0.0104821648715004538 	0.00501612225124228959 	0.000874085888797998122 	0.000209857217043509555 	-0.00799541294962607604 	0.00171497130334524977 	0.0080609983851262397 	0.0110447041983420223 	0.0111818627413944934 	-0.00838162626922003308 	-0.00422252560522866794 	-0.0025649887788959558 	0.000453533458110704857 	0.000828846711381064243 	0.000458291316225099702 	-0.00179087939779941905 	-0.00752453697748784421 	-0.0012235517701988136 	0.00854851613398391157 	-0.00395146654386617675 	-0.0022427894800246418 	0.00890248280081903758 	0.00208821612568750635 	-0.00191103528200058472 	0.00860363678133929839 	-0.00446889954439381835 	0.00873192332904906658 	0.000271146672955575483 	0.00661216754954073189 	0.00592254381482310889 	-0.00808308707686518184 	0.0112175035891868679 	0.00685471069916975765 	-0.00286792829416912835 	
]
;
bias = 2 [ -0.0322402029767411766 0.0322402029767412668 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 0 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 1 ;
n_layers = 2 ;
minibatch_size = 1 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
random_gen = *3  ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
