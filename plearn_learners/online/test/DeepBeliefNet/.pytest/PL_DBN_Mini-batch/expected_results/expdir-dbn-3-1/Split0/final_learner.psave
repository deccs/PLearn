*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.259999999999999731 0.320000000000000118 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -4.88348781864529524 -4.8837790966619945 0.0998136183975280172 0.105471817501073567 0.0944416603126441573 0.0997535283630023167 0.0995807079469193807 0.0969420280226542391 0.101407798986863112 0.103819719061399696 0.0969561262386221118 0.103379686484071684 0.0932604806258945512 0.0949581076326168755 0.0978612202826870392 0.101940630727569342 0.103281189924958716 0.0941595431112412506 0.0998305935628365643 0.0933123105594513141 0.103865433445130023 0.101629187737637239 0.0973778633969569346 0.100349460306733224 0.101767253426589127 0.0939952628691959613 0.0957642872874144846 0.0935745523905245069 0.102064003256194066 0.098361691863909001 0.0989175053269632093 0.10614746415871347 0.0961217644556267709 0.106849253706285993 0.0945216452223907322 0.0952991047808851438 0.100547639463152719 0.0985605833598848236 0.105983428725311621 0.0994327692125842322 0.103893097444509405 0.0968643024791368545 0.102520198423240241 0.100204431378448769 0.103958775859172015 0.0939290211077105641 0.099947437518405513 0.0929393923414386647 0.0991701323486275238 0.094408220117351227 0.0945697106806672877 0.0929791640592441959 0.0938470820938613198 0.0957359700320323803 0.101626912170330416 0.101052854003951254 0.108921157875693661 0.0963814492151018887 0.103458632943262935 0.10290812806515362 0.100178659212683582 0.0971214500704266626 0.0965871618141980054 0.103073960705580392 0.105996494971855509 0.100087602274505402 0.104366272501995289 0.0984793481047083058 0.0999092875429416077 0.0932523589552438636 0.104637234166777962 0.10212217225891014 0.10185947931508095 0.101878379680090239 0.100853886423779154 0.105057249424197946 0.0967631186351052691 0.0975018372905746139 0.101409956557437189 0.103055880161497679 0.0989832218691384519 0.0979591861849546941 0.100737252815511033 0.106483496226710855 0.096583400725600066 0.108223002610933108 0.100965208043670873 0.0988008819013017348 0.100127932147128867 0.103179296286824845 0.100801354336986573 0.100407892578924282 0.0952068316396505326 0.0982331855345689731 0.0970389632595778512 0.10012569038037146 0.0944119786063295219 0.0997856098841084088 0.100261110879061879 0.104142637036895788 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-0.595479171538772389 	-0.647843265634009846 	
-0.615238337477441055 	-0.626646056674283858 	
0.0538900294397439625 	-0.0137742833948165666 	
-0.06875053142052448 	-0.0128356405145059228 	
0.101750482831042349 	0.0645179709928756923 	
0.0788404196343822639 	-0.0363313352895024075 	
0.0823984677889268713 	-0.0359772385695514493 	
0.111455643794722045 	-0.00410482619395231754 	
0.0609652140478198074 	-0.0553056639846301532 	
-0.0571686153486568316 	0.0104202988290012649 	
0.0769767542086591816 	0.0288702909576745818 	
-0.0738826113496724585 	0.0376651648655449978 	
0.0890025291790311757 	0.10658630388745495 	
0.0628827179229135558 	0.0909309318538381178 	
0.10189692292911387 	-0.0160894138207842638 	
0.0269756763337721528 	-0.0340491698234521578 	
-0.0131781351491743713 	-0.0230764112596843068 	
0.108709363233458603 	0.064594665896358705 	
0.0330446970922479294 	0.00641644683858688929 	
0.111338474011847738 	0.0830744128480884469 	
-0.00923663549878875507 	-0.039419952693748761 	
-0.0390168467135288966 	0.039692762930110273 	
0.053884855284114512 	0.0417960182001957531 	
0.0722589195882538671 	-0.0431916351119050954 	
-0.0628580553109818196 	0.0620282656863879525 	
0.0904696456760091527 	0.0869795013810659712 	
0.063155692471325367 	0.070941165193654579 	
0.089737672806708732 	0.0983663784623535487 	
0.0273272832467084739 	-0.0370754352212263952 	
0.0665515477695941687 	0.00665545528587137454 	
0.114615148493610861 	-0.0513201825260646144 	
-0.0456422913795766633 	-0.0504568195824679072 	
0.0690561056867186052 	0.0565546631705502387 	
-0.0754060455133409996 	-0.0346219815131878009 	
0.0713063685070573078 	0.0933620354169992783 	
0.0341980957421883225 	0.112370604562321508 	
-0.0392048865688329473 	0.0645005741897170803 	
0.100413128501990329 	-0.030219248975625241 	
-0.0557068816320919549 	-0.0369117849033234746 	
0.000529733929197459758 	0.0485162644411036431 	
0.0170355689113608801 	-0.0656936836103067801 	
0.0433878525009998087 	0.0645360645558576418 	
0.0248375275797735953 	-0.0443637944730375169 	
-0.0760831140867710004 	0.112732191490474185 	
0.00587915934077326736 	-0.0562115972021530394 	
0.0766272396820571744 	0.102736863234715037 	
-0.000592684940426658319 	0.0378303322767531494 	
0.0992806567766492953 	0.104535562881183194 	
-0.0226534723321051186 	0.0788333372758215217 	
0.0956148861294622843 	0.071608409395350639 	
0.111961983119019282 	0.051503114001920508 	
0.103261697334856045 	0.0995893663062659279 	
0.113622132076437066 	0.0674654151128029206 	
0.0775371261339915241 	0.0570887588626447992 	
0.0705810984356155524 	-0.0689366435996839055 	
0.044843023134881671 	-0.0322309100088603862 	
-0.0714869712521966627 	-0.0802860339949844071 	
0.0350917134068162787 	0.0847180859020596616 	
-0.00934136513864572762 	-0.0307058733146445759 	
0.017274684402242526 	-0.0451641166704254277 	
-0.00744338758825805347 	0.0394987995010958187 	
0.01635978807368689 	0.0864131668208693443 	
0.0709612773109407208 	0.0433967733386337942 	
0.00718060967436377762 	-0.0388226740324390668 	
-0.0755833033596572668 	-0.0167504198245917793 	
-0.0642340161003093352 	0.102350333481158032 	
0.0048042487224343542 	-0.0636443844298318767 	
0.0282189683208145595 	0.0419719166047329909 	
0.0299132095892969373 	0.00775440451798690283 	
0.111530306999090348 	0.0842099709862055845 	
0.0111726585535115806 	-0.0753750532311086435 	
-0.0647904300854395682 	0.0560328728134857693 	
-0.0392948976134838007 	0.0348323569795132501 	
0.0123915169443690812 	-0.0184093328026520113 	
0.0431605911084246008 	-0.0262028154072604068 	
-0.022117499304064675 	-0.0514567367068857959 	
0.068835727405720748 	0.0415705062017272323 	
0.0890847854970412689 	0.00441555037709988676 	
0.0852942013840160274 	-0.0781125130895272829 	
-0.0472940655022145579 	0.0167306727323274472 	
0.0220238553939347895 	0.0368257958383149606 	
0.0599111578444758569 	0.0223267883631605608 	
-0.055857013383988692 	0.0780883336256121829 	
-0.058716698004954021 	-0.0441544608089798271 	
0.0793606765007453946 	0.0352579600100396198 	
-0.0640094082428914191 	-0.0739527557808974806 	
0.0489600429692438541 	-0.0341678748008232419 	
0.00379375700322669976 	0.0596590822724617845 	
0.0302207297680062124 	0.00254921219936410327 	
-0.0616037449568939341 	0.0290990160924210796 	
-0.0125089212557680778 	0.0306990708174415226 	
0.0351162640727813793 	-0.00848184184674327657 	
0.049213844559273745 	0.0988530120564841547 	
0.0345815650076597564 	0.0413837339984958544 	
-0.00231189629031251787 	0.1080671288555725 	
0.0674832518044770763 	-0.0336835252022576748 	
0.0770889815106832049 	0.0900588562201595916 	
-0.0367474445651055082 	0.0795105696210817031 	
0.0713351233590624745 	-0.0403765780191503165 	
0.00580328195072376662 	-0.0599406438638086306 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0123420928014191765 	0.00916499543260136662 	-0.00164506058869937728 	-0.0079295871380481147 	0.00236549116291899161 	-0.00816839208649198199 	-0.00393729201208150269 	0.00383571983020708452 	-0.00544728800267464067 	-0.00266053897009083237 	0.00946810364372980412 	-0.00972470140984709602 	-0.00715049251794375867 	-0.00734869875953184874 	-0.00851045478860876746 	0.000733198497111746091 	-0.00587341695528064475 	-0.00209131432022617667 	0.00867743624742248892 	-0.00174242905445374857 	-0.00803777150919455716 	2.68947234888729918e-05 	-0.00978963001083593166 	-0.00219383685419234295 	0.00713629807466046717 	-0.0017607190700940085 	-0.00693551341442329074 	0.00760840838401072306 	-0.00689064362225262714 	0.00821779551345409691 	0.00775615975335418317 	0.00256994077777214936 	-0.000125487652430557821 	-0.00765557075172304622 	0.00270057028444748229 	0.00046445864750938921 	-0.00737340071900495931 	0.00924350722960627473 	0.000308359129016673504 	0.00213576384551587232 	-0.0088316481921647573 	-0.00479667378996826745 	-0.00314050304959243194 	0.00677359813450965909 	0.000461574357387472883 	0.0052630551506867209 	0.00342377191963190138 	0.00328382212079000434 	-0.00626455935271804255 	-0.00135382711424076175 	0.00428995531271315379 	0.00717178746011403606 	-0.00889343281654111917 	-0.00926633853826809052 	0.00458758045120281812 	-0.00924171707330578504 	-0.0089407727361354699 	-0.000689382609061561812 	-0.00144386531203365706 	0.00344874682264902609 	-0.00445501595657440443 	0.00439439909658437614 	0.00146877925949968099 	0.00820337445445518988 	-0.00592893418508044692 	0.00182255472740502824 	0.00731552216505707356 	-0.0093740454197580262 	-0.000212912355459383902 	-0.00863228712512624334 	-0.00315315105065477668 	0.00635133933025240193 	0.00750852663533482702 	-0.00805517934762344477 	0.00972441442848316628 	0.00554144065331621267 	0.00669469475106060277 	-0.00565723229911999689 	-0.00967100372334113445 	-0.000114466692242828325 	0.00865912090766649163 	-0.00731143980482081273 	0.00556306573368089453 	-0.00350700272215526306 	0.00733748393075391286 	-0.00173505410219775328 	0.0086972297748011216 	0.00136029609347290475 	0.00071739170531200905 	0.00991167438484492555 	0.00573543123204991317 	1.63578136879163428e-06 	0.00106564480483038434 	0.00193302874506671757 	-0.00966095349810980504 	0.00653802734483209004 	-0.00763470234441813479 	0.00566876259818077134 	-0.0024499179463127619 	0.00406053318954284741 	
-0.0111738846093165402 	-0.000548682555326289933 	0.00697000822713652029 	0.00138753007834285184 	0.00766445580783438156 	-0.00860777589669724057 	0.00644679742555415332 	0.00740125880871012574 	0.00287193856746441843 	-0.00677899801957570006 	0.00826191989123869694 	0.00115583659118469336 	0.00582889788198777056 	-0.00187316962044102651 	0.00334312408956729005 	0.0080872764050561631 	0.00243764569952672171 	0.0014126969154523441 	0.00700860246182310413 	-0.00352784450061643332 	0.00321421318331525842 	0.00106822699359159965 	-0.00101338297676285176 	0.00828488639125498846 	-0.00806675534350202901 	-0.00871347504120848285 	-0.00159867887480246102 	-0.00603600974286399878 	0.00670775103521673542 	0.00437948857073182894 	-0.00396246760226966893 	-0.00459702425477752537 	-0.00784011758788464089 	0.00947731814134509208 	-0.00750171391112994246 	-0.00117317699394124133 	-0.00893685763971203626 	0.000700923280907214804 	0.00234846370887252 	-0.00820605084031584935 	-0.00170467919317889645 	0.00570568789669640558 	0.00220298768276994995 	0.00974557764735873785 	0.000626821250270257813 	-0.00470979802525691143 	-0.00231845383620405462 	0.00309793335509616187 	0.00199836423242812523 	-0.00816490725146091882 	0.000968802173294960032 	0.0025393460609361854 	-0.00650539020630128747 	0.00214043896541134824 	-0.00587543269286049108 	0.00116619384585259374 	0.0053050167725119373 	0.00678312969867851494 	0.00950181053835282008 	-0.00941018273948261708 	0.00814468902457629769 	0.00674089248166376623 	0.00846999001116628507 	0.00159122082434438785 	0.00558086969076118829 	0.00371987946113228485 	0.00896868983933631937 	0.00392580299849605227 	-0.000325498179622835126 	-0.000442150935507603228 	-0.00952586521815736165 	0.000360361302915812836 	0.0067212861590301631 	0.00970070024520561756 	0.00991357247738965976 	-0.0099411564224208826 	-0.00517454782326429424 	-0.00357508531990571995 	-0.00084756135678746181 	-0.000595474746156425842 	-0.000670178730631579441 	-0.00283987246258698067 	-0.00877680298212392754 	-0.00287434571919966764 	0.00761101315321550259 	-0.00570802323852433267 	-0.00351809444571104472 	0.00778924897444837998 	0.000872309102505270263 	-0.00334203925717386661 	0.00733885683349534863 	-0.00570509716576950762 	0.00791110215571273062 	-0.000799315232385290142 	0.00564398948162753589 	0.00471025043949309472 	-0.00883670104575096267 	0.0100340604251309938 	0.00563281500183433759 	-0.00436639622631694244 	
]
;
bias = 2 [ -0.00391578848611695736 0.00391578848611706665 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 1 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
