*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ -0.196666666666666434 -0.199999999999999761 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ 2.58927831149933851 2.5864667316340344 -0.0525863262800879971 -0.049701151626684828 -0.0558370842730609995 -0.0526670928117814255 -0.0527692186319411172 -0.0543118730603495137 -0.051768235510647978 -0.0505061149237686635 -0.0542405712863612624 -0.0507805330764750582 -0.0566392105228117129 -0.0555045107889033038 -0.0537618939982477187 -0.0514353897847103364 -0.0507359503158334446 -0.0560281091690213937 -0.0525580721079815308 -0.0565997775566389333 -0.0504478872711732126 -0.0516353231331728169 -0.0539768619227540963 -0.0523385100540057491 -0.0516260747638155604 -0.0561328277131424094 -0.0549770541571955734 -0.0564218316989937574 -0.0513737031409291708 -0.0534080704055221109 -0.0532234323359034173 -0.049359119719903366 -0.054748481420695147 -0.0490558456261177833 -0.0557887904963138559 -0.0553286325680148808 -0.0522475457064476914 -0.0533680706771226254 -0.0494404869299046659 -0.0528025070759326615 -0.0504618351492271203 -0.0542962960222423893 -0.0511408712719258751 -0.0526087129614231097 -0.0504142520847571107 -0.0561876891955786079 -0.0525081678439186378 -0.0568594543724587967 -0.0530132070352526477 -0.0558564985986491139 -0.0557642293607729447 -0.0568303570889149151 -0.0562397677437568716 -0.0549925767764838785 -0.0516836592606707695 -0.0519163950418511655 -0.0481302008387591782 -0.0546127241916318507 -0.0506479050117313312 -0.0509375463294486838 -0.0523877537339214536 -0.0541773091437517187 -0.0544604044458761108 -0.0508458809510060825 -0.0494588585776306322 -0.0526192640571188849 -0.0502194625640121073 -0.0533304472390503104 -0.0525137553499726156 -0.0566401566636174011 -0.0501019892190422353 -0.0514348801423082508 -0.0515091279013158571 -0.051456071021884861 -0.0520167360434775836 -0.0498700121024035353 -0.0543515442838604784 -0.0539365710036960253 -0.051842325623519897 -0.0508841749245111316 -0.053039148832892978 -0.0536341949650127672 -0.0521926542063309018 -0.0492092279049861775 -0.0544677590541281093 -0.0484307543177743688 -0.051966819879535206 -0.0531702701625530044 -0.052393673162255551 -0.0508498324117470785 -0.0520444895988692244 -0.0522442434809628348 -0.0553582585228156662 -0.0534710938099692348 -0.0542841486703997886 -0.0524431647977401383 -0.0558574615367430638 -0.0526886433404681817 -0.0523820034795238615 -0.0503259572848782852 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
1.19323444237248788 	1.10365134020205291 	
1.16455791575720546 	1.1355021575841302 	
0.0128036549823034515 	-0.0546697883032441628 	
-0.10887284932728393 	-0.0532803989953366738 	
0.0596259802471913736 	0.0224833702714180815 	
0.0376200401292133071 	-0.0771353164643296951 	
0.0411159107714298908 	-0.0768203736787752001 	
0.0696660041607025937 	-0.0454008667458865797 	
0.0199980688049050878 	-0.0958909979026360687 	
-0.0974044323932856393 	-0.0302019903373169675 	
0.0354184220286879112 	-0.0125611304358038151 	
-0.114131411831397175 	-0.00315477081028009594 	
0.0467246048507069453 	0.0640609898122714017 	
0.02107826230735068 	0.0488270569950124342 	
0.0602803704386650277 	-0.0572218016409999641 	
-0.0137612550592881907 	-0.0746545996212691354 	
-0.0536300362218993174 	-0.0636165735846278557 	
0.0664918670416289187 	0.0225112606484414446 	
-0.00791140581492407076 	-0.034544195625692567 	
0.0689526832755080338 	0.0407311741636741248 	
-0.0496685562073276785 	-0.0798628675343147354 	
-0.0794987836830611388 	-0.00125843451143519552 	
0.0124988341600040086 	0.000342211347447629946 	
0.0311194053018360381 	-0.0839256295554418191 	
-0.103227227400035676 	0.0209965948909844775 	
0.048353899526284265 	0.0447505077732809342 	
0.0214843045020424311 	0.0290921577393402769 	
0.0475564005076015983 	0.0559969794535006143 	
-0.0134129247355141319 	-0.0776705022077120583 	
0.0252476268825518289 	-0.0344772540609961931 	
0.0730890435823567663 	-0.0921593328411282192 	
-0.0857692743681313513 	-0.0906934290512722008 	
0.0274301692817681998 	0.0148655859337688719 	
-0.115456235687370512 	-0.0749293684606054528 	
0.0294031487722755738 	0.0511933596600224125 	
-0.00739325615111159195 	0.070191992696761199 	
-0.0797893824866778567 	0.0233125767443296064 	
0.0589340775210044909 	-0.0711754717550912713 	
-0.0958271005588528235 	-0.0772213849384036505 	
-0.0403086301253670481 	0.00731804959302331803 	
-0.0235029000370315343 	-0.10604170048416367 	
0.00198064346701789119 	0.0228813107886171943 	
-0.0158366318496782205 	-0.0848802522225989148 	
-0.1166127679251618 	0.0711846307355772645 	
-0.0345898678194880294 	-0.0965713110481548204 	
0.0345843667358964046 	0.0603999271313219108 	
-0.0413759633305404023 	-0.0032625508914142726 	
0.0568953331524017086 	0.0619810130960365968 	
-0.0634666909662302547 	0.0373912094084370844 	
0.0535429400853260976 	0.0295462051864257905 	
0.069807218280953362 	0.00957505293860321481 	
0.0608660950276555812 	0.0570816700015629314 	
0.0713164087175934686 	0.0253094968696553242 	
0.0357693168722422461 	0.0153044737325466959 	
0.0296156270992086676 	-0.109429806788760242 	
0.00392809093975230589 	-0.0729306566471017853 	
-0.111469754933580592 	-0.120367891684431461 	
-0.00634213058906721479 	0.042875693347806651 	
-0.0498008712594534206 	-0.0712087344132402572 	
-0.0232971321093652477 	-0.0856136580186096507 	
-0.0482061418463571797 	-0.00161313750454946205 	
-0.0248696022935214096 	0.0446756257026981324 	
0.0293700253150780063 	0.0018244315069270683 	
-0.0333445289699803721 	-0.0792923446265925008 	
-0.115662878954422135 	-0.0571561953855523192 	
-0.104803349227026971 	0.0608658684308862954 	
-0.0356361888053585985 	-0.103956689053216353 	
-0.0128992478109994715 	0.000652900826941616623 	
-0.0110217411046003386 	-0.0332064052489344577 	
0.0691161167596030662 	0.0418333998069146951 	
-0.0292636866747932115 	-0.115621781103275034 	
-0.105137795267041312 	0.0150476339745554688 	
-0.0797514666755506779 	-0.00606928545664890077 	
-0.028301327684715983 	-0.0590984409778385969 	
0.00225519042321181262 	-0.0669262344826936639 	
-0.0623712109063180378 	-0.0917329013746771005 	
0.0273153410904841271 	6.52094837636866534e-05 	
0.0475223423845173715 	-0.0368325126935498334 	
0.044179395011721391 	-0.118635570703876134 	
-0.0876241142877172974 	-0.0239836229616016625 	
-0.0189633207792590484 	-0.00436423113984147487 	
0.0185779726058129917 	-0.0189438734958861758 	
-0.096349841489912616 	0.0368621669978151448 	
-0.0988006306957863178 	-0.0844115922057575852 	
0.0377312835201180641 	-0.00626227110423731477 	
-0.103999980656173399 	-0.114038694659248499 	
0.00805864621039445103 	-0.0748297159189370148 	
-0.0371631232440120945 	0.0182933059578666152 	
-0.0106927141702562994 	-0.0383654004456464096 	
-0.101858045600465311 	-0.0116421159769202719 	
-0.0531673510373415759 	-0.0102832582626856718 	
-0.00578125687040188449 	-0.0493096297365558933 	
0.00752127585122116995 	0.0567365302401570543 	
-0.00657077892673409159 	6.56886074690213865e-05 	
-0.0434977398831923739 	0.066148600248103373 	
0.0263731492134056701 	-0.0744527041884158192 	
0.0351194715380596031 	0.0478770450733050287 	
-0.0774341019405877379 	0.0381399610289265487 	
0.0301968535147759225 	-0.0811252394624102369 	
-0.0346362874759416836 	-0.100260574098479868 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
-0.0051126666632509473 	-0.00999088620274462061 	-0.00121466696870137789 	-0.00773300611596802571 	0.00302148579126679815 	-0.00772809316375816426 	-0.00348919697825370977 	0.00439610512651089462 	-0.00507683601503103668 	-0.00239567932057347874 	0.0100182593535812822 	-0.00943524090449528868 	-0.00644519681370213631 	-0.00671400083506097558 	-0.0079890873505423475 	0.00107369341016355386 	-0.0055907976476629118 	-0.00142290618098027529 	0.00910434177622430202 	-0.0010392033704020255 	-0.00777859363462465783 	0.000384013757316790168 	-0.00925920662414934231 	-0.00177893841800526287 	0.00749624275386964051 	-0.00108635924430357592 	-0.00633613061998029165 	0.00830095846111596203 	-0.00655504416372737313 	0.00870920586928189584 	0.00824477338811939985 	0.00273712874764631652 	0.000458789082551274005 	-0.0075148041761148518 	0.00335378021721601102 	0.0010912099579492387 	-0.00696637853990363532 	0.00973813252118751506 	0.000482345190178480783 	0.00258204293059011636 	-0.00856934253533120534 	-0.00424362373088101562 	-0.00282323665100731817 	0.00721844963936686072 	0.000719107626785250951 	0.00594156483052304864 	0.00384729880794616296 	0.00400239112586509276 	-0.00579942313792349701 	-0.000696671002405571454 	0.00494273657121188214 	0.00788865022188791135 	-0.00821168176060774711 	-0.00866602948767879015 	0.00495387805501592681 	-0.00886246284277298485 	-0.00888108140933724713 	-0.000113231638400241905 	-0.00116835906847599039 	0.00374954500000187346 	-0.00404081722252320249 	0.00494178035821720655 	0.00203324327329691169 	0.00849597907405493825 	-0.00575305964926590193 	0.00226508928132380287 	0.0075570620107589595 	-0.00889013002654167814 	0.000210504781530930523 	-0.0079269121812115019 	-0.00292050995324969875 	0.00669533612776303504 	0.00785538235414176902 	-0.00771425299131676175 	0.0101112894185951922 	0.0057526315788456418 	0.00725211495606297319 	-0.0051262732613356907 	-0.00928988224725322241 	0.000181386200525739257 	0.00912213057250394269 	-0.00680481503025695718 	0.00596885101690989954 	-0.00335290041568023786 	0.00790317672346741232 	-0.0016486825469074636 	0.00908127617458759188 	0.00183398261006754103 	0.00113176041998486925 	0.0102061139389016571 	0.00612321962325854726 	0.000405121500552078396 	0.00169185580472786088 	0.00242750165585267413 	-0.00910257860152900548 	0.00696002928635123738 	-0.00697761715645561168 	0.00611077258251763004 	-0.00203194781463226799 	0.0043110020621627285 	
0.0062808748553535871 	0.018607199080019711 	0.00653961460713854172 	0.0011909490562627763 	0.00700846117948656158 	-0.00904807481943104702 	0.00599870239172634739 	0.00684087351240631782 	0.00250148657982082138 	-0.00704385766909305412 	0.00771176418138723452 	0.000866376085832874093 	0.00512360217774615167 	-0.00250786754491189642 	0.00282175665150085318 	0.00774678149200439415 	0.00215502639190898963 	0.000744288776206447384 	0.00658169693302130751 	-0.0042310701846681462 	0.0029550353087453708 	0.000711107959763680199 	-0.00154380636344943829 	0.00786998795506793289 	-0.00842670002271118067 	-0.00938783486699894427 	-0.00219806166924547703 	-0.00672855981996926377 	0.00637215157669147447 	0.00388807821490403391 	-0.00445108123703488474 	-0.0047642122246516665 	-0.00842439432286647485 	0.00933655156573692628 	-0.00815492384389846121 	-0.00179992830438108859 	-0.00934387981881335331 	0.000206297989325970979 	0.00217447764771071424 	-0.00865232992539006172 	-0.00196698485001238575 	0.00515263783760915549 	0.00188572128418484203 	0.00930072614250153189 	0.000369287980872480505 	-0.0053883077050932383 	-0.00274198072451831707 	0.00237936435002106912 	0.00153322801763357145 	-0.00882206336329610132 	0.000316020914796217645 	0.00182248329916229559 	-0.00718714126223458406 	0.00154012991482207085 	-0.00624173029667359977 	0.000786939615319756365 	0.00524532544571377091 	0.00620697872801721263 	0.00922630429479513042 	-0.00971098091683546272 	0.00773049029052503504 	0.00619351122003093755 	0.00790552599736898086 	0.00129861620474462387 	0.0054049951549466433 	0.00327734490721350242 	0.00872714999363435363 	0.00344188760527968729 	-0.000748915316613148522 	-0.0011475258794223181 	-0.00975850631556246691 	1.63645054051856736e-05 	0.0063744304402232263 	0.00935977388889892847 	0.00952669748727763208 	-0.0101523473479503308 	-0.00573196802826666553 	-0.00410604435769002744 	-0.00122868283287535813 	-0.000891327638924992258 	-0.00113318839546903429 	-0.00334649723715081844 	-0.00918258826535293948 	-0.00302844802567469196 	0.00704532036050202135 	-0.00579439479381463948 	-0.00390214084549752325 	0.00731556245785374652 	0.000457940387832414942 	-0.00363647881123063199 	0.00695106844228671455 	-0.00610858288495282412 	0.00728489115581521657 	-0.00129378814317124887 	0.00508561458504681006 	0.00428824849797394738 	-0.00949378623371353696 	0.00959205044079419408 	0.00521484487015389398 	-0.00461686509893682786 	
]
;
bias = 2 [ 0.00257529472867298187 -0.00257529472867288429 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 1 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
random_gen = *3  ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
