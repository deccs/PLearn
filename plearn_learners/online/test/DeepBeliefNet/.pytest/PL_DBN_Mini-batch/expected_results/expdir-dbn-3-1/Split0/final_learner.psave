*1 ->DeepBeliefNet(
cd_learning_rate = 0.0100000000000000002 ;
grad_learning_rate = 0.0100000000000000002 ;
grad_decrease_ct = 0 ;
batch_size = 3 ;
n_classes = 2 ;
training_schedule = 2 [ 1000 1000 ] ;
use_classification_cost = 0 ;
reconstruct_layerwise = 0 ;
layers = 2 [ *2 ->RBMBinomialLayer(
size = 2 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 2 [ 0.259999999999999731 0.320000000000000118 ] ;
input_size = 2 ;
output_size = 2 ;
name = "RBMBinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*4 ->RBMMultinomialLayer(
size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 100 [ -4.88348781864529524 -4.88377909666199628 0.0998136183975280034 0.105471817501073581 0.0944416603126441712 0.0997535283630023306 0.0995807079469193529 0.0969420280226542391 0.101407798986863071 0.103819719061399696 0.0969561262386221256 0.103379686484071684 0.0932604806258945929 0.0949581076326168616 0.0978612202826870531 0.101940630727569329 0.103281189924958716 0.0941595431112412368 0.0998305935628365643 0.0933123105594512864 0.103865433445130051 0.101629187737637211 0.0973778633969569346 0.100349460306733224 0.101767253426589127 0.0939952628691959613 0.0957642872874144568 0.0935745523905245069 0.102064003256194025 0.098361691863909001 0.0989175053269632093 0.10614746415871347 0.0961217644556267847 0.106849253706285979 0.0945216452223907599 0.0952991047808851438 0.100547639463152691 0.0985605833598848236 0.105983428725311607 0.0994327692125842183 0.103893097444509377 0.0968643024791368407 0.102520198423240214 0.100204431378448755 0.103958775859172015 0.0939290211077105641 0.0999474375184054992 0.0929393923414386508 0.0991701323486275238 0.0944082201173512409 0.0945697106806672877 0.092979164059244182 0.093847082093861306 0.0957359700320323803 0.101626912170330402 0.101052854003951226 0.108921157875693647 0.0963814492151018748 0.103458632943262963 0.10290812806515362 0.100178659212683596 0.0971214500704266626 0.0965871618141980054 0.103073960705580364 0.105996494971855496 0.100087602274505388 0.104366272501995302 0.0984793481047083058 0.0999092875429416216 0.093252358955243822 0.104637234166777962 0.102122172258910154 0.10185947931508095 0.101878379680090225 0.100853886423779154 0.10505724942419796 0.0967631186351052552 0.0975018372905746139 0.101409956557437175 0.103055880161497665 0.0989832218691384935 0.0979591861849546941 0.100737252815511005 0.106483496226710883 0.0965834007256001076 0.108223002610933108 0.100965208043670845 0.0988008819013017625 0.100127932147128867 0.103179296286824859 0.100801354336986601 0.100407892578924268 0.0952068316396505465 0.0982331855345690008 0.0970389632595778096 0.100125690380371446 0.094411978606329508 0.0997856098841084227 0.100261110879061907 0.104142637036895802 ] ;
input_size = 100 ;
output_size = 100 ;
name = "RBMMultinomialLayer" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
connections = 1 [ *5 ->RBMMatrixConnection(
weights = 100  2  [ 
-0.595479171538772722 	-0.64784326563401029 	
-0.6152383374774405 	-0.62664605667428297 	
0.0538900294397439625 	-0.0137742833948165666 	
-0.06875053142052448 	-0.0128356405145059246 	
0.101750482831042335 	0.0645179709928756923 	
0.0788404196343822777 	-0.0363313352895024214 	
0.0823984677889268713 	-0.0359772385695514424 	
0.111455643794722073 	-0.0041048261939523184 	
0.0609652140478198282 	-0.0553056639846301532 	
-0.0571686153486568316 	0.0104202988290012701 	
0.0769767542086592094 	0.0288702909576745818 	
-0.0738826113496724585 	0.0376651648655449978 	
0.0890025291790312034 	0.10658630388745495 	
0.0628827179229135558 	0.0909309318538381317 	
0.10189692292911387 	-0.0160894138207842603 	
0.0269756763337721632 	-0.0340491698234521578 	
-0.0131781351491743748 	-0.0230764112596843103 	
0.108709363233458617 	0.0645946658963587189 	
0.0330446970922479225 	0.00641644683858688409 	
0.111338474011847738 	0.0830744128480884469 	
-0.00923663549878874814 	-0.039419952693748761 	
-0.0390168467135288966 	0.0396927629301102661 	
0.053884855284114519 	0.04179601820019576 	
0.0722589195882538532 	-0.0431916351119050954 	
-0.0628580553109818196 	0.0620282656863879525 	
0.0904696456760091527 	0.0869795013810659712 	
0.063155692471325367 	0.0709411651936545651 	
0.089737672806708732 	0.0983663784623535764 	
0.0273272832467084566 	-0.0370754352212264021 	
0.0665515477695941549 	0.0066554552858713676 	
0.114615148493610874 	-0.0513201825260645936 	
-0.0456422913795766633 	-0.0504568195824679211 	
0.0690561056867186052 	0.0565546631705502456 	
-0.0754060455133410135 	-0.0346219815131878009 	
0.0713063685070573078 	0.0933620354169992783 	
0.0341980957421883225 	0.112370604562321522 	
-0.0392048865688329473 	0.0645005741897170942 	
0.100413128501990342 	-0.0302192489756252305 	
-0.0557068816320919549 	-0.0369117849033234677 	
0.000529733929197445555 	0.0485162644411036431 	
0.0170355689113608696 	-0.0656936836103067801 	
0.0433878525009998087 	0.0645360645558576557 	
0.0248375275797735988 	-0.0443637944730375239 	
-0.0760831140867710143 	0.112732191490474212 	
0.00587915934077326303 	-0.0562115972021530463 	
0.0766272396820571744 	0.102736863234715051 	
-0.000592684940426663198 	0.0378303322767531494 	
0.0992806567766493231 	0.104535562881183208 	
-0.0226534723321051186 	0.078833337275821494 	
0.0956148861294622843 	0.0716084093953505973 	
0.111961983119019282 	0.051503114001920508 	
0.103261697334856059 	0.0995893663062659279 	
0.113622132076437066 	0.0674654151128029206 	
0.077537126133991538 	0.0570887588626447992 	
0.0705810984356155524 	-0.0689366435996839194 	
0.044843023134881678 	-0.0322309100088603792 	
-0.0714869712521966627 	-0.0802860339949844209 	
0.0350917134068162717 	0.0847180859020596616 	
-0.00934136513864572242 	-0.0307058733146445689 	
0.017274684402242526 	-0.0451641166704254277 	
-0.00744338758825806822 	0.0394987995010958187 	
0.01635978807368689 	0.0864131668208693443 	
0.070961277310940693 	0.043396773338633815 	
0.00718060967436378282 	-0.0388226740324390598 	
-0.0755833033596572668 	-0.0167504198245917932 	
-0.0642340161003093629 	0.102350333481158032 	
0.00480424872243435854 	-0.0636443844298318767 	
0.0282189683208145629 	0.0419719166047329909 	
0.0299132095892969477 	0.0077544045179868985 	
0.111530306999090334 	0.0842099709862055845 	
0.0111726585535115806 	-0.0753750532311086713 	
-0.0647904300854395543 	0.0560328728134857762 	
-0.0392948976134837868 	0.0348323569795132501 	
0.012391516944369076 	-0.0184093328026520009 	
0.0431605911084246147 	-0.0262028154072604068 	
-0.0221174993040646715 	-0.0514567367068857959 	
0.0688357274057207064 	0.0415705062017272323 	
0.089084785497041255 	0.00441555037709988676 	
0.0852942013840160274 	-0.0781125130895272968 	
-0.0472940655022145579 	0.0167306727323274437 	
0.0220238553939347825 	0.0368257958383149744 	
0.0599111578444758708 	0.0223267883631605574 	
-0.0558570133839886712 	0.0780883336256121968 	
-0.058716698004954028 	-0.0441544608089798341 	
0.0793606765007453807 	0.0352579600100396198 	
-0.0640094082428914329 	-0.0739527557808974945 	
0.0489600429692438679 	-0.0341678748008232419 	
0.00379375700322669715 	0.0596590822724617914 	
0.0302207297680062159 	0.00254921219936410934 	
-0.0616037449568939341 	0.0290990160924210692 	
-0.0125089212557680796 	0.0306990708174415296 	
0.0351162640727813863 	-0.00848184184674327137 	
0.0492138445592737589 	0.0988530120564841547 	
0.0345815650076597633 	0.0413837339984958752 	
-0.00231189629031252003 	0.1080671288555725 	
0.0674832518044770763 	-0.0336835252022576678 	
0.0770889815106832327 	0.0900588562201595916 	
-0.0367474445651055151 	0.0795105696210816892 	
0.0713351233590624745 	-0.0403765780191503165 	
0.00580328195072377442 	-0.0599406438638086306 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 2 ;
up_size = 100 ;
learning_rate = 0.0100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 2 ;
output_size = 100 ;
name = "RBMMatrixConnection" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *6 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
] ;
classification_module = *0 ;
final_module = *7 ->ModuleStackModule(
modules = 2 [ *8 ->GradNNetLayerModule(
start_learning_rate = 0.0100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  100  [ 
0.0123420928014191557 	0.00916499543260136142 	-0.00164506058869937706 	-0.00792958713804811817 	0.00236549116291899161 	-0.00816839208649198199 	-0.00393729201208150355 	0.00383571983020708843 	-0.00544728800267464154 	-0.00266053897009083237 	0.00946810364372980065 	-0.00972470140984709429 	-0.00715049251794375867 	-0.00734869875953185047 	-0.00851045478860876919 	0.000733198497111745766 	-0.00587341695528064214 	-0.00209131432022617624 	0.00867743624742249239 	-0.0017424290544537477 	-0.00803777150919455716 	2.68947234888736322e-05 	-0.00978963001083593166 	-0.00219383685419234338 	0.00713629807466046543 	-0.00176071907009400916 	-0.00693551341442328901 	0.00760840838401072046 	-0.00689064362225262801 	0.00821779551345410038 	0.00775615975335418317 	0.00256994077777214979 	-0.000125487652430558499 	-0.00765557075172304709 	0.00270057028444748272 	0.00046445864750938883 	-0.00737340071900496018 	0.00924350722960627647 	0.000308359129016674426 	0.00213576384551587362 	-0.0088316481921647573 	-0.00479667378996827178 	-0.00314050304959243281 	0.00677359813450965909 	0.000461574357387472775 	0.0052630551506867209 	0.00342377191963190138 	0.00328382212079000564 	-0.00626455935271803908 	-0.0013538271142407624 	0.00428995531271315206 	0.00717178746011403519 	-0.0088934328165411157 	-0.00926633853826809052 	0.00458758045120281812 	-0.00924171707330578331 	-0.00894077273613546816 	-0.000689382609061560837 	-0.00144386531203365576 	0.00344874682264902479 	-0.00445501595657440182 	0.004394399096584377 	0.00146877925949968121 	0.00820337445445518988 	-0.00592893418508044692 	0.00182255472740502585 	0.00731552216505707183 	-0.0093740454197580262 	-0.000212912355459384688 	-0.00863228712512623987 	-0.00315315105065477495 	0.00635133933025240714 	0.00750852663533482529 	-0.00805517934762344651 	0.00972441442848316455 	0.00554144065331621354 	0.0066946947510606019 	-0.00565723229911999602 	-0.00967100372334113619 	-0.00011446669224282846 	0.00865912090766649163 	-0.00731143980482081186 	0.005563065733680898 	-0.00350700272215526175 	0.00733748393075391286 	-0.00173505410219775436 	0.0086972297748011216 	0.00136029609347290388 	0.000717391705312010676 	0.00991167438484492555 	0.00573543123204991317 	1.6357813687929368e-06 	0.0010656448048303839 	0.00193302874506671692 	-0.00966095349810980504 	0.00653802734483208657 	-0.00763470234441813913 	0.00566876259818077221 	-0.00244991794631276147 	0.00406053318954284741 	
-0.011173884609316509 	-0.000548682555326316496 	0.00697000822713652116 	0.00138753007834285054 	0.00766445580783437982 	-0.00860777589669724404 	0.00644679742555415245 	0.00740125880871012228 	0.002871938567464418 	-0.00677899801957569919 	0.0082619198912386952 	0.00115583659118469271 	0.00582889788198777143 	-0.00187316962044102499 	0.00334312408956729222 	0.00808727640505616137 	0.00243764569952671997 	0.00141269691545234518 	0.00700860246182310586 	-0.00352784450061643289 	0.00321421318331525842 	0.00106822699359159987 	-0.0010133829767628522 	0.00828488639125499193 	-0.00806675534350202728 	-0.00871347504120848111 	-0.00159867887480246037 	-0.00603600974286399965 	0.00670775103521673542 	0.00437948857073182807 	-0.00396246760226966373 	-0.00459702425477752624 	-0.00784011758788464436 	0.00947731814134509035 	-0.00750171391112993986 	-0.00117317699394124133 	-0.00893685763971203972 	0.000700923280907215672 	0.0023484637088725213 	-0.00820605084031584588 	-0.00170467919317889645 	0.00570568789669640732 	0.00220298768276995212 	0.00974557764735873959 	0.000626821250270258572 	-0.00470979802525691143 	-0.00231845383620405418 	0.00309793335509616231 	0.00199836423242812436 	-0.00816490725146091709 	0.000968802173294958623 	0.00253934606093618453 	-0.006505390206301284 	0.00214043896541134737 	-0.00587543269286049195 	0.00116619384585259201 	0.0053050167725119373 	0.00678312969867851581 	0.00950181053835282355 	-0.00941018273948261187 	0.00814468902457630116 	0.0067408924816637671 	0.00846999001116627986 	0.0015912208243443885 	0.00558086969076118568 	0.00371987946113228442 	0.00896868983933632111 	0.00392580299849605227 	-0.000325498179622836156 	-0.000442150935507603716 	-0.00952586521815736338 	0.000360361302915814029 	0.0067212861590301657 	0.0097007002452056193 	0.00991357247738965976 	-0.00994115642242088086 	-0.00517454782326429597 	-0.00357508531990572255 	-0.000847561356787462027 	-0.000595474746156425408 	-0.000670178730631581176 	-0.00283987246258697937 	-0.00877680298212393101 	-0.00287434571919966721 	0.00761101315321550433 	-0.00570802323852433353 	-0.00351809444571104602 	0.00778924897444837824 	0.000872309102505269395 	-0.00334203925717386965 	0.00733885683349534603 	-0.00570509716576950762 	0.00791110215571273409 	-0.000799315232385289817 	0.00564398948162753416 	0.00471025043949309646 	-0.00883670104575096267 	0.0100340604251309921 	0.00563281500183433932 	-0.0043663962263169433 	
]
;
bias = 2 [ -0.00391578848611695649 0.00391578848611705884 ] ;
input_size = 100 ;
output_size = 2 ;
name = "GradNNetLayerModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *9 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
*10 ->SoftmaxModule(
input_size = 2 ;
name = "SoftmaxModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
n_modules = 2 ;
name = "ModuleStackModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
final_cost = *11 ->CombiningCostsModule(
sub_costs = 2 [ *12 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
*13 ->ClassErrorCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "ClassErrorCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
cost_weights = 2 [ 1 0 ] ;
n_sub_costs = 2 ;
target_size = 1 ;
input_size = 2 ;
output_size = 3 ;
name = "CombiningCostsModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
;
partial_costs = 1 [ *14 ->NLLCostModule(
target_size = 1 ;
input_size = 100 ;
output_size = 1 ;
name = "NLLCostModule" ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *3   )
] ;
online = 1 ;
background_gibbs_update_ratio = 0 ;
gibbs_chain_reinit_freq = 2147483647 ;
top_layer_joint_cd = 0 ;
n_layers = 2 ;
minibatch_size = 3 ;
gibbs_down_state = 1 [ 0  0  [ 
]
] ;
seed = 1827 ;
stage = 2000 ;
n_examples = 4 ;
inputsize = 2 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 2000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
