*1 ->HyperLearner(
tester = *2 ->PTester(
expdir = "" ;
dataset = *3 ->AutoVMatrix(
filename = "PLEARNDIR:examples/data/test_suite/linear_4x_2y_binary_class.vmat" ;
load_in_memory = 0 ;
writable = 0 ;
length = 200 ;
width = 6 ;
inputsize = 5 ;
targetsize = 1 ;
weightsize = 0 ;
extrasize = 0 ;
metadatadir = "PLEARNDIR:examples/data/test_suite/linear_4x_2y_binary_class.vmat.metadata/"  )
;
splitter = *4 ->ExplicitSplitter(
splitsets = 1  2  [ 
*3  	*3  	
]
 )
;
statnames = []
;
statmask = []
;
learner = *5 ->ModuleLearner(
module = *6 ->ForwardModule(
modules = 3 [ *7 ->NetworkModule(
modules = 1 [ *8 ->RBMModule(
visible_layer = *9 ->RBMBinomialLayer(
size = 5 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 5 [ -0.00741490224202020608 -0.00543599885302569787 -0.00631989082786923572 0.000938451348255942832 -0.000862380524672084797 ] ;
input_size = 5 ;
output_size = 5 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10 ->PRandom(
seed = 1827 ;
fixed_seed = 0  )
 )
;
hidden_layer = *11 ->RBMBinomialLayer(
size = 15 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 15 [ -0.00019091881638435857 0.000692612344419769725 8.05887038896703814e-05 6.58650757853363334e-05 -0.000462703741505384781 -0.000345319709093550389 -0.000426910327063052602 -0.000332496350013624959 -0.000249832087456332448 -0.000305219800169643238 -0.00010980993375596001 -3.23934346327403339e-05 -0.000659721786812819916 -0.000434905533523833536 -5.51609528667892839e-05 ] ;
input_size = 15 ;
output_size = 15 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
connection = *12 ->RBMMatrixConnection(
weights = 15  5  [ 
0.111532539174318199 	0.187811788715984557 	-0.22626158765521126 	-0.233129870295510383 	0.119238976328474175 	
-0.237753965753817409 	-0.231057634349966873 	-0.0160342360440717188 	-0.0348869237801669382 	0.0904224929888394341 	
-0.11480906531481426 	0.114256570455461448 	0.0395184419057638264 	0.213465119193897074 	-0.151617646776664866 	
0.0452810620903923225 	0.186138648341168028 	-0.241669850969782773 	-0.00273182989094965852 	-0.217454074499106198 	
-0.0837472601661387317 	0.162600765517560919 	0.19306474933853307 	-0.203481508797696664 	0.254103925287085419 	
0.139460994658605147 	0.173337056482309709 	-0.145409675053789461 	-0.246538097386788446 	-0.00236295468943661545 	
0.221884912969608578 	-0.186265533072615563 	0.142780753905995345 	-0.0878442708884909357 	0.193631993546532849 	
-0.0480186751024380479 	0.223544608567212366 	0.0364252949429773806 	0.0225722593694714958 	0.257623444853429029 	
0.146378222626808829 	-0.000158438587164408488 	0.0288614979002441464 	0.0539600251678709272 	-0.245602785443513966 	
0.167026346551878119 	-0.192829125680318236 	0.145830128272192411 	-0.0589841834439883347 	0.106161183485431715 	
-0.199347233078686348 	0.122085769377975079 	0.174091772543225415 	0.0355997489339363454 	0.192618740686110151 	
-0.22758879765717735 	0.159694755162982593 	0.182898714339929436 	0.0719426859730288304 	-0.175849783304905943 	
0.203433183673328438 	0.0252734783895589288 	0.140629819750046015 	-0.0525607739415335368 	0.0822164419110390232 	
0.201369706773431967 	0.0573850010944562394 	0.0272266445762920119 	0.177649517290784931 	-0.0977265536520297434 	
0.0771932230840291916 	0.0219421891209198236 	-0.0339867489356452807 	0.210398374465431665 	-0.210555786860010002 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 5 ;
up_size = 15 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 5 ;
output_size = 15 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
reconstruction_connection = *0 ;
grad_learning_rate = 0.00100000000000000002 ;
cd_learning_rate = 0 ;
compute_contrastive_divergence = 0 ;
standard_cd_grad = 1 ;
standard_cd_bias_grad = 1 ;
standard_cd_weights_grad = 1 ;
n_Gibbs_steps_CD = 1 ;
min_n_Gibbs_steps = 1 ;
n_Gibbs_steps_per_generated_sample = 1 ;
compute_log_likelihood = 0 ;
minimize_log_likelihood = 0 ;
Gibbs_step = 0 ;
log_partition_function = 0 ;
partition_function_is_stale = 1 ;
input_size = -1 ;
output_size = -1 ;
name = "rbm_0" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
] ;
connections = []
;
ports = 2 [ ("input" , "rbm_0.visible" )("output" , "rbm_0.hidden.state" )] ;
save_states = 1 ;
name = "network_0" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
*13 ->NetworkModule(
modules = 2 [ *8  *14 ->RBMModule(
visible_layer = *15 ->RBMBinomialLayer(
size = 15 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 15 [ -0.00181010305207781903 -0.0139565166488147593 -0.0173911992694234588 -0.011301792170158172 0.00715722737262551763 -0.0118417704523890339 7.84881727217838948e-05 -0.000922491975538373282 0.00176248685259962259 -0.00917947635612968195 0.00659751404013013236 -0.0012431721700721357 -0.000690366017608163066 0.00301805856872872395 0.00991044597535732999 ] ;
input_size = 15 ;
output_size = 15 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
hidden_layer = *16 ->RBMBinomialLayer(
size = 20 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
bias = 20 [ 0.000809098640355019726 -0.000661246082206968979 -0.00226872094948746923 0.000222388424196158057 -0.00119824300992009631 -0.00124327581110912091 -0.000399884602011445667 0.000756073269680812088 -0.00129997591475091703 -0.000872283779968379119 -0.00117326298168328935 -0.0013574076213712827 0.000459098879022368418 -0.000704366492196004113 -0.00166789963894511625 -0.00104582443465928848 -0.0013668875266807511 -0.000665999997969096377 -0.000470681182910106957 -0.000143409964875425484 ] ;
input_size = 20 ;
output_size = 20 ;
name = "RBMBinomialLayer" ;
use_fast_approximations = 0 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
connection = *17 ->RBMMatrixConnection(
weights = 20  15  [ 
-0.199183283591467586 	-0.0448861405222477916 	-0.145911605089940416 	0.143167128930779708 	0.097264546687425249 	-0.0949925133778040665 	-0.102716450211031304 	-0.178404509085510282 	0.210887183685237151 	-0.174857624749812868 	-0.0275685708748617357 	-0.20085264239421638 	0.0127999445714401579 	0.0525619265455185072 	-0.181114851994662734 	
-0.0405345646699039885 	0.115713015655211388 	0.0382070774945121316 	0.209081052310465254 	0.0154753678304534268 	-0.115963095563931154 	-0.0545581384739589198 	0.0622760463753706944 	0.0423000400201669555 	-0.19141013712398261 	0.0195581330642528688 	0.0497516461676063906 	-0.150568769029755634 	0.044099340425539868 	-0.128099183304432179 	
0.0212798441799221354 	0.107092884451473497 	0.134112247501170623 	0.201054824223234785 	-0.207564543339615937 	0.169553880747502411 	0.145202456176182881 	0.182382196206076985 	0.0338098074757868308 	0.115703271531355081 	0.084076361430113114 	0.195966020934331825 	0.0823736521471305078 	-0.00913591333341486067 	-0.00998542292239412363 	
-0.213808731496335919 	-3.57330316626099779e-05 	0.139752412963511513 	0.208377805756720713 	0.221252008485986112 	-0.227515159385436067 	-0.119083828031646008 	-0.0834267669359637087 	-0.0198051341758010112 	-0.018834976026176755 	-0.0147944479928383658 	-0.0671443164205455106 	-0.197328863181277181 	-0.0636097587615780946 	0.169747111964694303 	
-0.129095368343955269 	-0.0888443250152665676 	0.15999870979229569 	0.00991180882672867102 	-0.0723159457344011436 	0.1535621811608186 	-0.129795156939259609 	0.170079227523400461 	-0.0207740929889144686 	0.116278017909354006 	0.105182066749371791 	-0.202777591919059585 	0.219466888486365835 	0.12370898938567175 	-0.0936132531499176967 	
-0.165050353670635891 	-0.0435589319440154235 	0.211862476683310236 	-0.140221785334447402 	-0.173047144269131703 	0.210517225745375763 	0.165803320692554462 	0.112748400313367414 	-0.216285011527125065 	-0.0903413637635619715 	0.125602744201942867 	-0.0355660465583450269 	-0.099736673904979728 	-0.0345107616919458973 	-0.0907558488484283277 	
0.0907620876195860127 	0.0031112905420243712 	0.056192360136695936 	0.0505260375405189935 	0.208668743045385324 	-0.110248218664548467 	0.191720854009795771 	0.0361553634497484844 	0.215994366414907241 	0.149777468047158163 	-0.103513680983149642 	-0.0505190687185509413 	-0.0317941043051931313 	-0.170769240409502421 	-0.112378271931309684 	
0.0487690395705152324 	-0.136349650315423954 	0.10166556779473096 	0.0164455374614681654 	-0.0926661213082684426 	-0.063904658788169727 	-0.105535610323310505 	0.103138039735415368 	0.16163997241155223 	-0.117491996772037213 	0.115599170790724362 	0.084912011840722279 	0.184423359707916762 	0.127927366591155778 	0.0530818670446324692 	
-0.0677287415174576829 	0.0809964567517113543 	-0.0195424402232347166 	-0.00234618811655406103 	-0.162188494160543345 	0.161510693358132701 	0.0672422678381438266 	-0.178178544520118665 	0.00409551312339385964 	0.155293083170179314 	-0.113117763319655687 	-0.165469649900201715 	0.184381214596949949 	0.17371604967408702 	0.0335741236754884265 	
0.135057664772329028 	-0.0625317430835595905 	0.130353400231434408 	-0.0605017926117314975 	0.0341619687090545382 	0.143589971976766345 	-0.0560524005758504459 	0.200415286788135277 	-0.0143093493141647262 	-0.034064429123071796 	-0.133204077490446743 	0.14635290101959747 	0.102182978734996863 	0.178539241205019183 	-0.077229389893740355 	
0.18449946751420962 	0.189003724286365554 	0.0733148255564332746 	0.125919553021787811 	-0.19400489683760086 	-0.138330194324075062 	-0.00463023911156397808 	0.0430833112717642283 	-0.147927678399169926 	-0.0395301083992953134 	-0.094807587083368311 	-0.149765119075252223 	0.063964250555166996 	0.06784891506159417 	0.121436033608037355 	
-0.0951353216285513031 	0.0698845430271437945 	-0.0792594642563902718 	0.165798137588183431 	0.085001790360831761 	0.103741466635519058 	0.0459721074331424159 	0.0248930365946458433 	-0.191523552757090126 	0.212552098030806186 	0.0808342450785385219 	0.220291996514472982 	0.118777171673848436 	-0.0877877443919223843 	-0.170523275914209238 	
-0.11113273135806466 	-0.0783495570820732234 	-0.00458520115775960368 	-0.196201530322556855 	0.0394905130558005288 	-0.125693748428586577 	0.0987032594647054839 	-0.0549026133969209434 	0.175712916180009476 	0.121127071128284844 	-0.0950606462321347961 	0.0644456081388188606 	-0.178814649109568846 	-0.136472097688931454 	-0.142439315950637746 	
-0.145975586300460619 	0.133195998967976653 	0.0483913722439270749 	0.0597838240065062185 	0.0435847922746179436 	0.108895270934145541 	-0.170627032747475649 	0.0973387506263579672 	0.116040734082825739 	-0.0791557496692463086 	0.02470237269618486 	0.0950701182149208401 	-0.193197890566248559 	0.145668765551007107 	-0.027749652168303874 	
0.198398860472742578 	0.0748486204979505604 	0.153835092500548165 	-0.0545505188068773836 	0.0845650568354725796 	0.0723265025689846103 	0.138709224380672597 	0.146492818989972018 	-0.19457948319521895 	0.15964410781348326 	-0.0586848185802863118 	-0.0768467088050233393 	0.122578832502764287 	-0.0474091109791810808 	-0.125035892567181839 	
0.0231602096473796683 	0.101152310252098712 	0.166538464234946421 	0.148817381944993332 	-0.130712803632445113 	0.0966351039136320172 	-0.179653661653241731 	0.210901483761747555 	0.152086536422386953 	-0.11677447559900532 	0.104005828855715687 	0.0049574435177267423 	-0.0388113984088926806 	0.0416311090585825272 	0.184646906532305449 	
0.118003014455172445 	0.156810604485115607 	0.140185871814998197 	-0.106793368511750822 	0.118109991102171422 	0.213803585283534131 	-0.165602253030414426 	-0.19740285349086803 	-0.14867722710498707 	-0.036693641308080234 	0.00190101283092516536 	0.0913318284426307275 	-0.0717647299711370312 	-0.145638383254883763 	0.0144819652994947357 	
0.190898004079688044 	-0.0105865443108898553 	0.045103835106424163 	-0.215370421512423749 	0.0824334362374186669 	0.0743494290457734491 	0.104582470590265431 	-0.0221113870931153519 	-0.0507552873024821119 	0.163349281186003337 	-0.139658142898227727 	0.0220992644453049357 	-0.0103308405592924916 	0.0876248823067597993 	-0.12634008093061902 	
0.0623093147787751878 	0.148170929224122755 	-0.205778911070684828 	0.0466533311755787314 	0.0757877277385159143 	0.129665202643826916 	0.193334660473715725 	-0.0258395529259260875 	-0.209167429241361169 	0.0407058656450209264 	-0.195600174202360783 	0.111011627274150843 	0.000231292374348730556 	-0.101977810287692483 	0.121069362554991275 	
0.190842131767268691 	-0.185167598723336546 	0.0978899396526391602 	-0.181864114656352577 	-0.106782088342657663 	-0.0517523444814251277 	0.0147853680011378052 	-0.129438454801838632 	-0.0242626106507723427 	0.214688607370236678 	0.12661801914067547 	-0.0864452182514442863 	0.0131257843063401942 	-0.0126889411988008911 	-0.18644360949281652 	
]
;
gibbs_ma_schedule = []
;
gibbs_ma_increment = 0.100000000000000006 ;
gibbs_initial_ma_coefficient = 0.100000000000000006 ;
down_size = 15 ;
up_size = 20 ;
learning_rate = 0.00100000000000000002 ;
momentum = 0 ;
initialization_method = "uniform_sqrt" ;
input_size = 15 ;
output_size = 20 ;
name = "RBMMatrixConnection" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
reconstruction_connection = *0 ;
grad_learning_rate = 0.00100000000000000002 ;
cd_learning_rate = 0 ;
compute_contrastive_divergence = 0 ;
standard_cd_grad = 1 ;
standard_cd_bias_grad = 1 ;
standard_cd_weights_grad = 1 ;
n_Gibbs_steps_CD = 1 ;
min_n_Gibbs_steps = 1 ;
n_Gibbs_steps_per_generated_sample = 1 ;
compute_log_likelihood = 0 ;
minimize_log_likelihood = 0 ;
Gibbs_step = 0 ;
log_partition_function = 0 ;
partition_function_is_stale = 1 ;
input_size = -1 ;
output_size = -1 ;
name = "rbm_1" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
] ;
connections = 1 [ *18 ->NetworkConnection(
source = "rbm_0.hidden.state" ;
destination = "rbm_1.visible" ;
propagate_gradient = 0  )
] ;
ports = 2 [ ("input" , "rbm_0.visible" )("output" , "rbm_1.hidden.state" )] ;
save_states = 1 ;
name = "network_1" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
*19 ->NetworkModule(
modules = 5 [ *8  *14  *20 ->GradNNetLayerModule(
start_learning_rate = 0.00100000000000000002 ;
decrease_constant = 0 ;
init_weights = 0  0  [ 
]
;
init_bias = []
;
init_weights_random_scale = 1 ;
L1_penalty_factor = 0 ;
L2_penalty_factor = 0 ;
weights = 2  20  [ 
0.0140741517422963459 	0.0240834059583218268 	0.0360118846831064751 	0.0374805587163126175 	-0.0276567128699623938 	-0.0141115213235216731 	-0.0512251993073655834 	-0.0208456831823070655 	0.00886820967367440462 	0.031115840858219123 	-0.00226946082449172018 	-0.00473980592688510397 	-0.0245274143902266956 	-0.0449922107970131546 	-0.0114658242515571409 	0.0279812900985528731 	0.0101001167313342841 	-0.0204964532283910331 	0.0452068878780007774 	-0.0138422507158356342 	
0.0421728699579591929 	0.0206068739371179227 	0.00377870183874261028 	-1.50558823653514107e-05 	-0.0410155602518118417 	-0.00289826952355626884 	0.0361562715042887811 	0.0516676812038726341 	-0.0308327467931672657 	0.0306367850923931415 	-0.00830346424580894089 	0.0455204091838931763 	0.030708383294163151 	-0.00698013302220279203 	0.0415121312677211377 	-0.0153077627702553273 	0.0504549648736455775 	-0.0444965282455243305 	-0.00833873096619561736 	0.0359536118171052757 	
]
;
bias = 2 [ -0.00643817158042547886 0.00643817158042547973 ] ;
input_size = 20 ;
output_size = 2 ;
name = "affine_net" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
*21 ->SoftmaxModule(
input_size = 2 ;
name = "softmax" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
*22 ->NLLCostModule(
target_size = 1 ;
input_size = 2 ;
output_size = 1 ;
name = "nll" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
] ;
connections = 4 [ *23 ->NetworkConnection(
source = "rbm_0.hidden.state" ;
destination = "rbm_1.visible" ;
propagate_gradient = 1  )
*24 ->NetworkConnection(
source = "rbm_1.hidden.state" ;
destination = "affine_net.input" ;
propagate_gradient = 1  )
*25 ->NetworkConnection(
source = "affine_net.output" ;
destination = "softmax.input" ;
propagate_gradient = 1  )
*26 ->NetworkConnection(
source = "softmax.output" ;
destination = "nll.prediction" ;
propagate_gradient = 1  )
] ;
ports = 4 [ ("input" , "rbm_0.visible" )("output" , "affine_net.output" )("target" , "nll.target" )("NLL" , "nll.cost" )] ;
save_states = 1 ;
name = "network_2" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
] ;
forward_to = "network_2" ;
forget_all = 1 ;
input_size = -1 ;
output_size = -1 ;
name = "network" ;
use_fast_approximations = 1 ;
estimate_simpler_diag_hessian = 0 ;
expdir = "" ;
random_gen = *10   )
;
batch_size = 10 ;
reset_seed_upon_train = 0 ;
cost_ports = 1 [ "NLL" ] ;
input_ports = 1 [ "input" ] ;
target_ports = 1 [ "target" ] ;
weight_ports = []
;
mbatch_size = 10 ;
seed = 1827 ;
stage = 4000 ;
n_examples = 200 ;
inputsize = 5 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 4000 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1000 ;
use_a_separate_random_generator_for_testing = 1827  )
;
perf_evaluators = {};
report_stats = 1 ;
save_initial_tester = 1 ;
save_stat_collectors = 1 ;
save_learners = 1 ;
save_initial_learners = 0 ;
save_data_sets = 0 ;
save_test_outputs = 0 ;
call_forget_in_run = 1 ;
save_test_costs = 0 ;
provide_learner_expdir = 0 ;
should_train = 1 ;
should_test = 1 ;
template_stats_collector = *0 ;
global_template_stats_collector = *0 ;
final_commands = []
;
save_test_confidence = 0 ;
enforce_clean_expdir = 1  )
;
option_fields = 1 [ "nstages" ] ;
dont_restart_upon_change = 10 [ "module.forward_to" "nstages" "cost_ports" "target_ports" "module.modules[1].modules[0].cd_learning_rate" "module.modules[2].modules[1].cd_learning_rate" "module.modules[2].modules[0].grad_learning_rate" "module.modules[2].modules[1].grad_learning_rate" "module.modules[2].modules[2].start_learning_rate" "nstages" ] ;
strategy = 9 [ *27 ->HyperSetOption(
option_name = "" ;
option_value = "" ;
options = 4 [ ("module.forward_to" , "network_0" )("nstages" , "1000" )("cost_ports" , "[]" )("target_ports" , "[]" )] ;
call_build = 1  )
*28 ->HyperRetrain(
splitter = *0 ;
provide_tester_expdir = 0 ;
call_forget = 0  )
*29 ->HyperSetOption(
option_name = "" ;
option_value = "" ;
options = 5 [ ("module.forward_to" , "network_1" )("nstages" , "2000" )("cost_ports" , "[]" )("target_ports" , "[]" )("module.modules[1].modules[0].cd_learning_rate" , "0" )] ;
call_build = 1  )
*30 ->HyperRetrain(
splitter = *0 ;
provide_tester_expdir = 0 ;
call_forget = 0  )
*31 ->HyperSetOption(
option_name = "" ;
option_value = "" ;
options = 4 [ ("module.forward_to" , "network_2" )("cost_ports" , "[ \"NLL\" ]" )("target_ports" , "[ \"target\" ]" )("module.modules[2].modules[1].cd_learning_rate" , "0" )] ;
call_build = 1  )
*32 ->HyperSetOption(
option_name = "" ;
option_value = "" ;
options = 4 [ ("module.modules[2].modules[0].grad_learning_rate" , "0.01" )("module.modules[2].modules[1].grad_learning_rate" , "0.01" )("module.modules[2].modules[2].start_learning_rate" , "0.01" )("nstages" , "2000" )] ;
call_build = 0  )
*33 ->HyperRetrain(
splitter = *0 ;
provide_tester_expdir = 0 ;
call_forget = 0  )
*34 ->HyperSetOption(
option_name = "" ;
option_value = "" ;
options = 4 [ ("module.modules[2].modules[0].grad_learning_rate" , "0.001" )("module.modules[2].modules[1].grad_learning_rate" , "0.001" )("module.modules[2].modules[2].start_learning_rate" , "0.001" )("nstages" , "4000" )] ;
call_build = 0  )
*35 ->HyperRetrain(
splitter = *0 ;
provide_tester_expdir = 0 ;
call_forget = 0  )
] ;
provide_strategy_expdir = 1 ;
save_final_learner = 0 ;
learner = *5  ;
provide_learner_expdir = 0 ;
expdir_append = "" ;
stage = 1 ;
n_examples = 200 ;
inputsize = 5 ;
targetsize = 1 ;
weightsize = 0 ;
forget_when_training_set_changes = 0 ;
nstages = 1 ;
report_progress = 1 ;
verbosity = 1 ;
nservers = 0 ;
save_trainingset_prefix = "" ;
test_minibatch_size = 1 ;
use_a_separate_random_generator_for_testing = 1827  )
