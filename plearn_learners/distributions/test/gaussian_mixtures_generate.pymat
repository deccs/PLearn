## Automatically adapted for numpy.numarray Jun 13, 2007 by python_numarray_to_numpy (-xsm)

# Generate data from Gaussian mixtures.
# Also test the 'expecation' method.

from numpy.numarray        import array
from plearn.pyplearn import pl

def diagonal(predictor_size):
    return pl.GaussMix(
            L = 4,
            type = "diagonal",
            kmeans_iterations = 5,
            alpha = [ 0.1, 0.3, 0.2, 0.4 ],
            diags = array([ [ 2, 1, 0.5 ], [ 0.3, 2, 1 ], [ 0.5, 0.3, 2 ], [ 1, 0.5, 0.3 ] ]),
            center = array([ [ 10, 0, 0 ], [ 10, 10, 10 ], [ 0, 10, 0 ], [ 0, 0, 0 ] ]),
            outputs_def = "l",
            predictor_size = predictor_size,
            predicted_size = 3 - predictor_size,
            predictor_part = [ 0 ],
            seed = 123456,
            stage = 1,
            inputsize = 3,
            targetsize = 0,
            weightsize = 0,
            report_progress = 1,
            verbosity = 1
    )

def general(predictor_size):
    return pl.GaussMix(
            L = 4,
            type = "general",
            kmeans_iterations = 5,
            alpha = [ 0.1, 0.3, 0.2, 0.4 ],
            eigenvalues = array( [ [ 5.6266, 0.2229, 0.1294 ], [ 3.9589, 1.0099, 0.2522 ],
                                   [ 4.7447, 2.4120, 0.1737 ], [ 8.3573, 2.6007, 0.1924 ] ] ),
            eigenvectors = [ array( [ [ -0.3359, 0.6577, -0.6742 ], [ -0.8944, 0.0016, 0.4473 ], [ 0.2953,  0.7532, 0.5877 ] ] ),
                             array( [ [ -1, 0, 0                 ], [ 0, 1, 0                 ], [ 0, 0, 1                 ] ] ),
                             array( [ [ -0.5846, -0.1119, 0.8036 ], [ 0.4047, 0.8182, 0.4083  ], [ -0.7032, 0.5639, -0.4330] ] ),
                             array( [ [ 0.6159,  -0.6446, -0.4530], [ 0.6687, 0.1235,  0.7332 ], [ 0.4166, 0.7545, -0.5071 ] ] ) ],

            center = array([ [ 5, 10, 5 ], [ -10, -10, 10 ], [ 10, 5, -10 ], [ 0, 0, 0 ] ]),

            outputs_def = "l",
            predictor_size = predictor_size,
            predicted_size = 3 - predictor_size,
            predictor_part = [ 0 ],
            seed = 123456,
            stage = 1,
            inputsize = 3,
            targetsize = 0,
            weightsize = 0,
            report_progress = 1,
            verbosity = 1
    )

def spherical(predictor_size):
    return pl.GaussMix(
            L = 4,
            type = "spherical",
            kmeans_iterations = 5,
            alpha = [ 0.1, 0.3, 0.2, 0.4 ],
            sigma = [ 0.3, 1, 0.5, 2 ],
            center = array([ [ 10, 0, 0 ], [ 10, 10, 10 ], [ 0, 10, 0 ], [ 0, 0, 0 ] ]),
            outputs_def = "l",
            predictor_size = predictor_size,
            predicted_size = 3 - predictor_size,
            predictor_part = [ 0 ],
            seed = 123456,
            stage = 1,
            inputsize = 3,
            targetsize = 0,
            weightsize = 0,
            report_progress = 1,
            verbosity = 1
    )

def generate_vmat(mixture, n_samples):

    generated_data = pl.VMatrixFromDistribution(
            distr = mixture,
            mode = "sample",
            generator_seed = 123456,
            nsamples = n_samples)

    mixture.outputs_def = "e"
    expectation = pl.PLearnerOutputVMatrix(
            data = pl.MemoryVMatrix(
                data = array([ [ 0, 0, 0] ]),
                inputsize = 3,
                targetsize = 0,
                weightsize = 0),
            learners = [ mixture ]
            )
    return pl.ConcatRowsVMatrix( array = [ generated_data, expectation ] )

def main():
    return pl.ConcatRowsVMatrix(
            fill_missing = 1,
            array = [
                generate_vmat(spherical(0), 20),
                generate_vmat(spherical(1), 20),
                generate_vmat(diagonal(0), 20),
                generate_vmat(diagonal(1), 20),
                generate_vmat(general(0), 20),
                generate_vmat(general(1), 20)
            ],
	    inputsize=3,
	    targetsize=0,
	    weightsize=0
           )

